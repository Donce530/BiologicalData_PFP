{"cells":[{"cell_type":"markdown","metadata":{"id":"rrM-gFkvkbOx"},"source":["# Convolutional Neural Networks\n","\n","This note book will be used to test convolutional neural networks on each of the 3 ontologies."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4395,"status":"ok","timestamp":1708280188908,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"INY5-pvaEKak"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-23 18:24:14.076768: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-23 18:24:14.076873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-23 18:24:14.156840: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-23 18:24:14.187131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-23 18:24:24.089634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import f1_score\n","import itertools\n","import pprint\n","import yaml"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708280188909,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"FQzydhXnRN-w","outputId":"08b2a418-74ab-476a-a67b-8be45e3a9619"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow v2.15.0\n","Numpy v1.26.4\n"]}],"source":["print(\"TensorFlow v\" + tf.__version__)\n","print(\"Numpy v\" + np.__version__)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32484,"status":"ok","timestamp":1708280221856,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"EHNRK5u9RRIt","outputId":"f6da9d73-d18b-4455-e601-32ab2371479c"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["config_path = './config.yaml'\n","with open(config_path, 'r') as file:\n","    config = yaml.safe_load(file)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["USE_75_PERCENT_DATA = config['use_75_percent_datasets']\n","partial_dataset_prefix = '75percent_' if USE_75_PERCENT_DATA else ''\n","BP_train_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_embeddings_BiologicalProcesses.pkl\")\n","CC_train_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_embeddings_CellularComponent.pkl\")\n","MF_train_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_embeddings_MolecularFunction.pkl\")\n","BP_label_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_labels_BiologicalProcesses.pkl\")\n","CC_label_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_labels_CellularComponent.pkl\")\n","MF_label_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_labels_MolecularFunction.pkl\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1708280243024,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"fN_1hLZRq1JW"},"outputs":[],"source":["train_data_dict = {'Biological Processes': [BP_train_df, BP_label_df],\n","                   'Cellular Component': [CC_train_df, CC_label_df],\n","                   'Molecular Function': [MF_train_df, MF_label_df]\n","}"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1708280243024,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"OdUudkyKj3ID"},"outputs":[],"source":["num_labels = 1500\n","num_folds = config['num_folds']"]},{"cell_type":"markdown","metadata":{"id":"NApU98ealM6R"},"source":["## Model 1 Architecture: CNN"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1708280243025,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"62fohGyUlVrU"},"outputs":[],"source":["BATCH_SIZE = config['batch_size']"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":418,"status":"ok","timestamp":1708291601431,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"dkj2GTgvrg7S"},"outputs":[],"source":["def model1_training(dataset_name, data):\n","  train = data[0]\n","  label = data[1]\n","\n","  INPUT_SHAPE = (train.shape[1], 1)\n","\n","  best_f1 = 0\n","  print('=======================================================================')\n","  print(f'Training for {dataset_name}')\n","  \n","  model_root_path = f'{config[\"directories\"][\"models\"]}/CNNMod1'\n","\n","  for num_filters, size_kernel in itertools.product([16, 32], [64, 128, 256]):\n","    print('----------------------------------------------------------------------')\n","    print('The number of filters is ', num_filters)\n","    print('The size of the kernel is ', size_kernel)\n","\n","    kfold = KFold(n_splits=num_folds, shuffle=True)\n","    fold_no = 1\n","\n","    for train_fold, test_fold in kfold.split(train, label):\n","\n","      model1 = tf.keras.Sequential([\n","          tf.keras.layers.BatchNormalization(input_shape = INPUT_SHAPE),\n","          tf.keras.layers.Conv1D(filters = num_filters, kernel_size = size_kernel, activation = 'relu'),\n","          tf.keras.layers.MaxPooling1D(pool_size = 2),\n","          tf.keras.layers.Flatten(),\n","          tf.keras.layers.Dense(units = 512, activation = 'relu'),\n","          tf.keras.layers.Dense(units = num_labels, activation = 'sigmoid')\n","          ])\n","\n","      # Compile model\n","      model1.compile(\n","          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","          loss='binary_crossentropy',\n","          metrics=['binary_accuracy',\n","                  tf.keras.metrics.AUC(),\n","                  tf.keras.metrics.Precision(),\n","                  tf.keras.metrics.Recall(),\n","                  ] # tf.keras.metrics.F1Score() not appropriate as it is calculated batchwise\n","          )\n","\n","      print(f'Training for fold {fold_no} ...')\n","\n","      # Fit the data to the model\n","      history = model1.fit(\n","          train.iloc[train_fold], label.iloc[train_fold],\n","          validation_data=(train.iloc[test_fold], label.iloc[test_fold]),\n","          batch_size=BATCH_SIZE,\n","          epochs=5\n","          )\n","\n","      # Generate metrics\n","      scores = model1.evaluate(train.iloc[test_fold], label.iloc[test_fold], verbose=0)\n","      precision = scores[3]\n","      recall = scores[4]\n","      F1_score = 2*precision*recall / (precision + recall)\n","      print(f'Score for fold {fold_no}: F1 score of {F1_score}; {model1.metrics_names[0]} of {scores[0]}; {model1.metrics_names[1]} of {scores[1]*100}%')\n","\n","      if F1_score > best_f1:\n","        best_f1 = F1_score\n","        if dataset_name == 'Biological Processes':\n","          tf.keras.models.save_model(\n","              model1,\n","              f'{model_root_path}/best_BP_model')\n","          print(f'Current best model for Biological Processes has {num_filters} filters, with a kernel size of {size_kernel} and has an F1 score of {F1_score}')\n","\n","        elif dataset_name == 'Molecular Function':\n","          tf.keras.models.save_model(\n","              model1,\n","              f'{model_root_path}/best_MF_model')\n","          print(f'Current best model for Molecular Function has {num_filters} filters, with a kernel size of {size_kernel} and has an F1 score of {F1_score}')\n","\n","        else:\n","          tf.keras.models.save_model(\n","              model1,\n","              f'{model_root_path}/best_CC_model')\n","          print(f'Current best model for Cellular Component has {num_filters} filters, with a kernel size of {size_kernel} and has an F1 score of {F1_score}')\n","\n","      fold_no += 1"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yMgob7Ir4dh","outputId":"ec8a4e84-ef29-4dd3-cafb-56d090537fd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["=======================================================================\n","Training for Biological Processes\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  64\n"]},{"name":"stderr","output_type":"stream","text":["2024-02-23 18:24:52.798707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79086 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:44:00.0, compute capability: 8.0\n"]},{"name":"stdout","output_type":"stream","text":["Training for fold 1 ...\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2024-02-23 18:24:58.443054: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n","2024-02-23 18:25:05.297466: I external/local_xla/xla/service/service.cc:168] XLA service 0x2b487b9c0ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2024-02-23 18:25:05.297534: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n","2024-02-23 18:25:05.309087: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1708705505.923059  113418 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["147/147 [==============================] - 19s 15ms/step - loss: 0.1126 - binary_accuracy: 0.9669 - auc: 0.8153 - precision: 0.3018 - recall: 0.1221 - val_loss: 0.4684 - val_binary_accuracy: 0.9736 - val_auc: 0.8738 - val_precision: 0.6710 - val_recall: 0.1480\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0866 - binary_accuracy: 0.9742 - auc: 0.8942 - precision: 0.6723 - recall: 0.1860 - val_loss: 0.2463 - val_binary_accuracy: 0.9741 - val_auc: 0.9083 - val_precision: 0.6693 - val_recall: 0.1871\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0816 - binary_accuracy: 0.9746 - auc: 0.9138 - precision: 0.6716 - recall: 0.2172 - val_loss: 0.1611 - val_binary_accuracy: 0.9740 - val_auc: 0.9148 - val_precision: 0.6125 - val_recall: 0.2445\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0791 - binary_accuracy: 0.9749 - auc: 0.9217 - precision: 0.6738 - recall: 0.2338 - val_loss: 0.0923 - val_binary_accuracy: 0.9738 - val_auc: 0.9191 - val_precision: 0.6038 - val_recall: 0.2457\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0776 - binary_accuracy: 0.9751 - auc: 0.9260 - precision: 0.6737 - recall: 0.2472 - val_loss: 0.0805 - val_binary_accuracy: 0.9744 - val_auc: 0.9185 - val_precision: 0.6848 - val_recall: 0.1949\n","Score for fold 1: F1 score of 0.3034272923708012; loss of 0.08045875281095505; binary_accuracy of 97.44227528572083%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 16 filters, with a kernel size of 64 and has an F1 score of 0.3034272923708012\n","Training for fold 2 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1120 - binary_accuracy: 0.9671 - auc_1: 0.8189 - precision_1: 0.3072 - recall_1: 0.1231 - val_loss: 0.4613 - val_binary_accuracy: 0.9736 - val_auc_1: 0.8806 - val_precision_1: 0.6908 - val_recall_1: 0.1462\n","Epoch 2/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0863 - binary_accuracy: 0.9742 - auc_1: 0.8964 - precision_1: 0.6730 - recall_1: 0.1846 - val_loss: 0.2887 - val_binary_accuracy: 0.9741 - val_auc_1: 0.9114 - val_precision_1: 0.6733 - val_recall_1: 0.1894\n","Epoch 3/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0815 - binary_accuracy: 0.9747 - auc_1: 0.9140 - precision_1: 0.6733 - recall_1: 0.2154 - val_loss: 0.1390 - val_binary_accuracy: 0.9741 - val_auc_1: 0.9185 - val_precision_1: 0.6514 - val_recall_1: 0.2070\n","Epoch 4/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0788 - binary_accuracy: 0.9750 - auc_1: 0.9223 - precision_1: 0.6750 - recall_1: 0.2353 - val_loss: 0.0922 - val_binary_accuracy: 0.9740 - val_auc_1: 0.9251 - val_precision_1: 0.5978 - val_recall_1: 0.2854\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0771 - binary_accuracy: 0.9752 - auc_1: 0.9270 - precision_1: 0.6763 - recall_1: 0.2494 - val_loss: 0.0801 - val_binary_accuracy: 0.9745 - val_auc_1: 0.9257 - val_precision_1: 0.6273 - val_recall_1: 0.2746\n","Score for fold 2: F1 score of 0.3820372922039355; loss of 0.08013329654932022; binary_accuracy of 97.45275974273682%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 16 filters, with a kernel size of 64 and has an F1 score of 0.3820372922039355\n","Training for fold 3 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1120 - binary_accuracy: 0.9670 - auc_2: 0.8182 - precision_2: 0.3045 - recall_2: 0.1221 - val_loss: 0.4706 - val_binary_accuracy: 0.9734 - val_auc_2: 0.8783 - val_precision_2: 0.6431 - val_recall_2: 0.1781\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0862 - binary_accuracy: 0.9742 - auc_2: 0.8966 - precision_2: 0.6704 - recall_2: 0.1873 - val_loss: 0.2735 - val_binary_accuracy: 0.9740 - val_auc_2: 0.9079 - val_precision_2: 0.6736 - val_recall_2: 0.1936\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0814 - binary_accuracy: 0.9747 - auc_2: 0.9143 - precision_2: 0.6719 - recall_2: 0.2169 - val_loss: 0.1221 - val_binary_accuracy: 0.9740 - val_auc_2: 0.9157 - val_precision_2: 0.6770 - val_recall_2: 0.1920\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0791 - binary_accuracy: 0.9749 - auc_2: 0.9211 - precision_2: 0.6723 - recall_2: 0.2350 - val_loss: 0.0846 - val_binary_accuracy: 0.9744 - val_auc_2: 0.9242 - val_precision_2: 0.6808 - val_recall_2: 0.2134\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0773 - binary_accuracy: 0.9752 - auc_2: 0.9262 - precision_2: 0.6771 - recall_2: 0.2488 - val_loss: 0.0807 - val_binary_accuracy: 0.9744 - val_auc_2: 0.9244 - val_precision_2: 0.6676 - val_recall_2: 0.2235\n","Score for fold 3: F1 score of 0.33487577129948737; loss of 0.08071483671665192; binary_accuracy of 97.43795394897461%\n","Training for fold 4 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1114 - binary_accuracy: 0.9670 - auc_3: 0.8234 - precision_3: 0.3145 - recall_3: 0.1322 - val_loss: 0.4567 - val_binary_accuracy: 0.9740 - val_auc_3: 0.8874 - val_precision_3: 0.6875 - val_recall_3: 0.1544\n","Epoch 2/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0856 - binary_accuracy: 0.9742 - auc_3: 0.8999 - precision_3: 0.6709 - recall_3: 0.1900 - val_loss: 0.2727 - val_binary_accuracy: 0.9742 - val_auc_3: 0.9114 - val_precision_3: 0.7198 - val_recall_3: 0.1517\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0815 - binary_accuracy: 0.9746 - auc_3: 0.9146 - precision_3: 0.6730 - recall_3: 0.2148 - val_loss: 0.1377 - val_binary_accuracy: 0.9741 - val_auc_3: 0.9188 - val_precision_3: 0.6129 - val_recall_3: 0.2345\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0789 - binary_accuracy: 0.9749 - auc_3: 0.9223 - precision_3: 0.6757 - recall_3: 0.2344 - val_loss: 0.0907 - val_binary_accuracy: 0.9744 - val_auc_3: 0.9229 - val_precision_3: 0.6219 - val_recall_3: 0.2533\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0774 - binary_accuracy: 0.9752 - auc_3: 0.9264 - precision_3: 0.6761 - recall_3: 0.2490 - val_loss: 0.0843 - val_binary_accuracy: 0.9737 - val_auc_3: 0.9243 - val_precision_3: 0.5693 - val_recall_3: 0.3043\n","Score for fold 4: F1 score of 0.3966024721146812; loss of 0.08425020426511765; binary_accuracy of 97.37236499786377%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 16 filters, with a kernel size of 64 and has an F1 score of 0.3966024721146812\n","Training for fold 5 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1113 - binary_accuracy: 0.9670 - auc_4: 0.8244 - precision_4: 0.3115 - recall_4: 0.1293 - val_loss: 0.4534 - val_binary_accuracy: 0.9741 - val_auc_4: 0.8883 - val_precision_4: 0.6760 - val_recall_4: 0.1648\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0854 - binary_accuracy: 0.9742 - auc_4: 0.9012 - precision_4: 0.6708 - recall_4: 0.1891 - val_loss: 0.2672 - val_binary_accuracy: 0.9743 - val_auc_4: 0.9110 - val_precision_4: 0.6577 - val_recall_4: 0.1976\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0814 - binary_accuracy: 0.9746 - auc_4: 0.9150 - precision_4: 0.6734 - recall_4: 0.2153 - val_loss: 0.1196 - val_binary_accuracy: 0.9746 - val_auc_4: 0.9187 - val_precision_4: 0.7098 - val_recall_4: 0.1776\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0791 - binary_accuracy: 0.9749 - auc_4: 0.9216 - precision_4: 0.6760 - recall_4: 0.2335 - val_loss: 0.0813 - val_binary_accuracy: 0.9743 - val_auc_4: 0.9211 - val_precision_4: 0.7258 - val_recall_4: 0.1530\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0776 - binary_accuracy: 0.9751 - auc_4: 0.9257 - precision_4: 0.6760 - recall_4: 0.2461 - val_loss: 0.0794 - val_binary_accuracy: 0.9749 - val_auc_4: 0.9251 - val_precision_4: 0.6429 - val_recall_4: 0.2585\n","Score for fold 5: F1 score of 0.3687817068233707; loss of 0.07941184937953949; binary_accuracy of 97.49056696891785%\n","Training for fold 6 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1130 - binary_accuracy: 0.9666 - auc_5: 0.8147 - precision_5: 0.2938 - recall_5: 0.1191 - val_loss: 0.4638 - val_binary_accuracy: 0.9743 - val_auc_5: 0.8732 - val_precision_5: 0.6920 - val_recall_5: 0.1434\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0869 - binary_accuracy: 0.9741 - auc_5: 0.8943 - precision_5: 0.6712 - recall_5: 0.1851 - val_loss: 0.2712 - val_binary_accuracy: 0.9748 - val_auc_5: 0.9075 - val_precision_5: 0.6870 - val_recall_5: 0.1754\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0818 - binary_accuracy: 0.9746 - auc_5: 0.9139 - precision_5: 0.6721 - recall_5: 0.2157 - val_loss: 0.1692 - val_binary_accuracy: 0.9742 - val_auc_5: 0.9183 - val_precision_5: 0.5799 - val_recall_5: 0.2767\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0792 - binary_accuracy: 0.9749 - auc_5: 0.9216 - precision_5: 0.6733 - recall_5: 0.2355 - val_loss: 0.0867 - val_binary_accuracy: 0.9751 - val_auc_5: 0.9256 - val_precision_5: 0.6414 - val_recall_5: 0.2479\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0773 - binary_accuracy: 0.9752 - auc_5: 0.9269 - precision_5: 0.6776 - recall_5: 0.2497 - val_loss: 0.0807 - val_binary_accuracy: 0.9749 - val_auc_5: 0.9239 - val_precision_5: 0.6314 - val_recall_5: 0.2436\n","Score for fold 6: F1 score of 0.35159960484351105; loss of 0.08073154836893082; binary_accuracy of 97.49172925949097%\n","Training for fold 7 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1119 - binary_accuracy: 0.9672 - auc_6: 0.8173 - precision_6: 0.3098 - recall_6: 0.1218 - val_loss: 0.4320 - val_binary_accuracy: 0.9738 - val_auc_6: 0.8755 - val_precision_6: 0.7250 - val_recall_6: 0.1277\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0862 - binary_accuracy: 0.9742 - auc_6: 0.8961 - precision_6: 0.6715 - recall_6: 0.1887 - val_loss: 0.2377 - val_binary_accuracy: 0.9738 - val_auc_6: 0.9067 - val_precision_6: 0.7070 - val_recall_6: 0.1378\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0814 - binary_accuracy: 0.9746 - auc_6: 0.9148 - precision_6: 0.6720 - recall_6: 0.2168 - val_loss: 0.1494 - val_binary_accuracy: 0.9739 - val_auc_6: 0.9179 - val_precision_6: 0.5808 - val_recall_6: 0.2961\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0790 - binary_accuracy: 0.9749 - auc_6: 0.9220 - precision_6: 0.6725 - recall_6: 0.2374 - val_loss: 0.1013 - val_binary_accuracy: 0.9740 - val_auc_6: 0.9207 - val_precision_6: 0.5999 - val_recall_6: 0.2586\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0774 - binary_accuracy: 0.9752 - auc_6: 0.9264 - precision_6: 0.6754 - recall_6: 0.2486 - val_loss: 0.0784 - val_binary_accuracy: 0.9747 - val_auc_6: 0.9241 - val_precision_6: 0.6873 - val_recall_6: 0.2060\n","Score for fold 7: F1 score of 0.31694161659341746; loss of 0.07843054085969925; binary_accuracy of 97.47098684310913%\n","Training for fold 8 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1105 - binary_accuracy: 0.9674 - auc_7: 0.8249 - precision_7: 0.3238 - recall_7: 0.1317 - val_loss: 0.4458 - val_binary_accuracy: 0.9736 - val_auc_7: 0.8890 - val_precision_7: 0.6863 - val_recall_7: 0.1617\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_7: 0.9022 - precision_7: 0.6709 - recall_7: 0.1927 - val_loss: 0.2718 - val_binary_accuracy: 0.9731 - val_auc_7: 0.9070 - val_precision_7: 0.6249 - val_recall_7: 0.1762\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0809 - binary_accuracy: 0.9747 - auc_7: 0.9162 - precision_7: 0.6733 - recall_7: 0.2185 - val_loss: 0.1692 - val_binary_accuracy: 0.9728 - val_auc_7: 0.9172 - val_precision_7: 0.5648 - val_recall_7: 0.2640\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_7: 0.9224 - precision_7: 0.6726 - recall_7: 0.2363 - val_loss: 0.0891 - val_binary_accuracy: 0.9738 - val_auc_7: 0.9218 - val_precision_7: 0.6808 - val_recall_7: 0.1766\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0767 - binary_accuracy: 0.9753 - auc_7: 0.9279 - precision_7: 0.6801 - recall_7: 0.2502 - val_loss: 0.0821 - val_binary_accuracy: 0.9734 - val_auc_7: 0.9218 - val_precision_7: 0.5964 - val_recall_7: 0.2533\n","Score for fold 8: F1 score of 0.35557952165823464; loss of 0.08215028047561646; binary_accuracy of 97.34395146369934%\n","Training for fold 9 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1120 - binary_accuracy: 0.9672 - auc_8: 0.8200 - precision_8: 0.3118 - recall_8: 0.1233 - val_loss: 0.4633 - val_binary_accuracy: 0.9739 - val_auc_8: 0.8865 - val_precision_8: 0.6599 - val_recall_8: 0.1715\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0854 - binary_accuracy: 0.9742 - auc_8: 0.9010 - precision_8: 0.6702 - recall_8: 0.1900 - val_loss: 0.2721 - val_binary_accuracy: 0.9739 - val_auc_8: 0.9095 - val_precision_8: 0.7127 - val_recall_8: 0.1372\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0814 - binary_accuracy: 0.9746 - auc_8: 0.9150 - precision_8: 0.6756 - recall_8: 0.2140 - val_loss: 0.1775 - val_binary_accuracy: 0.9738 - val_auc_8: 0.9188 - val_precision_8: 0.5853 - val_recall_8: 0.2733\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0793 - binary_accuracy: 0.9749 - auc_8: 0.9211 - precision_8: 0.6750 - recall_8: 0.2336 - val_loss: 0.0807 - val_binary_accuracy: 0.9747 - val_auc_8: 0.9227 - val_precision_8: 0.6814 - val_recall_8: 0.2066\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0775 - binary_accuracy: 0.9752 - auc_8: 0.9254 - precision_8: 0.6773 - recall_8: 0.2488 - val_loss: 0.0841 - val_binary_accuracy: 0.9737 - val_auc_8: 0.9200 - val_precision_8: 0.5810 - val_recall_8: 0.2708\n","Score for fold 9: F1 score of 0.36945463145479585; loss of 0.0840747058391571; binary_accuracy of 97.3717987537384%\n","Training for fold 10 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1125 - binary_accuracy: 0.9667 - auc_9: 0.8176 - precision_9: 0.2979 - recall_9: 0.1238 - val_loss: 0.4475 - val_binary_accuracy: 0.9736 - val_auc_9: 0.8782 - val_precision_9: 0.7070 - val_recall_9: 0.1329\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0864 - binary_accuracy: 0.9742 - auc_9: 0.8961 - precision_9: 0.6720 - recall_9: 0.1845 - val_loss: 0.2686 - val_binary_accuracy: 0.9738 - val_auc_9: 0.9059 - val_precision_9: 0.6943 - val_recall_9: 0.1548\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0818 - binary_accuracy: 0.9746 - auc_9: 0.9131 - precision_9: 0.6724 - recall_9: 0.2141 - val_loss: 0.1593 - val_binary_accuracy: 0.9741 - val_auc_9: 0.9174 - val_precision_9: 0.6164 - val_recall_9: 0.2564\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0792 - binary_accuracy: 0.9749 - auc_9: 0.9214 - precision_9: 0.6734 - recall_9: 0.2335 - val_loss: 0.0876 - val_binary_accuracy: 0.9743 - val_auc_9: 0.9229 - val_precision_9: 0.6735 - val_recall_9: 0.2010\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0775 - binary_accuracy: 0.9752 - auc_9: 0.9260 - precision_9: 0.6761 - recall_9: 0.2474 - val_loss: 0.0801 - val_binary_accuracy: 0.9746 - val_auc_9: 0.9204 - val_precision_9: 0.7040 - val_recall_9: 0.1930\n","Score for fold 10: F1 score of 0.3029296940554657; loss of 0.08008356392383575; binary_accuracy of 97.45529890060425%\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  128\n","Training for fold 1 ...\n","Epoch 1/5\n","147/147 [==============================] - 4s 12ms/step - loss: 0.1123 - binary_accuracy: 0.9668 - auc_10: 0.8167 - precision_10: 0.2983 - recall_10: 0.1216 - val_loss: 0.4593 - val_binary_accuracy: 0.9735 - val_auc_10: 0.8806 - val_precision_10: 0.7048 - val_recall_10: 0.1359\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0861 - binary_accuracy: 0.9742 - auc_10: 0.8975 - precision_10: 0.6713 - recall_10: 0.1870 - val_loss: 0.2571 - val_binary_accuracy: 0.9738 - val_auc_10: 0.9090 - val_precision_10: 0.6843 - val_recall_10: 0.1670\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0817 - binary_accuracy: 0.9746 - auc_10: 0.9132 - precision_10: 0.6708 - recall_10: 0.2152 - val_loss: 0.1304 - val_binary_accuracy: 0.9735 - val_auc_10: 0.9168 - val_precision_10: 0.7078 - val_recall_10: 0.1387\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0792 - binary_accuracy: 0.9749 - auc_10: 0.9210 - precision_10: 0.6737 - recall_10: 0.2333 - val_loss: 0.0913 - val_binary_accuracy: 0.9731 - val_auc_10: 0.9186 - val_precision_10: 0.5826 - val_recall_10: 0.2413\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0776 - binary_accuracy: 0.9752 - auc_10: 0.9256 - precision_10: 0.6763 - recall_10: 0.2465 - val_loss: 0.0810 - val_binary_accuracy: 0.9741 - val_auc_10: 0.9220 - val_precision_10: 0.6711 - val_recall_10: 0.2010\n","Score for fold 1: F1 score of 0.3092921410569867; loss of 0.08101124316453934; binary_accuracy of 97.41311073303223%\n","Training for fold 2 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 16ms/step - loss: 0.1116 - binary_accuracy: 0.9672 - auc_11: 0.8208 - precision_11: 0.3155 - recall_11: 0.1267 - val_loss: 0.4534 - val_binary_accuracy: 0.9735 - val_auc_11: 0.8868 - val_precision_11: 0.7180 - val_recall_11: 0.1177\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0855 - binary_accuracy: 0.9742 - auc_11: 0.9002 - precision_11: 0.6712 - recall_11: 0.1895 - val_loss: 0.2889 - val_binary_accuracy: 0.9741 - val_auc_11: 0.9116 - val_precision_11: 0.6416 - val_recall_11: 0.2115\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0811 - binary_accuracy: 0.9747 - auc_11: 0.9155 - precision_11: 0.6728 - recall_11: 0.2178 - val_loss: 0.1615 - val_binary_accuracy: 0.9740 - val_auc_11: 0.9212 - val_precision_11: 0.5967 - val_recall_11: 0.2698\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0788 - binary_accuracy: 0.9750 - auc_11: 0.9226 - precision_11: 0.6756 - recall_11: 0.2371 - val_loss: 0.0805 - val_binary_accuracy: 0.9746 - val_auc_11: 0.9254 - val_precision_11: 0.6895 - val_recall_11: 0.2022\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0771 - binary_accuracy: 0.9752 - auc_11: 0.9268 - precision_11: 0.6774 - recall_11: 0.2524 - val_loss: 0.0829 - val_binary_accuracy: 0.9738 - val_auc_11: 0.9241 - val_precision_11: 0.6103 - val_recall_11: 0.2252\n","Score for fold 2: F1 score of 0.32901808825740486; loss of 0.08293482661247253; binary_accuracy of 97.37986326217651%\n","Training for fold 3 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 12ms/step - loss: 0.1137 - binary_accuracy: 0.9664 - auc_12: 0.8127 - precision_12: 0.2844 - recall_12: 0.1154 - val_loss: 0.4608 - val_binary_accuracy: 0.9739 - val_auc_12: 0.8716 - val_precision_12: 0.6885 - val_recall_12: 0.1389\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0869 - binary_accuracy: 0.9741 - auc_12: 0.8943 - precision_12: 0.6723 - recall_12: 0.1829 - val_loss: 0.2750 - val_binary_accuracy: 0.9745 - val_auc_12: 0.9076 - val_precision_12: 0.6716 - val_recall_12: 0.1889\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0818 - binary_accuracy: 0.9746 - auc_12: 0.9133 - precision_12: 0.6708 - recall_12: 0.2156 - val_loss: 0.1399 - val_binary_accuracy: 0.9748 - val_auc_12: 0.9192 - val_precision_12: 0.6600 - val_recall_12: 0.2223\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0792 - binary_accuracy: 0.9749 - auc_12: 0.9214 - precision_12: 0.6758 - recall_12: 0.2345 - val_loss: 0.0831 - val_binary_accuracy: 0.9747 - val_auc_12: 0.9206 - val_precision_12: 0.6998 - val_recall_12: 0.1804\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0774 - binary_accuracy: 0.9751 - auc_12: 0.9264 - precision_12: 0.6773 - recall_12: 0.2476 - val_loss: 0.0814 - val_binary_accuracy: 0.9742 - val_auc_12: 0.9156 - val_precision_12: 0.6835 - val_recall_12: 0.1607\n","Score for fold 3: F1 score of 0.2601561131711289; loss of 0.08137237280607224; binary_accuracy of 97.42370843887329%\n","Training for fold 4 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1119 - binary_accuracy: 0.9669 - auc_13: 0.8193 - precision_13: 0.3026 - recall_13: 0.1219 - val_loss: 0.4623 - val_binary_accuracy: 0.9737 - val_auc_13: 0.8792 - val_precision_13: 0.6749 - val_recall_13: 0.1534\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0862 - binary_accuracy: 0.9742 - auc_13: 0.8971 - precision_13: 0.6711 - recall_13: 0.1872 - val_loss: 0.2806 - val_binary_accuracy: 0.9738 - val_auc_13: 0.9056 - val_precision_13: 0.6920 - val_recall_13: 0.1468\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0815 - binary_accuracy: 0.9746 - auc_13: 0.9141 - precision_13: 0.6718 - recall_13: 0.2154 - val_loss: 0.1318 - val_binary_accuracy: 0.9743 - val_auc_13: 0.9190 - val_precision_13: 0.6595 - val_recall_13: 0.2082\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0789 - binary_accuracy: 0.9749 - auc_13: 0.9223 - precision_13: 0.6737 - recall_13: 0.2358 - val_loss: 0.0956 - val_binary_accuracy: 0.9743 - val_auc_13: 0.9222 - val_precision_13: 0.6130 - val_recall_13: 0.2694\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0772 - binary_accuracy: 0.9752 - auc_13: 0.9268 - precision_13: 0.6750 - recall_13: 0.2502 - val_loss: 0.0808 - val_binary_accuracy: 0.9743 - val_auc_13: 0.9246 - val_precision_13: 0.6085 - val_recall_13: 0.2809\n","Score for fold 4: F1 score of 0.38440232921793316; loss of 0.08080260455608368; binary_accuracy of 97.43165373802185%\n","Training for fold 5 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1129 - binary_accuracy: 0.9668 - auc_14: 0.8159 - precision_14: 0.2971 - recall_14: 0.1185 - val_loss: 0.4721 - val_binary_accuracy: 0.9738 - val_auc_14: 0.8768 - val_precision_14: 0.6842 - val_recall_14: 0.1482\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0867 - binary_accuracy: 0.9742 - auc_14: 0.8947 - precision_14: 0.6726 - recall_14: 0.1855 - val_loss: 0.3030 - val_binary_accuracy: 0.9740 - val_auc_14: 0.9081 - val_precision_14: 0.6160 - val_recall_14: 0.2325\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0820 - binary_accuracy: 0.9746 - auc_14: 0.9126 - precision_14: 0.6708 - recall_14: 0.2154 - val_loss: 0.1299 - val_binary_accuracy: 0.9740 - val_auc_14: 0.9164 - val_precision_14: 0.6182 - val_recall_14: 0.2262\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0792 - binary_accuracy: 0.9749 - auc_14: 0.9212 - precision_14: 0.6740 - recall_14: 0.2340 - val_loss: 0.0973 - val_binary_accuracy: 0.9744 - val_auc_14: 0.9224 - val_precision_14: 0.6096 - val_recall_14: 0.2773\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_14: 0.9247 - precision_14: 0.6751 - recall_14: 0.2459 - val_loss: 0.0856 - val_binary_accuracy: 0.9736 - val_auc_14: 0.9217 - val_precision_14: 0.5686 - val_recall_14: 0.2993\n","Score for fold 5: F1 score of 0.39219075739209325; loss of 0.08563639223575592; binary_accuracy of 97.35873937606812%\n","Training for fold 6 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 12ms/step - loss: 0.1122 - binary_accuracy: 0.9669 - auc_15: 0.8195 - precision_15: 0.3060 - recall_15: 0.1251 - val_loss: 0.4824 - val_binary_accuracy: 0.9740 - val_auc_15: 0.8822 - val_precision_15: 0.6674 - val_recall_15: 0.1642\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0874 - binary_accuracy: 0.9741 - auc_15: 0.8924 - precision_15: 0.6681 - recall_15: 0.1824 - val_loss: 0.2875 - val_binary_accuracy: 0.9745 - val_auc_15: 0.9083 - val_precision_15: 0.6777 - val_recall_15: 0.1864\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0822 - binary_accuracy: 0.9746 - auc_15: 0.9125 - precision_15: 0.6735 - recall_15: 0.2116 - val_loss: 0.1443 - val_binary_accuracy: 0.9742 - val_auc_15: 0.9162 - val_precision_15: 0.6023 - val_recall_15: 0.2637\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0796 - binary_accuracy: 0.9748 - auc_15: 0.9203 - precision_15: 0.6734 - recall_15: 0.2312 - val_loss: 0.0889 - val_binary_accuracy: 0.9745 - val_auc_15: 0.9214 - val_precision_15: 0.6112 - val_recall_15: 0.2680\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_15: 0.9252 - precision_15: 0.6737 - recall_15: 0.2448 - val_loss: 0.0819 - val_binary_accuracy: 0.9743 - val_auc_15: 0.9247 - val_precision_15: 0.5888 - val_recall_15: 0.3022\n","Score for fold 6: F1 score of 0.3993904596137415; loss of 0.08185695856809616; binary_accuracy of 97.42810726165771%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 16 filters, with a kernel size of 128 and has an F1 score of 0.3993904596137415\n","Training for fold 7 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1130 - binary_accuracy: 0.9667 - auc_16: 0.8134 - precision_16: 0.2918 - recall_16: 0.1177 - val_loss: 0.4710 - val_binary_accuracy: 0.9736 - val_auc_16: 0.8738 - val_precision_16: 0.6677 - val_recall_16: 0.1637\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0867 - binary_accuracy: 0.9742 - auc_16: 0.8941 - precision_16: 0.6724 - recall_16: 0.1834 - val_loss: 0.2756 - val_binary_accuracy: 0.9741 - val_auc_16: 0.9086 - val_precision_16: 0.6804 - val_recall_16: 0.1880\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0815 - binary_accuracy: 0.9747 - auc_16: 0.9142 - precision_16: 0.6740 - recall_16: 0.2153 - val_loss: 0.1397 - val_binary_accuracy: 0.9736 - val_auc_16: 0.9167 - val_precision_16: 0.5889 - val_recall_16: 0.2649\n","Epoch 4/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0791 - binary_accuracy: 0.9749 - auc_16: 0.9215 - precision_16: 0.6718 - recall_16: 0.2344 - val_loss: 0.0925 - val_binary_accuracy: 0.9743 - val_auc_16: 0.9223 - val_precision_16: 0.6675 - val_recall_16: 0.2126\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0772 - binary_accuracy: 0.9752 - auc_16: 0.9266 - precision_16: 0.6771 - recall_16: 0.2483 - val_loss: 0.0843 - val_binary_accuracy: 0.9738 - val_auc_16: 0.9265 - val_precision_16: 0.5821 - val_recall_16: 0.3168\n","Score for fold 7: F1 score of 0.41026616253070475; loss of 0.08432292193174362; binary_accuracy of 97.38355875015259%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 16 filters, with a kernel size of 128 and has an F1 score of 0.41026616253070475\n","Training for fold 8 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1115 - binary_accuracy: 0.9672 - auc_17: 0.8206 - precision_17: 0.3144 - recall_17: 0.1257 - val_loss: 0.4631 - val_binary_accuracy: 0.9735 - val_auc_17: 0.8841 - val_precision_17: 0.6997 - val_recall_17: 0.1273\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0859 - binary_accuracy: 0.9742 - auc_17: 0.8990 - precision_17: 0.6707 - recall_17: 0.1868 - val_loss: 0.3084 - val_binary_accuracy: 0.9740 - val_auc_17: 0.9101 - val_precision_17: 0.6279 - val_recall_17: 0.2224\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0815 - binary_accuracy: 0.9746 - auc_17: 0.9143 - precision_17: 0.6728 - recall_17: 0.2157 - val_loss: 0.1527 - val_binary_accuracy: 0.9737 - val_auc_17: 0.9142 - val_precision_17: 0.6094 - val_recall_17: 0.2230\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0791 - binary_accuracy: 0.9749 - auc_17: 0.9216 - precision_17: 0.6732 - recall_17: 0.2340 - val_loss: 0.0825 - val_binary_accuracy: 0.9740 - val_auc_17: 0.9166 - val_precision_17: 0.7266 - val_recall_17: 0.1444\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0778 - binary_accuracy: 0.9751 - auc_17: 0.9248 - precision_17: 0.6747 - recall_17: 0.2472 - val_loss: 0.0786 - val_binary_accuracy: 0.9749 - val_auc_17: 0.9255 - val_precision_17: 0.6775 - val_recall_17: 0.2327\n","Score for fold 8: F1 score of 0.3463766909625812; loss of 0.07864927500486374; binary_accuracy of 97.49367833137512%\n","Training for fold 9 ...\n","Epoch 1/5\n","147/147 [==============================] - 4s 12ms/step - loss: 0.1113 - binary_accuracy: 0.9674 - auc_18: 0.8210 - precision_18: 0.3196 - recall_18: 0.1252 - val_loss: 0.4554 - val_binary_accuracy: 0.9737 - val_auc_18: 0.8817 - val_precision_18: 0.6725 - val_recall_18: 0.1510\n","Epoch 2/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0858 - binary_accuracy: 0.9742 - auc_18: 0.8993 - precision_18: 0.6703 - recall_18: 0.1872 - val_loss: 0.2859 - val_binary_accuracy: 0.9740 - val_auc_18: 0.9112 - val_precision_18: 0.6175 - val_recall_18: 0.2336\n","Epoch 3/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0810 - binary_accuracy: 0.9747 - auc_18: 0.9159 - precision_18: 0.6716 - recall_18: 0.2186 - val_loss: 0.1370 - val_binary_accuracy: 0.9740 - val_auc_18: 0.9176 - val_precision_18: 0.6478 - val_recall_18: 0.1939\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0786 - binary_accuracy: 0.9750 - auc_18: 0.9230 - precision_18: 0.6753 - recall_18: 0.2374 - val_loss: 0.0812 - val_binary_accuracy: 0.9745 - val_auc_18: 0.9196 - val_precision_18: 0.6961 - val_recall_18: 0.1883\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0770 - binary_accuracy: 0.9753 - auc_18: 0.9270 - precision_18: 0.6782 - recall_18: 0.2521 - val_loss: 0.0794 - val_binary_accuracy: 0.9746 - val_auc_18: 0.9258 - val_precision_18: 0.6318 - val_recall_18: 0.2649\n","Score for fold 9: F1 score of 0.3733184965493241; loss of 0.07941091805696487; binary_accuracy of 97.46033549308777%\n","Training for fold 10 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 11ms/step - loss: 0.1126 - binary_accuracy: 0.9670 - auc_19: 0.8148 - precision_19: 0.3020 - recall_19: 0.1190 - val_loss: 0.4632 - val_binary_accuracy: 0.9736 - val_auc_19: 0.8717 - val_precision_19: 0.7065 - val_recall_19: 0.1324\n","Epoch 2/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0865 - binary_accuracy: 0.9742 - auc_19: 0.8949 - precision_19: 0.6719 - recall_19: 0.1857 - val_loss: 0.2804 - val_binary_accuracy: 0.9743 - val_auc_19: 0.9079 - val_precision_19: 0.6852 - val_recall_19: 0.1872\n","Epoch 3/5\n","147/147 [==============================] - 1s 8ms/step - loss: 0.0814 - binary_accuracy: 0.9746 - auc_19: 0.9146 - precision_19: 0.6722 - recall_19: 0.2168 - val_loss: 0.1361 - val_binary_accuracy: 0.9747 - val_auc_19: 0.9207 - val_precision_19: 0.6704 - val_recall_19: 0.2250\n","Epoch 4/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0788 - binary_accuracy: 0.9750 - auc_19: 0.9223 - precision_19: 0.6748 - recall_19: 0.2368 - val_loss: 0.0839 - val_binary_accuracy: 0.9746 - val_auc_19: 0.9241 - val_precision_19: 0.7006 - val_recall_19: 0.1936\n","Epoch 5/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0769 - binary_accuracy: 0.9753 - auc_19: 0.9274 - precision_19: 0.6786 - recall_19: 0.2513 - val_loss: 0.0797 - val_binary_accuracy: 0.9744 - val_auc_19: 0.9247 - val_precision_19: 0.6753 - val_recall_19: 0.2023\n","Score for fold 10: F1 score of 0.3113571811917102; loss of 0.07970583438873291; binary_accuracy of 97.44237065315247%\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  256\n","Training for fold 1 ...\n","Epoch 1/5\n","147/147 [==============================] - 5s 16ms/step - loss: 0.1127 - binary_accuracy: 0.9670 - auc_20: 0.8179 - precision_20: 0.3075 - recall_20: 0.1249 - val_loss: 0.4596 - val_binary_accuracy: 0.9739 - val_auc_20: 0.8829 - val_precision_20: 0.6582 - val_recall_20: 0.1606\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0862 - binary_accuracy: 0.9742 - auc_20: 0.8979 - precision_20: 0.6702 - recall_20: 0.1863 - val_loss: 0.2876 - val_binary_accuracy: 0.9741 - val_auc_20: 0.9099 - val_precision_20: 0.6055 - val_recall_20: 0.2417\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0815 - binary_accuracy: 0.9746 - auc_20: 0.9145 - precision_20: 0.6682 - recall_20: 0.2187 - val_loss: 0.1340 - val_binary_accuracy: 0.9743 - val_auc_20: 0.9163 - val_precision_20: 0.6744 - val_recall_20: 0.1759\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0791 - binary_accuracy: 0.9749 - auc_20: 0.9219 - precision_20: 0.6731 - recall_20: 0.2356 - val_loss: 0.1017 - val_binary_accuracy: 0.9737 - val_auc_20: 0.9195 - val_precision_20: 0.5781 - val_recall_20: 0.2663\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0775 - binary_accuracy: 0.9751 - auc_20: 0.9259 - precision_20: 0.6754 - recall_20: 0.2491 - val_loss: 0.0784 - val_binary_accuracy: 0.9749 - val_auc_20: 0.9226 - val_precision_20: 0.6369 - val_recall_20: 0.2628\n","Score for fold 1: F1 score of 0.3721185176347611; loss of 0.07837584614753723; binary_accuracy of 97.49054908752441%\n","Training for fold 2 ...\n","Epoch 1/5\n","147/147 [==============================] - 8s 14ms/step - loss: 0.1134 - binary_accuracy: 0.9668 - auc_21: 0.8128 - precision_21: 0.2904 - recall_21: 0.1157 - val_loss: 0.4585 - val_binary_accuracy: 0.9735 - val_auc_21: 0.8741 - val_precision_21: 0.6740 - val_recall_21: 0.1567\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0867 - binary_accuracy: 0.9742 - auc_21: 0.8943 - precision_21: 0.6716 - recall_21: 0.1836 - val_loss: 0.2978 - val_binary_accuracy: 0.9736 - val_auc_21: 0.9039 - val_precision_21: 0.6132 - val_recall_21: 0.2369\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0819 - binary_accuracy: 0.9746 - auc_21: 0.9130 - precision_21: 0.6699 - recall_21: 0.2133 - val_loss: 0.1588 - val_binary_accuracy: 0.9735 - val_auc_21: 0.9147 - val_precision_21: 0.5949 - val_recall_21: 0.2542\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0793 - binary_accuracy: 0.9749 - auc_21: 0.9209 - precision_21: 0.6715 - recall_21: 0.2325 - val_loss: 0.0874 - val_binary_accuracy: 0.9742 - val_auc_21: 0.9213 - val_precision_21: 0.6900 - val_recall_21: 0.1947\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0773 - binary_accuracy: 0.9752 - auc_21: 0.9264 - precision_21: 0.6777 - recall_21: 0.2467 - val_loss: 0.1033 - val_binary_accuracy: 0.9718 - val_auc_21: 0.9243 - val_precision_21: 0.5161 - val_recall_21: 0.3729\n","Score for fold 2: F1 score of 0.43298306650827967; loss of 0.10333667695522308; binary_accuracy of 97.17952609062195%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 16 filters, with a kernel size of 256 and has an F1 score of 0.43298306650827967\n","Training for fold 3 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1129 - binary_accuracy: 0.9671 - auc_22: 0.8165 - precision_22: 0.3057 - recall_22: 0.1208 - val_loss: 0.4544 - val_binary_accuracy: 0.9739 - val_auc_22: 0.8792 - val_precision_22: 0.7030 - val_recall_22: 0.1362\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0863 - binary_accuracy: 0.9741 - auc_22: 0.8971 - precision_22: 0.6693 - recall_22: 0.1863 - val_loss: 0.2816 - val_binary_accuracy: 0.9743 - val_auc_22: 0.9072 - val_precision_22: 0.6309 - val_recall_22: 0.2186\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0815 - binary_accuracy: 0.9746 - auc_22: 0.9148 - precision_22: 0.6696 - recall_22: 0.2173 - val_loss: 0.1246 - val_binary_accuracy: 0.9745 - val_auc_22: 0.9189 - val_precision_22: 0.6336 - val_recall_22: 0.2338\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0789 - binary_accuracy: 0.9749 - auc_22: 0.9224 - precision_22: 0.6722 - recall_22: 0.2368 - val_loss: 0.0813 - val_binary_accuracy: 0.9743 - val_auc_22: 0.9224 - val_precision_22: 0.7000 - val_recall_22: 0.1626\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0774 - binary_accuracy: 0.9751 - auc_22: 0.9262 - precision_22: 0.6760 - recall_22: 0.2489 - val_loss: 0.0790 - val_binary_accuracy: 0.9749 - val_auc_22: 0.9221 - val_precision_22: 0.6377 - val_recall_22: 0.2586\n","Score for fold 3: F1 score of 0.3680076011459725; loss of 0.07902350276708603; binary_accuracy of 97.48635292053223%\n","Training for fold 4 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1118 - binary_accuracy: 0.9673 - auc_23: 0.8196 - precision_23: 0.3159 - recall_23: 0.1243 - val_loss: 0.4495 - val_binary_accuracy: 0.9738 - val_auc_23: 0.8858 - val_precision_23: 0.6618 - val_recall_23: 0.1701\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0857 - binary_accuracy: 0.9742 - auc_23: 0.8995 - precision_23: 0.6699 - recall_23: 0.1894 - val_loss: 0.2726 - val_binary_accuracy: 0.9740 - val_auc_23: 0.9120 - val_precision_23: 0.6978 - val_recall_23: 0.1614\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0812 - binary_accuracy: 0.9747 - auc_23: 0.9152 - precision_23: 0.6706 - recall_23: 0.2195 - val_loss: 0.1427 - val_binary_accuracy: 0.9740 - val_auc_23: 0.9210 - val_precision_23: 0.6010 - val_recall_23: 0.2656\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_23: 0.9233 - precision_23: 0.6733 - recall_23: 0.2392 - val_loss: 0.1366 - val_binary_accuracy: 0.9664 - val_auc_23: 0.9142 - val_precision_23: 0.4043 - val_recall_23: 0.3685\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0785 - binary_accuracy: 0.9749 - auc_23: 0.9232 - precision_23: 0.6625 - recall_23: 0.2478 - val_loss: 0.0789 - val_binary_accuracy: 0.9747 - val_auc_23: 0.9235 - val_precision_23: 0.6512 - val_recall_23: 0.2476\n","Score for fold 4: F1 score of 0.3588044106212519; loss of 0.07888152450323105; binary_accuracy of 97.47063517570496%\n","Training for fold 5 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 15ms/step - loss: 0.1140 - binary_accuracy: 0.9667 - auc_24: 0.8122 - precision_24: 0.2929 - recall_24: 0.1163 - val_loss: 0.4646 - val_binary_accuracy: 0.9741 - val_auc_24: 0.8735 - val_precision_24: 0.6874 - val_recall_24: 0.1529\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0869 - binary_accuracy: 0.9741 - auc_24: 0.8942 - precision_24: 0.6708 - recall_24: 0.1847 - val_loss: 0.3010 - val_binary_accuracy: 0.9745 - val_auc_24: 0.9097 - val_precision_24: 0.6265 - val_recall_24: 0.2386\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0818 - binary_accuracy: 0.9746 - auc_24: 0.9137 - precision_24: 0.6711 - recall_24: 0.2155 - val_loss: 0.1315 - val_binary_accuracy: 0.9744 - val_auc_24: 0.9193 - val_precision_24: 0.6877 - val_recall_24: 0.1679\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0790 - binary_accuracy: 0.9749 - auc_24: 0.9220 - precision_24: 0.6747 - recall_24: 0.2346 - val_loss: 0.0796 - val_binary_accuracy: 0.9748 - val_auc_24: 0.9239 - val_precision_24: 0.7246 - val_recall_24: 0.1722\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0772 - binary_accuracy: 0.9752 - auc_24: 0.9268 - precision_24: 0.6771 - recall_24: 0.2496 - val_loss: 0.0798 - val_binary_accuracy: 0.9742 - val_auc_24: 0.9216 - val_precision_24: 0.6270 - val_recall_24: 0.2085\n","Score for fold 5: F1 score of 0.312911232266746; loss of 0.07976233959197998; binary_accuracy of 97.41675853729248%\n","Training for fold 6 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1143 - binary_accuracy: 0.9664 - auc_25: 0.8117 - precision_25: 0.2844 - recall_25: 0.1168 - val_loss: 0.4453 - val_binary_accuracy: 0.9737 - val_auc_25: 0.8746 - val_precision_25: 0.7212 - val_recall_25: 0.1230\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0868 - binary_accuracy: 0.9741 - auc_25: 0.8948 - precision_25: 0.6695 - recall_25: 0.1832 - val_loss: 0.2756 - val_binary_accuracy: 0.9738 - val_auc_25: 0.9063 - val_precision_25: 0.6129 - val_recall_25: 0.2128\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0817 - binary_accuracy: 0.9746 - auc_25: 0.9139 - precision_25: 0.6716 - recall_25: 0.2133 - val_loss: 0.1102 - val_binary_accuracy: 0.9743 - val_auc_25: 0.9183 - val_precision_25: 0.7331 - val_recall_25: 0.1526\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0795 - binary_accuracy: 0.9749 - auc_25: 0.9201 - precision_25: 0.6728 - recall_25: 0.2320 - val_loss: 0.0892 - val_binary_accuracy: 0.9748 - val_auc_25: 0.9240 - val_precision_25: 0.6598 - val_recall_25: 0.2364\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0774 - binary_accuracy: 0.9752 - auc_25: 0.9262 - precision_25: 0.6778 - recall_25: 0.2471 - val_loss: 0.0796 - val_binary_accuracy: 0.9746 - val_auc_25: 0.9217 - val_precision_25: 0.6554 - val_recall_25: 0.2240\n","Score for fold 6: F1 score of 0.3339149435314313; loss of 0.0796247273683548; binary_accuracy of 97.45685458183289%\n","Training for fold 7 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1129 - binary_accuracy: 0.9670 - auc_26: 0.8158 - precision_26: 0.3017 - recall_26: 0.1191 - val_loss: 0.4454 - val_binary_accuracy: 0.9737 - val_auc_26: 0.8768 - val_precision_26: 0.6679 - val_recall_26: 0.1623\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0864 - binary_accuracy: 0.9742 - auc_26: 0.8962 - precision_26: 0.6710 - recall_26: 0.1855 - val_loss: 0.2542 - val_binary_accuracy: 0.9741 - val_auc_26: 0.9082 - val_precision_26: 0.7078 - val_recall_26: 0.1647\n","Epoch 3/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0813 - binary_accuracy: 0.9747 - auc_26: 0.9147 - precision_26: 0.6720 - recall_26: 0.2169 - val_loss: 0.1469 - val_binary_accuracy: 0.9742 - val_auc_26: 0.9189 - val_precision_26: 0.6995 - val_recall_26: 0.1726\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_26: 0.9227 - precision_26: 0.6748 - recall_26: 0.2349 - val_loss: 0.0871 - val_binary_accuracy: 0.9745 - val_auc_26: 0.9228 - val_precision_26: 0.6640 - val_recall_26: 0.2193\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0768 - binary_accuracy: 0.9752 - auc_26: 0.9276 - precision_26: 0.6770 - recall_26: 0.2511 - val_loss: 0.0862 - val_binary_accuracy: 0.9738 - val_auc_26: 0.9206 - val_precision_26: 0.5962 - val_recall_26: 0.2661\n","Score for fold 7: F1 score of 0.36797210165904126; loss of 0.08619700372219086; binary_accuracy of 97.38324880599976%\n","Training for fold 8 ...\n","Epoch 1/5\n","147/147 [==============================] - 5s 14ms/step - loss: 0.1127 - binary_accuracy: 0.9668 - auc_27: 0.8173 - precision_27: 0.2989 - recall_27: 0.1209 - val_loss: 0.4609 - val_binary_accuracy: 0.9738 - val_auc_27: 0.8826 - val_precision_27: 0.6268 - val_recall_27: 0.1944\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0863 - binary_accuracy: 0.9742 - auc_27: 0.8970 - precision_27: 0.6674 - recall_27: 0.1890 - val_loss: 0.2591 - val_binary_accuracy: 0.9741 - val_auc_27: 0.9078 - val_precision_27: 0.6245 - val_recall_27: 0.2205\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0815 - binary_accuracy: 0.9746 - auc_27: 0.9142 - precision_27: 0.6717 - recall_27: 0.2160 - val_loss: 0.1472 - val_binary_accuracy: 0.9739 - val_auc_27: 0.9193 - val_precision_27: 0.5939 - val_recall_27: 0.2572\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0790 - binary_accuracy: 0.9749 - auc_27: 0.9219 - precision_27: 0.6736 - recall_27: 0.2356 - val_loss: 0.0821 - val_binary_accuracy: 0.9745 - val_auc_27: 0.9238 - val_precision_27: 0.7240 - val_recall_27: 0.1635\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0773 - binary_accuracy: 0.9752 - auc_27: 0.9265 - precision_27: 0.6776 - recall_27: 0.2489 - val_loss: 0.0830 - val_binary_accuracy: 0.9743 - val_auc_27: 0.9130 - val_precision_27: 0.6970 - val_recall_27: 0.1676\n","Score for fold 8: F1 score of 0.27021427549566746; loss of 0.08297469466924667; binary_accuracy of 97.42735624313354%\n","Training for fold 9 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 15ms/step - loss: 0.1129 - binary_accuracy: 0.9670 - auc_28: 0.8160 - precision_28: 0.3018 - recall_28: 0.1192 - val_loss: 0.4489 - val_binary_accuracy: 0.9736 - val_auc_28: 0.8763 - val_precision_28: 0.7096 - val_recall_28: 0.1341\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0864 - binary_accuracy: 0.9742 - auc_28: 0.8959 - precision_28: 0.6705 - recall_28: 0.1860 - val_loss: 0.2761 - val_binary_accuracy: 0.9741 - val_auc_28: 0.9088 - val_precision_28: 0.6726 - val_recall_28: 0.1877\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0814 - binary_accuracy: 0.9746 - auc_28: 0.9147 - precision_28: 0.6705 - recall_28: 0.2177 - val_loss: 0.1344 - val_binary_accuracy: 0.9742 - val_auc_28: 0.9187 - val_precision_28: 0.6742 - val_recall_28: 0.1921\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_28: 0.9224 - precision_28: 0.6738 - recall_28: 0.2371 - val_loss: 0.1089 - val_binary_accuracy: 0.9729 - val_auc_28: 0.9229 - val_precision_28: 0.5457 - val_recall_28: 0.3359\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0774 - binary_accuracy: 0.9752 - auc_28: 0.9263 - precision_28: 0.6724 - recall_28: 0.2506 - val_loss: 0.0809 - val_binary_accuracy: 0.9743 - val_auc_28: 0.9235 - val_precision_28: 0.6136 - val_recall_28: 0.2776\n","Score for fold 9: F1 score of 0.3822931268768298; loss of 0.0809289887547493; binary_accuracy of 97.42771983146667%\n","Training for fold 10 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1126 - binary_accuracy: 0.9671 - auc_29: 0.8183 - precision_29: 0.3042 - recall_29: 0.1212 - val_loss: 0.4853 - val_binary_accuracy: 0.9735 - val_auc_29: 0.8804 - val_precision_29: 0.6314 - val_recall_29: 0.1931\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0874 - binary_accuracy: 0.9741 - auc_29: 0.8920 - precision_29: 0.6673 - recall_29: 0.1808 - val_loss: 0.2812 - val_binary_accuracy: 0.9737 - val_auc_29: 0.9070 - val_precision_29: 0.7100 - val_recall_29: 0.1476\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0821 - binary_accuracy: 0.9746 - auc_29: 0.9124 - precision_29: 0.6733 - recall_29: 0.2096 - val_loss: 0.1320 - val_binary_accuracy: 0.9741 - val_auc_29: 0.9177 - val_precision_29: 0.6675 - val_recall_29: 0.1996\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0794 - binary_accuracy: 0.9749 - auc_29: 0.9206 - precision_29: 0.6731 - recall_29: 0.2314 - val_loss: 0.0945 - val_binary_accuracy: 0.9741 - val_auc_29: 0.9227 - val_precision_29: 0.6147 - val_recall_29: 0.2676\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0774 - binary_accuracy: 0.9752 - auc_29: 0.9263 - precision_29: 0.6773 - recall_29: 0.2467 - val_loss: 0.0809 - val_binary_accuracy: 0.9743 - val_auc_29: 0.9216 - val_precision_29: 0.6213 - val_recall_29: 0.2807\n","Score for fold 10: F1 score of 0.3867183867905613; loss of 0.0808509960770607; binary_accuracy of 97.43338823318481%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  64\n","Training for fold 1 ...\n","Epoch 1/5\n","147/147 [==============================] - 5s 13ms/step - loss: 0.1100 - binary_accuracy: 0.9673 - auc_30: 0.8239 - precision_30: 0.3222 - recall_30: 0.1303 - val_loss: 0.4701 - val_binary_accuracy: 0.9739 - val_auc_30: 0.8825 - val_precision_30: 0.6551 - val_recall_30: 0.1592\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0854 - binary_accuracy: 0.9743 - auc_30: 0.8997 - precision_30: 0.6702 - recall_30: 0.1957 - val_loss: 0.2793 - val_binary_accuracy: 0.9745 - val_auc_30: 0.9128 - val_precision_30: 0.6304 - val_recall_30: 0.2350\n","Epoch 3/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0809 - binary_accuracy: 0.9747 - auc_30: 0.9159 - precision_30: 0.6715 - recall_30: 0.2248 - val_loss: 0.2170 - val_binary_accuracy: 0.9657 - val_auc_30: 0.8941 - val_precision_30: 0.3592 - val_recall_30: 0.2764\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0801 - binary_accuracy: 0.9748 - auc_30: 0.9183 - precision_30: 0.6645 - recall_30: 0.2362 - val_loss: 0.0955 - val_binary_accuracy: 0.9746 - val_auc_30: 0.9241 - val_precision_30: 0.6071 - val_recall_30: 0.2840\n","Epoch 5/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0769 - binary_accuracy: 0.9752 - auc_30: 0.9274 - precision_30: 0.6781 - recall_30: 0.2527 - val_loss: 0.0790 - val_binary_accuracy: 0.9750 - val_auc_30: 0.9263 - val_precision_30: 0.6307 - val_recall_30: 0.2734\n","Score for fold 1: F1 score of 0.38141111903079183; loss of 0.07902435958385468; binary_accuracy of 97.49754667282104%\n","Training for fold 2 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1092 - binary_accuracy: 0.9672 - auc_31: 0.8267 - precision_31: 0.3190 - recall_31: 0.1336 - val_loss: 0.4683 - val_binary_accuracy: 0.9737 - val_auc_31: 0.8897 - val_precision_31: 0.6455 - val_recall_31: 0.1929\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0844 - binary_accuracy: 0.9744 - auc_31: 0.9031 - precision_31: 0.6703 - recall_31: 0.2001 - val_loss: 0.2528 - val_binary_accuracy: 0.9740 - val_auc_31: 0.9120 - val_precision_31: 0.6378 - val_recall_31: 0.2326\n","Epoch 3/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0803 - binary_accuracy: 0.9748 - auc_31: 0.9173 - precision_31: 0.6711 - recall_31: 0.2281 - val_loss: 0.1181 - val_binary_accuracy: 0.9743 - val_auc_31: 0.9216 - val_precision_31: 0.6906 - val_recall_31: 0.1996\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0780 - binary_accuracy: 0.9751 - auc_31: 0.9240 - precision_31: 0.6759 - recall_31: 0.2446 - val_loss: 0.1006 - val_binary_accuracy: 0.9726 - val_auc_31: 0.9194 - val_precision_31: 0.5450 - val_recall_31: 0.3070\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_31: 0.9283 - precision_31: 0.6761 - recall_31: 0.2572 - val_loss: 0.0793 - val_binary_accuracy: 0.9746 - val_auc_31: 0.9265 - val_precision_31: 0.6569 - val_recall_31: 0.2524\n","Score for fold 2: F1 score of 0.3647345908271446; loss of 0.07933004945516586; binary_accuracy of 97.46280908584595%\n","Training for fold 3 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1099 - binary_accuracy: 0.9668 - auc_32: 0.8247 - precision_32: 0.3056 - recall_32: 0.1295 - val_loss: 0.4739 - val_binary_accuracy: 0.9740 - val_auc_32: 0.8843 - val_precision_32: 0.6431 - val_recall_32: 0.1961\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0847 - binary_accuracy: 0.9743 - auc_32: 0.9022 - precision_32: 0.6691 - recall_32: 0.1994 - val_loss: 0.3148 - val_binary_accuracy: 0.9733 - val_auc_32: 0.9051 - val_precision_32: 0.5808 - val_recall_32: 0.2140\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0810 - binary_accuracy: 0.9747 - auc_32: 0.9156 - precision_32: 0.6683 - recall_32: 0.2250 - val_loss: 0.1387 - val_binary_accuracy: 0.9746 - val_auc_32: 0.9200 - val_precision_32: 0.6581 - val_recall_32: 0.2244\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0782 - binary_accuracy: 0.9751 - auc_32: 0.9242 - precision_32: 0.6755 - recall_32: 0.2422 - val_loss: 0.0851 - val_binary_accuracy: 0.9748 - val_auc_32: 0.9236 - val_precision_32: 0.6427 - val_recall_32: 0.2525\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_32: 0.9286 - precision_32: 0.6786 - recall_32: 0.2574 - val_loss: 0.0795 - val_binary_accuracy: 0.9747 - val_auc_32: 0.9224 - val_precision_32: 0.6546 - val_recall_32: 0.2306\n","Score for fold 3: F1 score of 0.34104155213696163; loss of 0.07949066907167435; binary_accuracy of 97.46654629707336%\n","Training for fold 4 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1092 - binary_accuracy: 0.9670 - auc_33: 0.8302 - precision_33: 0.3182 - recall_33: 0.1360 - val_loss: 0.4612 - val_binary_accuracy: 0.9736 - val_auc_33: 0.8872 - val_precision_33: 0.6005 - val_recall_33: 0.2196\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0853 - binary_accuracy: 0.9742 - auc_33: 0.9012 - precision_33: 0.6649 - recall_33: 0.1928 - val_loss: 0.2914 - val_binary_accuracy: 0.9743 - val_auc_33: 0.9129 - val_precision_33: 0.6517 - val_recall_33: 0.2120\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0810 - binary_accuracy: 0.9747 - auc_33: 0.9157 - precision_33: 0.6710 - recall_33: 0.2211 - val_loss: 0.1227 - val_binary_accuracy: 0.9739 - val_auc_33: 0.9185 - val_precision_33: 0.7237 - val_recall_33: 0.1377\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0789 - binary_accuracy: 0.9749 - auc_33: 0.9218 - precision_33: 0.6745 - recall_33: 0.2354 - val_loss: 0.0886 - val_binary_accuracy: 0.9745 - val_auc_33: 0.9253 - val_precision_33: 0.6215 - val_recall_33: 0.2699\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_33: 0.9282 - precision_33: 0.6779 - recall_33: 0.2540 - val_loss: 0.0806 - val_binary_accuracy: 0.9742 - val_auc_33: 0.9253 - val_precision_33: 0.6206 - val_recall_33: 0.2466\n","Score for fold 4: F1 score of 0.3529679329032876; loss of 0.08061889559030533; binary_accuracy of 97.42050170898438%\n","Training for fold 5 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1093 - binary_accuracy: 0.9672 - auc_34: 0.8269 - precision_34: 0.3172 - recall_34: 0.1301 - val_loss: 0.4259 - val_binary_accuracy: 0.9733 - val_auc_34: 0.8813 - val_precision_34: 0.6749 - val_recall_34: 0.1513\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0848 - binary_accuracy: 0.9743 - auc_34: 0.9016 - precision_34: 0.6684 - recall_34: 0.1957 - val_loss: 0.2910 - val_binary_accuracy: 0.9736 - val_auc_34: 0.9090 - val_precision_34: 0.6486 - val_recall_34: 0.1934\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0804 - binary_accuracy: 0.9748 - auc_34: 0.9173 - precision_34: 0.6729 - recall_34: 0.2241 - val_loss: 0.1404 - val_binary_accuracy: 0.9742 - val_auc_34: 0.9191 - val_precision_34: 0.6499 - val_recall_34: 0.2341\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0780 - binary_accuracy: 0.9751 - auc_34: 0.9242 - precision_34: 0.6748 - recall_34: 0.2431 - val_loss: 0.0856 - val_binary_accuracy: 0.9744 - val_auc_34: 0.9232 - val_precision_34: 0.6512 - val_recall_34: 0.2503\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0762 - binary_accuracy: 0.9754 - auc_34: 0.9288 - precision_34: 0.6787 - recall_34: 0.2578 - val_loss: 0.0867 - val_binary_accuracy: 0.9730 - val_auc_34: 0.9192 - val_precision_34: 0.5664 - val_recall_34: 0.2858\n","Score for fold 5: F1 score of 0.37986327510094614; loss of 0.08671166002750397; binary_accuracy of 97.30185270309448%\n","Training for fold 6 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 12ms/step - loss: 0.1093 - binary_accuracy: 0.9672 - auc_35: 0.8285 - precision_35: 0.3231 - recall_35: 0.1342 - val_loss: 0.4170 - val_binary_accuracy: 0.9740 - val_auc_35: 0.8878 - val_precision_35: 0.7379 - val_recall_35: 0.1154\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_35: 0.9023 - precision_35: 0.6703 - recall_35: 0.1959 - val_loss: 0.2622 - val_binary_accuracy: 0.9745 - val_auc_35: 0.9130 - val_precision_35: 0.7141 - val_recall_35: 0.1538\n","Epoch 3/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0806 - binary_accuracy: 0.9747 - auc_35: 0.9172 - precision_35: 0.6729 - recall_35: 0.2240 - val_loss: 0.1593 - val_binary_accuracy: 0.9745 - val_auc_35: 0.9196 - val_precision_35: 0.6065 - val_recall_35: 0.2560\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0783 - binary_accuracy: 0.9750 - auc_35: 0.9241 - precision_35: 0.6747 - recall_35: 0.2439 - val_loss: 0.0803 - val_binary_accuracy: 0.9743 - val_auc_35: 0.9225 - val_precision_35: 0.7310 - val_recall_35: 0.1307\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0769 - binary_accuracy: 0.9752 - auc_35: 0.9277 - precision_35: 0.6771 - recall_35: 0.2539 - val_loss: 0.0780 - val_binary_accuracy: 0.9748 - val_auc_35: 0.9257 - val_precision_35: 0.6718 - val_recall_35: 0.1988\n","Score for fold 6: F1 score of 0.3067630086556707; loss of 0.07802845537662506; binary_accuracy of 97.48061299324036%\n","Training for fold 7 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 12ms/step - loss: 0.1095 - binary_accuracy: 0.9668 - auc_36: 0.8283 - precision_36: 0.3116 - recall_36: 0.1342 - val_loss: 0.4671 - val_binary_accuracy: 0.9741 - val_auc_36: 0.8908 - val_precision_36: 0.6791 - val_recall_36: 0.1623\n","Epoch 2/5\n","147/147 [==============================] - 1s 9ms/step - loss: 0.0847 - binary_accuracy: 0.9743 - auc_36: 0.9028 - precision_36: 0.6733 - recall_36: 0.1964 - val_loss: 0.2868 - val_binary_accuracy: 0.9741 - val_auc_36: 0.9120 - val_precision_36: 0.5989 - val_recall_36: 0.2546\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0805 - binary_accuracy: 0.9748 - auc_36: 0.9169 - precision_36: 0.6728 - recall_36: 0.2269 - val_loss: 0.1581 - val_binary_accuracy: 0.9722 - val_auc_36: 0.9147 - val_precision_36: 0.5147 - val_recall_36: 0.3047\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_36: 0.9234 - precision_36: 0.6723 - recall_36: 0.2425 - val_loss: 0.0820 - val_binary_accuracy: 0.9749 - val_auc_36: 0.9242 - val_precision_36: 0.6712 - val_recall_36: 0.2222\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_36: 0.9284 - precision_36: 0.6789 - recall_36: 0.2569 - val_loss: 0.0778 - val_binary_accuracy: 0.9750 - val_auc_36: 0.9227 - val_precision_36: 0.6424 - val_recall_36: 0.2684\n","Score for fold 7: F1 score of 0.3785609928843051; loss of 0.0778178796172142; binary_accuracy of 97.50484228134155%\n","Training for fold 8 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1095 - binary_accuracy: 0.9672 - auc_37: 0.8254 - precision_37: 0.3159 - recall_37: 0.1306 - val_loss: 0.4400 - val_binary_accuracy: 0.9734 - val_auc_37: 0.8857 - val_precision_37: 0.7229 - val_recall_37: 0.1279\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0848 - binary_accuracy: 0.9744 - auc_37: 0.9012 - precision_37: 0.6729 - recall_37: 0.1955 - val_loss: 0.2850 - val_binary_accuracy: 0.9732 - val_auc_37: 0.9097 - val_precision_37: 0.6566 - val_recall_37: 0.1537\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0804 - binary_accuracy: 0.9748 - auc_37: 0.9173 - precision_37: 0.6729 - recall_37: 0.2244 - val_loss: 0.1739 - val_binary_accuracy: 0.9721 - val_auc_37: 0.9103 - val_precision_37: 0.5327 - val_recall_37: 0.2703\n","Epoch 4/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0786 - binary_accuracy: 0.9750 - auc_37: 0.9224 - precision_37: 0.6714 - recall_37: 0.2414 - val_loss: 0.0920 - val_binary_accuracy: 0.9740 - val_auc_37: 0.9240 - val_precision_37: 0.6182 - val_recall_37: 0.2624\n","Epoch 5/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0762 - binary_accuracy: 0.9754 - auc_37: 0.9290 - precision_37: 0.6792 - recall_37: 0.2574 - val_loss: 0.0800 - val_binary_accuracy: 0.9745 - val_auc_37: 0.9259 - val_precision_37: 0.6458 - val_recall_37: 0.2576\n","Score for fold 8: F1 score of 0.3682838417602612; loss of 0.0800062045454979; binary_accuracy of 97.44648933410645%\n","Training for fold 9 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1094 - binary_accuracy: 0.9670 - auc_38: 0.8279 - precision_38: 0.3165 - recall_38: 0.1357 - val_loss: 0.4309 - val_binary_accuracy: 0.9738 - val_auc_38: 0.8863 - val_precision_38: 0.6971 - val_recall_38: 0.1434\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_38: 0.9018 - precision_38: 0.6686 - recall_38: 0.1970 - val_loss: 0.2531 - val_binary_accuracy: 0.9739 - val_auc_38: 0.9099 - val_precision_38: 0.7339 - val_recall_38: 0.1296\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0807 - binary_accuracy: 0.9747 - auc_38: 0.9163 - precision_38: 0.6727 - recall_38: 0.2237 - val_loss: 0.1568 - val_binary_accuracy: 0.9736 - val_auc_38: 0.9166 - val_precision_38: 0.6090 - val_recall_38: 0.2081\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_38: 0.9224 - precision_38: 0.6741 - recall_38: 0.2398 - val_loss: 0.0887 - val_binary_accuracy: 0.9741 - val_auc_38: 0.9229 - val_precision_38: 0.6149 - val_recall_38: 0.2468\n","Epoch 5/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_38: 0.9281 - precision_38: 0.6776 - recall_38: 0.2550 - val_loss: 0.0801 - val_binary_accuracy: 0.9746 - val_auc_38: 0.9193 - val_precision_38: 0.6364 - val_recall_38: 0.2514\n","Score for fold 9: F1 score of 0.3604844478227972; loss of 0.08010628819465637; binary_accuracy of 97.45925068855286%\n","Training for fold 10 ...\n","Epoch 1/5\n","147/147 [==============================] - 6s 15ms/step - loss: 0.1098 - binary_accuracy: 0.9673 - auc_39: 0.8240 - precision_39: 0.3169 - recall_39: 0.1282 - val_loss: 0.4568 - val_binary_accuracy: 0.9734 - val_auc_39: 0.8804 - val_precision_39: 0.6379 - val_recall_39: 0.1612\n","Epoch 2/5\n","147/147 [==============================] - 2s 13ms/step - loss: 0.0852 - binary_accuracy: 0.9743 - auc_39: 0.9006 - precision_39: 0.6699 - recall_39: 0.1944 - val_loss: 0.2800 - val_binary_accuracy: 0.9738 - val_auc_39: 0.9103 - val_precision_39: 0.6390 - val_recall_39: 0.1895\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0806 - binary_accuracy: 0.9747 - auc_39: 0.9168 - precision_39: 0.6724 - recall_39: 0.2228 - val_loss: 0.1441 - val_binary_accuracy: 0.9742 - val_auc_39: 0.9190 - val_precision_39: 0.6648 - val_recall_39: 0.1950\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0781 - binary_accuracy: 0.9751 - auc_39: 0.9241 - precision_39: 0.6768 - recall_39: 0.2414 - val_loss: 0.0831 - val_binary_accuracy: 0.9746 - val_auc_39: 0.9221 - val_precision_39: 0.6592 - val_recall_39: 0.2299\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0767 - binary_accuracy: 0.9753 - auc_39: 0.9278 - precision_39: 0.6776 - recall_39: 0.2563 - val_loss: 0.0794 - val_binary_accuracy: 0.9749 - val_auc_39: 0.9271 - val_precision_39: 0.6417 - val_recall_39: 0.2709\n","Score for fold 10: F1 score of 0.3809497505681602; loss of 0.07940880209207535; binary_accuracy of 97.48506546020508%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  128\n","Training for fold 1 ...\n","Epoch 1/5\n","147/147 [==============================] - 4s 13ms/step - loss: 0.1094 - binary_accuracy: 0.9670 - auc_40: 0.8283 - precision_40: 0.3149 - recall_40: 0.1332 - val_loss: 0.4535 - val_binary_accuracy: 0.9736 - val_auc_40: 0.8902 - val_precision_40: 0.6315 - val_recall_40: 0.2016\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0847 - binary_accuracy: 0.9744 - auc_40: 0.9028 - precision_40: 0.6720 - recall_40: 0.1953 - val_loss: 0.2554 - val_binary_accuracy: 0.9732 - val_auc_40: 0.9105 - val_precision_40: 0.6766 - val_recall_40: 0.1348\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0806 - binary_accuracy: 0.9748 - auc_40: 0.9165 - precision_40: 0.6747 - recall_40: 0.2228 - val_loss: 0.1590 - val_binary_accuracy: 0.9730 - val_auc_40: 0.9122 - val_precision_40: 0.5795 - val_recall_40: 0.2227\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0784 - binary_accuracy: 0.9751 - auc_40: 0.9231 - precision_40: 0.6757 - recall_40: 0.2409 - val_loss: 0.1271 - val_binary_accuracy: 0.9675 - val_auc_40: 0.9130 - val_precision_40: 0.4292 - val_recall_40: 0.3890\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_40: 0.9242 - precision_40: 0.6701 - recall_40: 0.2494 - val_loss: 0.0827 - val_binary_accuracy: 0.9741 - val_auc_40: 0.9148 - val_precision_40: 0.7021 - val_recall_40: 0.1760\n","Score for fold 1: F1 score of 0.28149821148292015; loss of 0.08273734152317047; binary_accuracy of 97.41116762161255%\n","Training for fold 2 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1093 - binary_accuracy: 0.9673 - auc_41: 0.8281 - precision_41: 0.3225 - recall_41: 0.1340 - val_loss: 0.4505 - val_binary_accuracy: 0.9736 - val_auc_41: 0.8884 - val_precision_41: 0.7180 - val_recall_41: 0.1346\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0844 - binary_accuracy: 0.9744 - auc_41: 0.9032 - precision_41: 0.6713 - recall_41: 0.1978 - val_loss: 0.2838 - val_binary_accuracy: 0.9736 - val_auc_41: 0.9106 - val_precision_41: 0.6393 - val_recall_41: 0.1887\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0803 - binary_accuracy: 0.9748 - auc_41: 0.9175 - precision_41: 0.6714 - recall_41: 0.2276 - val_loss: 0.1342 - val_binary_accuracy: 0.9742 - val_auc_41: 0.9207 - val_precision_41: 0.6828 - val_recall_41: 0.1918\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_41: 0.9246 - precision_41: 0.6759 - recall_41: 0.2451 - val_loss: 0.0941 - val_binary_accuracy: 0.9730 - val_auc_41: 0.9205 - val_precision_41: 0.5640 - val_recall_41: 0.2707\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0762 - binary_accuracy: 0.9754 - auc_41: 0.9290 - precision_41: 0.6783 - recall_41: 0.2595 - val_loss: 0.0807 - val_binary_accuracy: 0.9742 - val_auc_41: 0.9213 - val_precision_41: 0.6114 - val_recall_41: 0.2795\n","Score for fold 2: F1 score of 0.38360049504113997; loss of 0.08072888106107712; binary_accuracy of 97.41814732551575%\n","Training for fold 3 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1099 - binary_accuracy: 0.9672 - auc_42: 0.8247 - precision_42: 0.3195 - recall_42: 0.1301 - val_loss: 0.4390 - val_binary_accuracy: 0.9740 - val_auc_42: 0.8832 - val_precision_42: 0.6844 - val_recall_42: 0.1517\n","Epoch 2/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0852 - binary_accuracy: 0.9743 - auc_42: 0.9003 - precision_42: 0.6708 - recall_42: 0.1953 - val_loss: 0.2973 - val_binary_accuracy: 0.9740 - val_auc_42: 0.9109 - val_precision_42: 0.6209 - val_recall_42: 0.2116\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0809 - binary_accuracy: 0.9747 - auc_42: 0.9158 - precision_42: 0.6702 - recall_42: 0.2243 - val_loss: 0.1462 - val_binary_accuracy: 0.9743 - val_auc_42: 0.9167 - val_precision_42: 0.6130 - val_recall_42: 0.2438\n","Epoch 4/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0783 - binary_accuracy: 0.9750 - auc_42: 0.9238 - precision_42: 0.6749 - recall_42: 0.2430 - val_loss: 0.0836 - val_binary_accuracy: 0.9746 - val_auc_42: 0.9193 - val_precision_42: 0.6604 - val_recall_42: 0.2091\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0767 - binary_accuracy: 0.9753 - auc_42: 0.9279 - precision_42: 0.6770 - recall_42: 0.2583 - val_loss: 0.0791 - val_binary_accuracy: 0.9747 - val_auc_42: 0.9258 - val_precision_42: 0.6131 - val_recall_42: 0.2860\n","Score for fold 3: F1 score of 0.3900166121095736; loss of 0.07912454009056091; binary_accuracy of 97.47018218040466%\n","Training for fold 4 ...\n","Epoch 1/5\n","147/147 [==============================] - 7s 43ms/step - loss: 0.1092 - binary_accuracy: 0.9673 - auc_43: 0.8294 - precision_43: 0.3257 - recall_43: 0.1357 - val_loss: 0.4715 - val_binary_accuracy: 0.9739 - val_auc_43: 0.8907 - val_precision_43: 0.6720 - val_recall_43: 0.1618\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0853 - binary_accuracy: 0.9742 - auc_43: 0.9005 - precision_43: 0.6685 - recall_43: 0.1938 - val_loss: 0.2798 - val_binary_accuracy: 0.9743 - val_auc_43: 0.9135 - val_precision_43: 0.6878 - val_recall_43: 0.1735\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0807 - binary_accuracy: 0.9748 - auc_43: 0.9167 - precision_43: 0.6728 - recall_43: 0.2245 - val_loss: 0.1226 - val_binary_accuracy: 0.9741 - val_auc_43: 0.9175 - val_precision_43: 0.6219 - val_recall_43: 0.2247\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_43: 0.9231 - precision_43: 0.6734 - recall_43: 0.2416 - val_loss: 0.0905 - val_binary_accuracy: 0.9744 - val_auc_43: 0.9246 - val_precision_43: 0.6054 - val_recall_43: 0.2819\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0769 - binary_accuracy: 0.9753 - auc_43: 0.9273 - precision_43: 0.6759 - recall_43: 0.2554 - val_loss: 0.0823 - val_binary_accuracy: 0.9740 - val_auc_43: 0.9216 - val_precision_43: 0.6057 - val_recall_43: 0.2467\n","Score for fold 4: F1 score of 0.35060946138074073; loss of 0.0823349580168724; binary_accuracy of 97.40389585494995%\n","Training for fold 5 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1101 - binary_accuracy: 0.9669 - auc_44: 0.8234 - precision_44: 0.3098 - recall_44: 0.1284 - val_loss: 0.4550 - val_binary_accuracy: 0.9740 - val_auc_44: 0.8825 - val_precision_44: 0.6976 - val_recall_44: 0.1457\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0851 - binary_accuracy: 0.9743 - auc_44: 0.9009 - precision_44: 0.6692 - recall_44: 0.1972 - val_loss: 0.2886 - val_binary_accuracy: 0.9740 - val_auc_44: 0.9098 - val_precision_44: 0.6256 - val_recall_44: 0.2038\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0807 - binary_accuracy: 0.9747 - auc_44: 0.9165 - precision_44: 0.6689 - recall_44: 0.2260 - val_loss: 0.2051 - val_binary_accuracy: 0.9715 - val_auc_44: 0.9160 - val_precision_44: 0.4938 - val_recall_44: 0.3180\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0790 - binary_accuracy: 0.9749 - auc_44: 0.9215 - precision_44: 0.6681 - recall_44: 0.2427 - val_loss: 0.0936 - val_binary_accuracy: 0.9740 - val_auc_44: 0.9217 - val_precision_44: 0.5841 - val_recall_44: 0.2812\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0767 - binary_accuracy: 0.9753 - auc_44: 0.9279 - precision_44: 0.6750 - recall_44: 0.2577 - val_loss: 0.0811 - val_binary_accuracy: 0.9747 - val_auc_44: 0.9273 - val_precision_44: 0.6270 - val_recall_44: 0.2605\n","Score for fold 5: F1 score of 0.3680806428683884; loss of 0.08107300102710724; binary_accuracy of 97.46790528297424%\n","Training for fold 6 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1100 - binary_accuracy: 0.9674 - auc_45: 0.8228 - precision_45: 0.3218 - recall_45: 0.1281 - val_loss: 0.4648 - val_binary_accuracy: 0.9740 - val_auc_45: 0.8819 - val_precision_45: 0.6667 - val_recall_45: 0.1730\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0853 - binary_accuracy: 0.9743 - auc_45: 0.8998 - precision_45: 0.6691 - recall_45: 0.1954 - val_loss: 0.2568 - val_binary_accuracy: 0.9740 - val_auc_45: 0.9101 - val_precision_45: 0.6716 - val_recall_45: 0.1703\n","Epoch 3/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0808 - binary_accuracy: 0.9747 - auc_45: 0.9163 - precision_45: 0.6676 - recall_45: 0.2259 - val_loss: 0.1426 - val_binary_accuracy: 0.9730 - val_auc_45: 0.9136 - val_precision_45: 0.5737 - val_recall_45: 0.1977\n","Epoch 4/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_45: 0.9233 - precision_45: 0.6716 - recall_45: 0.2424 - val_loss: 0.0996 - val_binary_accuracy: 0.9740 - val_auc_45: 0.9219 - val_precision_45: 0.5824 - val_recall_45: 0.3046\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0770 - binary_accuracy: 0.9752 - auc_45: 0.9273 - precision_45: 0.6756 - recall_45: 0.2530 - val_loss: 0.0789 - val_binary_accuracy: 0.9747 - val_auc_45: 0.9231 - val_precision_45: 0.6711 - val_recall_45: 0.2176\n","Score for fold 6: F1 score of 0.3286683276663007; loss of 0.07890310883522034; binary_accuracy of 97.47160077095032%\n","Training for fold 7 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1096 - binary_accuracy: 0.9673 - auc_46: 0.8247 - precision_46: 0.3176 - recall_46: 0.1281 - val_loss: 0.4437 - val_binary_accuracy: 0.9738 - val_auc_46: 0.8857 - val_precision_46: 0.7169 - val_recall_46: 0.1343\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_46: 0.9012 - precision_46: 0.6710 - recall_46: 0.1973 - val_loss: 0.3074 - val_binary_accuracy: 0.9737 - val_auc_46: 0.9077 - val_precision_46: 0.6146 - val_recall_46: 0.2071\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0806 - binary_accuracy: 0.9747 - auc_46: 0.9167 - precision_46: 0.6699 - recall_46: 0.2256 - val_loss: 0.1278 - val_binary_accuracy: 0.9746 - val_auc_46: 0.9185 - val_precision_46: 0.6568 - val_recall_46: 0.2251\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0782 - binary_accuracy: 0.9751 - auc_46: 0.9239 - precision_46: 0.6743 - recall_46: 0.2451 - val_loss: 0.0881 - val_binary_accuracy: 0.9746 - val_auc_46: 0.9252 - val_precision_46: 0.6255 - val_recall_46: 0.2651\n","Epoch 5/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0763 - binary_accuracy: 0.9754 - auc_46: 0.9291 - precision_46: 0.6781 - recall_46: 0.2591 - val_loss: 0.0801 - val_binary_accuracy: 0.9743 - val_auc_46: 0.9246 - val_precision_46: 0.5965 - val_recall_46: 0.2988\n","Score for fold 7: F1 score of 0.39816018195116226; loss of 0.08009883761405945; binary_accuracy of 97.42798209190369%\n","Training for fold 8 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1093 - binary_accuracy: 0.9671 - auc_47: 0.8272 - precision_47: 0.3117 - recall_47: 0.1295 - val_loss: 0.4569 - val_binary_accuracy: 0.9736 - val_auc_47: 0.8871 - val_precision_47: 0.7119 - val_recall_47: 0.1418\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0846 - binary_accuracy: 0.9743 - auc_47: 0.9028 - precision_47: 0.6683 - recall_47: 0.1975 - val_loss: 0.2811 - val_binary_accuracy: 0.9742 - val_auc_47: 0.9125 - val_precision_47: 0.6797 - val_recall_47: 0.1970\n","Epoch 3/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0801 - binary_accuracy: 0.9748 - auc_47: 0.9179 - precision_47: 0.6722 - recall_47: 0.2283 - val_loss: 0.1553 - val_binary_accuracy: 0.9744 - val_auc_47: 0.9205 - val_precision_47: 0.6564 - val_recall_47: 0.2362\n","Epoch 4/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0777 - binary_accuracy: 0.9752 - auc_47: 0.9248 - precision_47: 0.6750 - recall_47: 0.2467 - val_loss: 0.0890 - val_binary_accuracy: 0.9741 - val_auc_47: 0.9228 - val_precision_47: 0.6220 - val_recall_47: 0.2602\n","Epoch 5/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0759 - binary_accuracy: 0.9754 - auc_47: 0.9296 - precision_47: 0.6790 - recall_47: 0.2604 - val_loss: 0.0830 - val_binary_accuracy: 0.9739 - val_auc_47: 0.9206 - val_precision_47: 0.6003 - val_recall_47: 0.2807\n","Score for fold 8: F1 score of 0.3825056920400955; loss of 0.0830407664179802; binary_accuracy of 97.38727807998657%\n","Training for fold 9 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 13ms/step - loss: 0.1096 - binary_accuracy: 0.9667 - auc_48: 0.8293 - precision_48: 0.3072 - recall_48: 0.1337 - val_loss: 0.4541 - val_binary_accuracy: 0.9739 - val_auc_48: 0.8936 - val_precision_48: 0.6502 - val_recall_48: 0.1790\n","Epoch 2/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0842 - binary_accuracy: 0.9744 - auc_48: 0.9049 - precision_48: 0.6692 - recall_48: 0.1998 - val_loss: 0.2847 - val_binary_accuracy: 0.9744 - val_auc_48: 0.9147 - val_precision_48: 0.6455 - val_recall_48: 0.2254\n","Epoch 3/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0803 - binary_accuracy: 0.9748 - auc_48: 0.9179 - precision_48: 0.6718 - recall_48: 0.2271 - val_loss: 0.1389 - val_binary_accuracy: 0.9746 - val_auc_48: 0.9229 - val_precision_48: 0.6334 - val_recall_48: 0.2513\n","Epoch 4/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_48: 0.9246 - precision_48: 0.6760 - recall_48: 0.2461 - val_loss: 0.0879 - val_binary_accuracy: 0.9745 - val_auc_48: 0.9238 - val_precision_48: 0.6491 - val_recall_48: 0.2258\n","Epoch 5/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0762 - binary_accuracy: 0.9754 - auc_48: 0.9290 - precision_48: 0.6801 - recall_48: 0.2587 - val_loss: 0.0802 - val_binary_accuracy: 0.9746 - val_auc_48: 0.9248 - val_precision_48: 0.6463 - val_recall_48: 0.2366\n","Score for fold 9: F1 score of 0.3463637769165842; loss of 0.08019457012414932; binary_accuracy of 97.45863080024719%\n","Training for fold 10 ...\n","Epoch 1/5\n","147/147 [==============================] - 4s 17ms/step - loss: 0.1093 - binary_accuracy: 0.9670 - auc_49: 0.8296 - precision_49: 0.3161 - recall_49: 0.1339 - val_loss: 0.4420 - val_binary_accuracy: 0.9738 - val_auc_49: 0.8893 - val_precision_49: 0.6541 - val_recall_49: 0.1740\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0845 - binary_accuracy: 0.9743 - auc_49: 0.9038 - precision_49: 0.6687 - recall_49: 0.1986 - val_loss: 0.2767 - val_binary_accuracy: 0.9742 - val_auc_49: 0.9104 - val_precision_49: 0.6707 - val_recall_49: 0.1834\n","Epoch 3/5\n","147/147 [==============================] - 1s 10ms/step - loss: 0.0803 - binary_accuracy: 0.9748 - auc_49: 0.9178 - precision_49: 0.6734 - recall_49: 0.2261 - val_loss: 0.1609 - val_binary_accuracy: 0.9738 - val_auc_49: 0.9165 - val_precision_49: 0.6226 - val_recall_49: 0.2024\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0782 - binary_accuracy: 0.9751 - auc_49: 0.9239 - precision_49: 0.6753 - recall_49: 0.2439 - val_loss: 0.0915 - val_binary_accuracy: 0.9742 - val_auc_49: 0.9251 - val_precision_49: 0.6030 - val_recall_49: 0.2774\n","Epoch 5/5\n","147/147 [==============================] - 2s 10ms/step - loss: 0.0764 - binary_accuracy: 0.9754 - auc_49: 0.9284 - precision_49: 0.6791 - recall_49: 0.2595 - val_loss: 0.0810 - val_binary_accuracy: 0.9745 - val_auc_49: 0.9166 - val_precision_49: 0.7138 - val_recall_49: 0.1731\n","Score for fold 10: F1 score of 0.2786295215990917; loss of 0.08097746968269348; binary_accuracy of 97.44558334350586%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  256\n","Training for fold 1 ...\n","Epoch 1/5\n","147/147 [==============================] - 5s 16ms/step - loss: 0.1100 - binary_accuracy: 0.9670 - auc_50: 0.8266 - precision_50: 0.3101 - recall_50: 0.1297 - val_loss: 0.4643 - val_binary_accuracy: 0.9735 - val_auc_50: 0.8901 - val_precision_50: 0.6485 - val_recall_50: 0.1859\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0846 - binary_accuracy: 0.9743 - auc_50: 0.9030 - precision_50: 0.6691 - recall_50: 0.1950 - val_loss: 0.2401 - val_binary_accuracy: 0.9737 - val_auc_50: 0.9093 - val_precision_50: 0.6961 - val_recall_50: 0.1640\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0803 - binary_accuracy: 0.9748 - auc_50: 0.9173 - precision_50: 0.6728 - recall_50: 0.2243 - val_loss: 0.1433 - val_binary_accuracy: 0.9735 - val_auc_50: 0.9165 - val_precision_50: 0.6148 - val_recall_50: 0.2233\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0781 - binary_accuracy: 0.9751 - auc_50: 0.9238 - precision_50: 0.6740 - recall_50: 0.2428 - val_loss: 0.0904 - val_binary_accuracy: 0.9741 - val_auc_50: 0.9216 - val_precision_50: 0.6564 - val_recall_50: 0.2191\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0763 - binary_accuracy: 0.9754 - auc_50: 0.9285 - precision_50: 0.6792 - recall_50: 0.2575 - val_loss: 0.0825 - val_binary_accuracy: 0.9737 - val_auc_50: 0.9165 - val_precision_50: 0.6568 - val_recall_50: 0.1895\n","Score for fold 1: F1 score of 0.294124350991375; loss of 0.08247032016515732; binary_accuracy of 97.3680317401886%\n","Training for fold 2 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1103 - binary_accuracy: 0.9671 - auc_51: 0.8248 - precision_51: 0.3157 - recall_51: 0.1279 - val_loss: 0.4669 - val_binary_accuracy: 0.9745 - val_auc_51: 0.8873 - val_precision_51: 0.6684 - val_recall_51: 0.1695\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0854 - binary_accuracy: 0.9742 - auc_51: 0.9007 - precision_51: 0.6698 - recall_51: 0.1936 - val_loss: 0.2610 - val_binary_accuracy: 0.9742 - val_auc_51: 0.9062 - val_precision_51: 0.6547 - val_recall_51: 0.1580\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0810 - binary_accuracy: 0.9747 - auc_51: 0.9162 - precision_51: 0.6730 - recall_51: 0.2218 - val_loss: 0.1239 - val_binary_accuracy: 0.9751 - val_auc_51: 0.9206 - val_precision_51: 0.6521 - val_recall_51: 0.2227\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0786 - binary_accuracy: 0.9750 - auc_51: 0.9229 - precision_51: 0.6746 - recall_51: 0.2420 - val_loss: 0.1054 - val_binary_accuracy: 0.9736 - val_auc_51: 0.9235 - val_precision_51: 0.5436 - val_recall_51: 0.3241\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0771 - binary_accuracy: 0.9752 - auc_51: 0.9270 - precision_51: 0.6747 - recall_51: 0.2561 - val_loss: 0.0764 - val_binary_accuracy: 0.9754 - val_auc_51: 0.9271 - val_precision_51: 0.6395 - val_recall_51: 0.2637\n","Score for fold 2: F1 score of 0.3733794956223974; loss of 0.07642318308353424; binary_accuracy of 97.53677248954773%\n","Training for fold 3 ...\n","Epoch 1/5\n","147/147 [==============================] - 7s 17ms/step - loss: 0.1103 - binary_accuracy: 0.9665 - auc_52: 0.8271 - precision_52: 0.2999 - recall_52: 0.1320 - val_loss: 0.4261 - val_binary_accuracy: 0.9734 - val_auc_52: 0.8880 - val_precision_52: 0.6629 - val_recall_52: 0.1498\n","Epoch 2/5\n","147/147 [==============================] - 2s 13ms/step - loss: 0.0850 - binary_accuracy: 0.9743 - auc_52: 0.9014 - precision_52: 0.6687 - recall_52: 0.1932 - val_loss: 0.3058 - val_binary_accuracy: 0.9740 - val_auc_52: 0.9121 - val_precision_52: 0.6206 - val_recall_52: 0.2433\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0809 - binary_accuracy: 0.9747 - auc_52: 0.9156 - precision_52: 0.6711 - recall_52: 0.2227 - val_loss: 0.1127 - val_binary_accuracy: 0.9737 - val_auc_52: 0.9192 - val_precision_52: 0.7725 - val_recall_52: 0.1191\n","Epoch 4/5\n","147/147 [==============================] - 2s 13ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_52: 0.9227 - precision_52: 0.6738 - recall_52: 0.2392 - val_loss: 0.0908 - val_binary_accuracy: 0.9740 - val_auc_52: 0.9220 - val_precision_52: 0.6223 - val_recall_52: 0.2387\n","Epoch 5/5\n","147/147 [==============================] - 2s 14ms/step - loss: 0.0768 - binary_accuracy: 0.9753 - auc_52: 0.9274 - precision_52: 0.6775 - recall_52: 0.2541 - val_loss: 0.0790 - val_binary_accuracy: 0.9744 - val_auc_52: 0.9262 - val_precision_52: 0.6444 - val_recall_52: 0.2450\n","Score for fold 3: F1 score of 0.3550100687583484; loss of 0.07898147404193878; binary_accuracy of 97.44300246238708%\n","Training for fold 4 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 15ms/step - loss: 0.1099 - binary_accuracy: 0.9673 - auc_53: 0.8253 - precision_53: 0.3178 - recall_53: 0.1281 - val_loss: 0.4245 - val_binary_accuracy: 0.9738 - val_auc_53: 0.8839 - val_precision_53: 0.6989 - val_recall_53: 0.1305\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0850 - binary_accuracy: 0.9743 - auc_53: 0.9015 - precision_53: 0.6703 - recall_53: 0.1966 - val_loss: 0.2991 - val_binary_accuracy: 0.9739 - val_auc_53: 0.9069 - val_precision_53: 0.6007 - val_recall_53: 0.2311\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0809 - binary_accuracy: 0.9747 - auc_53: 0.9162 - precision_53: 0.6698 - recall_53: 0.2241 - val_loss: 0.1218 - val_binary_accuracy: 0.9743 - val_auc_53: 0.9187 - val_precision_53: 0.6893 - val_recall_53: 0.1697\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_53: 0.9236 - precision_53: 0.6739 - recall_53: 0.2407 - val_loss: 0.0829 - val_binary_accuracy: 0.9746 - val_auc_53: 0.9245 - val_precision_53: 0.6323 - val_recall_53: 0.2436\n","Epoch 5/5\n","147/147 [==============================] - 2s 14ms/step - loss: 0.0764 - binary_accuracy: 0.9753 - auc_53: 0.9288 - precision_53: 0.6778 - recall_53: 0.2572 - val_loss: 0.0899 - val_binary_accuracy: 0.9721 - val_auc_53: 0.9201 - val_precision_53: 0.5105 - val_recall_53: 0.3380\n","Score for fold 4: F1 score of 0.40670728691884234; loss of 0.0899074375629425; binary_accuracy of 97.20789790153503%\n","Training for fold 5 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 15ms/step - loss: 0.1101 - binary_accuracy: 0.9673 - auc_54: 0.8230 - precision_54: 0.3153 - recall_54: 0.1253 - val_loss: 0.4448 - val_binary_accuracy: 0.9735 - val_auc_54: 0.8844 - val_precision_54: 0.7075 - val_recall_54: 0.1408\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_54: 0.9014 - precision_54: 0.6708 - recall_54: 0.1952 - val_loss: 0.2322 - val_binary_accuracy: 0.9737 - val_auc_54: 0.9108 - val_precision_54: 0.7426 - val_recall_54: 0.1369\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0807 - binary_accuracy: 0.9748 - auc_54: 0.9160 - precision_54: 0.6716 - recall_54: 0.2250 - val_loss: 0.1372 - val_binary_accuracy: 0.9739 - val_auc_54: 0.9175 - val_precision_54: 0.6416 - val_recall_54: 0.2231\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0780 - binary_accuracy: 0.9751 - auc_54: 0.9242 - precision_54: 0.6748 - recall_54: 0.2437 - val_loss: 0.0888 - val_binary_accuracy: 0.9733 - val_auc_54: 0.9117 - val_precision_54: 0.6098 - val_recall_54: 0.2126\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0767 - binary_accuracy: 0.9753 - auc_54: 0.9276 - precision_54: 0.6764 - recall_54: 0.2548 - val_loss: 0.1121 - val_binary_accuracy: 0.9689 - val_auc_54: 0.9202 - val_precision_54: 0.4574 - val_recall_54: 0.4164\n","Score for fold 5: F1 score of 0.43592912667095485; loss of 0.11208514869213104; binary_accuracy of 96.88553810119629%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_BP_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Biological Processes has 32 filters, with a kernel size of 256 and has an F1 score of 0.43592912667095485\n","Training for fold 6 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1104 - binary_accuracy: 0.9667 - auc_55: 0.8258 - precision_55: 0.3049 - recall_55: 0.1303 - val_loss: 0.4373 - val_binary_accuracy: 0.9738 - val_auc_55: 0.8889 - val_precision_55: 0.7028 - val_recall_55: 0.1492\n","Epoch 2/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_55: 0.9019 - precision_55: 0.6702 - recall_55: 0.1941 - val_loss: 0.3207 - val_binary_accuracy: 0.9734 - val_auc_55: 0.9095 - val_precision_55: 0.5796 - val_recall_55: 0.2567\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0809 - binary_accuracy: 0.9747 - auc_55: 0.9158 - precision_55: 0.6697 - recall_55: 0.2224 - val_loss: 0.1110 - val_binary_accuracy: 0.9741 - val_auc_55: 0.9178 - val_precision_55: 0.7488 - val_recall_55: 0.1430\n","Epoch 4/5\n","147/147 [==============================] - 2s 11ms/step - loss: 0.0788 - binary_accuracy: 0.9750 - auc_55: 0.9216 - precision_55: 0.6739 - recall_55: 0.2394 - val_loss: 0.0897 - val_binary_accuracy: 0.9744 - val_auc_55: 0.9216 - val_precision_55: 0.6512 - val_recall_55: 0.2274\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_55: 0.9282 - precision_55: 0.6763 - recall_55: 0.2550 - val_loss: 0.0843 - val_binary_accuracy: 0.9739 - val_auc_55: 0.9114 - val_precision_55: 0.7363 - val_recall_55: 0.1378\n","Score for fold 6: F1 score of 0.2322062085550309; loss of 0.08433469384908676; binary_accuracy of 97.39124774932861%\n","Training for fold 7 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1099 - binary_accuracy: 0.9670 - auc_56: 0.8271 - precision_56: 0.3143 - recall_56: 0.1321 - val_loss: 0.4303 - val_binary_accuracy: 0.9739 - val_auc_56: 0.8833 - val_precision_56: 0.6383 - val_recall_56: 0.1729\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0851 - binary_accuracy: 0.9742 - auc_56: 0.9016 - precision_56: 0.6700 - recall_56: 0.1935 - val_loss: 0.3049 - val_binary_accuracy: 0.9743 - val_auc_56: 0.9127 - val_precision_56: 0.6071 - val_recall_56: 0.2531\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0808 - binary_accuracy: 0.9747 - auc_56: 0.9163 - precision_56: 0.6714 - recall_56: 0.2235 - val_loss: 0.1576 - val_binary_accuracy: 0.9743 - val_auc_56: 0.9216 - val_precision_56: 0.5885 - val_recall_56: 0.2958\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0782 - binary_accuracy: 0.9751 - auc_56: 0.9240 - precision_56: 0.6754 - recall_56: 0.2445 - val_loss: 0.0860 - val_binary_accuracy: 0.9751 - val_auc_56: 0.9268 - val_precision_56: 0.6885 - val_recall_56: 0.2141\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0763 - binary_accuracy: 0.9754 - auc_56: 0.9289 - precision_56: 0.6805 - recall_56: 0.2599 - val_loss: 0.0771 - val_binary_accuracy: 0.9752 - val_auc_56: 0.9261 - val_precision_56: 0.6689 - val_recall_56: 0.2407\n","Score for fold 7: F1 score of 0.3540480339492936; loss of 0.07710741460323334; binary_accuracy of 97.51800894737244%\n","Training for fold 8 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1096 - binary_accuracy: 0.9673 - auc_57: 0.8267 - precision_57: 0.3208 - recall_57: 0.1314 - val_loss: 0.4542 - val_binary_accuracy: 0.9739 - val_auc_57: 0.8901 - val_precision_57: 0.6727 - val_recall_57: 0.1700\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0848 - binary_accuracy: 0.9743 - auc_57: 0.9019 - precision_57: 0.6707 - recall_57: 0.1971 - val_loss: 0.3641 - val_binary_accuracy: 0.9705 - val_auc_57: 0.9045 - val_precision_57: 0.4751 - val_recall_57: 0.3161\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0823 - binary_accuracy: 0.9745 - auc_57: 0.9110 - precision_57: 0.6616 - recall_57: 0.2200 - val_loss: 0.1283 - val_binary_accuracy: 0.9745 - val_auc_57: 0.9231 - val_precision_57: 0.7222 - val_recall_57: 0.1753\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0784 - binary_accuracy: 0.9751 - auc_57: 0.9234 - precision_57: 0.6756 - recall_57: 0.2409 - val_loss: 0.0941 - val_binary_accuracy: 0.9738 - val_auc_57: 0.9226 - val_precision_57: 0.5972 - val_recall_57: 0.2512\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0767 - binary_accuracy: 0.9753 - auc_57: 0.9280 - precision_57: 0.6768 - recall_57: 0.2542 - val_loss: 0.0790 - val_binary_accuracy: 0.9747 - val_auc_57: 0.9241 - val_precision_57: 0.6854 - val_recall_57: 0.2094\n","Score for fold 8: F1 score of 0.32084220188564355; loss of 0.07902964949607849; binary_accuracy of 97.4653959274292%\n","Training for fold 9 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 14ms/step - loss: 0.1102 - binary_accuracy: 0.9671 - auc_58: 0.8253 - precision_58: 0.3135 - recall_58: 0.1286 - val_loss: 0.4504 - val_binary_accuracy: 0.9737 - val_auc_58: 0.8856 - val_precision_58: 0.6487 - val_recall_58: 0.1804\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_58: 0.9017 - precision_58: 0.6689 - recall_58: 0.1964 - val_loss: 0.2600 - val_binary_accuracy: 0.9737 - val_auc_58: 0.9105 - val_precision_58: 0.6840 - val_recall_58: 0.1568\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0805 - binary_accuracy: 0.9748 - auc_58: 0.9172 - precision_58: 0.6733 - recall_58: 0.2228 - val_loss: 0.1319 - val_binary_accuracy: 0.9741 - val_auc_58: 0.9209 - val_precision_58: 0.6970 - val_recall_58: 0.1726\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0782 - binary_accuracy: 0.9751 - auc_58: 0.9235 - precision_58: 0.6758 - recall_58: 0.2417 - val_loss: 0.0984 - val_binary_accuracy: 0.9734 - val_auc_58: 0.9235 - val_precision_58: 0.5723 - val_recall_58: 0.2916\n","Epoch 5/5\n","147/147 [==============================] - 2s 13ms/step - loss: 0.0763 - binary_accuracy: 0.9754 - auc_58: 0.9288 - precision_58: 0.6779 - recall_58: 0.2579 - val_loss: 0.0839 - val_binary_accuracy: 0.9737 - val_auc_58: 0.9221 - val_precision_58: 0.5825 - val_recall_58: 0.2932\n","Score for fold 9: F1 score of 0.39003366349161306; loss of 0.0839318335056305; binary_accuracy of 97.36818671226501%\n","Training for fold 10 ...\n","Epoch 1/5\n","147/147 [==============================] - 3s 15ms/step - loss: 0.1101 - binary_accuracy: 0.9667 - auc_59: 0.8276 - precision_59: 0.3087 - recall_59: 0.1336 - val_loss: 0.4605 - val_binary_accuracy: 0.9739 - val_auc_59: 0.8895 - val_precision_59: 0.6260 - val_recall_59: 0.2001\n","Epoch 2/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0849 - binary_accuracy: 0.9743 - auc_59: 0.9022 - precision_59: 0.6687 - recall_59: 0.1968 - val_loss: 0.3055 - val_binary_accuracy: 0.9744 - val_auc_59: 0.9104 - val_precision_59: 0.6686 - val_recall_59: 0.1923\n","Epoch 3/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0808 - binary_accuracy: 0.9747 - auc_59: 0.9162 - precision_59: 0.6723 - recall_59: 0.2233 - val_loss: 0.1147 - val_binary_accuracy: 0.9733 - val_auc_59: 0.9180 - val_precision_59: 0.8286 - val_recall_59: 0.0739\n","Epoch 4/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_59: 0.9227 - precision_59: 0.6743 - recall_59: 0.2392 - val_loss: 0.1113 - val_binary_accuracy: 0.9725 - val_auc_59: 0.9215 - val_precision_59: 0.5253 - val_recall_59: 0.3317\n","Epoch 5/5\n","147/147 [==============================] - 2s 12ms/step - loss: 0.0768 - binary_accuracy: 0.9753 - auc_59: 0.9276 - precision_59: 0.6764 - recall_59: 0.2548 - val_loss: 0.0818 - val_binary_accuracy: 0.9743 - val_auc_59: 0.9233 - val_precision_59: 0.6159 - val_recall_59: 0.2522\n","Score for fold 10: F1 score of 0.3578714669992696; loss of 0.08181596547365189; binary_accuracy of 97.43124842643738%\n","=======================================================================\n","Training for Cellular Component\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  64\n","Training for fold 1 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 13ms/step - loss: 0.0965 - binary_accuracy: 0.9723 - auc_60: 0.8361 - precision_60: 0.3841 - recall_60: 0.1948 - val_loss: 0.4556 - val_binary_accuracy: 0.9790 - val_auc_60: 0.8980 - val_precision_60: 0.7459 - val_recall_60: 0.2187\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0722 - binary_accuracy: 0.9791 - auc_60: 0.9098 - precision_60: 0.7492 - recall_60: 0.2339 - val_loss: 0.2567 - val_binary_accuracy: 0.9795 - val_auc_60: 0.9218 - val_precision_60: 0.7691 - val_recall_60: 0.2341\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0685 - binary_accuracy: 0.9795 - auc_60: 0.9232 - precision_60: 0.7483 - recall_60: 0.2575 - val_loss: 0.1242 - val_binary_accuracy: 0.9798 - val_auc_60: 0.9312 - val_precision_60: 0.7490 - val_recall_60: 0.2662\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_60: 0.9304 - precision_60: 0.7452 - recall_60: 0.2749 - val_loss: 0.0714 - val_binary_accuracy: 0.9799 - val_auc_60: 0.9351 - val_precision_60: 0.7685 - val_recall_60: 0.2591\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0648 - binary_accuracy: 0.9799 - auc_60: 0.9344 - precision_60: 0.7418 - recall_60: 0.2875 - val_loss: 0.0655 - val_binary_accuracy: 0.9801 - val_auc_60: 0.9363 - val_precision_60: 0.7302 - val_recall_60: 0.2982\n","Score for fold 1: F1 score of 0.42344294741940114; loss of 0.06552459299564362; binary_accuracy of 98.00773859024048%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Cellular Component has 16 filters, with a kernel size of 64 and has an F1 score of 0.42344294741940114\n","Training for fold 2 ...\n","Epoch 1/5\n","149/149 [==============================] - 12s 12ms/step - loss: 0.0986 - binary_accuracy: 0.9716 - auc_61: 0.8268 - precision_61: 0.3602 - recall_61: 0.1876 - val_loss: 0.4610 - val_binary_accuracy: 0.9791 - val_auc_61: 0.8828 - val_precision_61: 0.7697 - val_recall_61: 0.2023\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0740 - binary_accuracy: 0.9790 - auc_61: 0.9006 - precision_61: 0.7533 - recall_61: 0.2278 - val_loss: 0.2385 - val_binary_accuracy: 0.9795 - val_auc_61: 0.9186 - val_precision_61: 0.8120 - val_recall_61: 0.2018\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0691 - binary_accuracy: 0.9794 - auc_61: 0.9210 - precision_61: 0.7479 - recall_61: 0.2558 - val_loss: 0.1163 - val_binary_accuracy: 0.9799 - val_auc_61: 0.9313 - val_precision_61: 0.7793 - val_recall_61: 0.2410\n","Epoch 4/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9796 - auc_61: 0.9284 - precision_61: 0.7421 - recall_61: 0.2728 - val_loss: 0.0700 - val_binary_accuracy: 0.9800 - val_auc_61: 0.9350 - val_precision_61: 0.7571 - val_recall_61: 0.2620\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_61: 0.9341 - precision_61: 0.7420 - recall_61: 0.2854 - val_loss: 0.0644 - val_binary_accuracy: 0.9802 - val_auc_61: 0.9361 - val_precision_61: 0.7218 - val_recall_61: 0.3005\n","Score for fold 2: F1 score of 0.4243692287634947; loss of 0.06441351771354675; binary_accuracy of 98.01920652389526%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Cellular Component has 16 filters, with a kernel size of 64 and has an F1 score of 0.4243692287634947\n","Training for fold 3 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0979 - binary_accuracy: 0.9720 - auc_62: 0.8300 - precision_62: 0.3709 - recall_62: 0.1902 - val_loss: 0.4395 - val_binary_accuracy: 0.9785 - val_auc_62: 0.8881 - val_precision_62: 0.7998 - val_recall_62: 0.1861\n","Epoch 2/5\n","149/149 [==============================] - 2s 14ms/step - loss: 0.0729 - binary_accuracy: 0.9791 - auc_62: 0.9057 - precision_62: 0.7492 - recall_62: 0.2320 - val_loss: 0.2598 - val_binary_accuracy: 0.9791 - val_auc_62: 0.9205 - val_precision_62: 0.7417 - val_recall_62: 0.2506\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_62: 0.9225 - precision_62: 0.7461 - recall_62: 0.2570 - val_loss: 0.1264 - val_binary_accuracy: 0.9794 - val_auc_62: 0.9303 - val_precision_62: 0.7515 - val_recall_62: 0.2624\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_62: 0.9299 - precision_62: 0.7440 - recall_62: 0.2740 - val_loss: 0.0754 - val_binary_accuracy: 0.9795 - val_auc_62: 0.9348 - val_precision_62: 0.7271 - val_recall_62: 0.2892\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0648 - binary_accuracy: 0.9799 - auc_62: 0.9342 - precision_62: 0.7405 - recall_62: 0.2868 - val_loss: 0.0658 - val_binary_accuracy: 0.9796 - val_auc_62: 0.9336 - val_precision_62: 0.7698 - val_recall_62: 0.2647\n","Score for fold 3: F1 score of 0.39398730772170343; loss of 0.06575683504343033; binary_accuracy of 97.96485304832458%\n","Training for fold 4 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0974 - binary_accuracy: 0.9725 - auc_63: 0.8308 - precision_63: 0.3844 - recall_63: 0.1876 - val_loss: 0.4151 - val_binary_accuracy: 0.9787 - val_auc_63: 0.8844 - val_precision_63: 0.7728 - val_recall_63: 0.1943\n","Epoch 2/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0730 - binary_accuracy: 0.9791 - auc_63: 0.9056 - precision_63: 0.7486 - recall_63: 0.2314 - val_loss: 0.2330 - val_binary_accuracy: 0.9791 - val_auc_63: 0.9177 - val_precision_63: 0.7873 - val_recall_63: 0.2115\n","Epoch 3/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_63: 0.9228 - precision_63: 0.7475 - recall_63: 0.2570 - val_loss: 0.1261 - val_binary_accuracy: 0.9796 - val_auc_63: 0.9303 - val_precision_63: 0.7294 - val_recall_63: 0.2754\n","Epoch 4/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_63: 0.9299 - precision_63: 0.7434 - recall_63: 0.2739 - val_loss: 0.0765 - val_binary_accuracy: 0.9796 - val_auc_63: 0.9350 - val_precision_63: 0.7108 - val_recall_63: 0.2972\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_63: 0.9346 - precision_63: 0.7426 - recall_63: 0.2872 - val_loss: 0.0672 - val_binary_accuracy: 0.9797 - val_auc_63: 0.9370 - val_precision_63: 0.6985 - val_recall_63: 0.3157\n","Score for fold 4: F1 score of 0.43487226501577325; loss of 0.06724322587251663; binary_accuracy of 97.97096848487854%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Cellular Component has 16 filters, with a kernel size of 64 and has an F1 score of 0.43487226501577325\n","Training for fold 5 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0977 - binary_accuracy: 0.9722 - auc_64: 0.8293 - precision_64: 0.3778 - recall_64: 0.1889 - val_loss: 0.4320 - val_binary_accuracy: 0.9790 - val_auc_64: 0.8856 - val_precision_64: 0.7950 - val_recall_64: 0.1888\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0734 - binary_accuracy: 0.9791 - auc_64: 0.9032 - precision_64: 0.7533 - recall_64: 0.2297 - val_loss: 0.2406 - val_binary_accuracy: 0.9795 - val_auc_64: 0.9196 - val_precision_64: 0.7892 - val_recall_64: 0.2184\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0687 - binary_accuracy: 0.9795 - auc_64: 0.9223 - precision_64: 0.7475 - recall_64: 0.2574 - val_loss: 0.1118 - val_binary_accuracy: 0.9798 - val_auc_64: 0.9316 - val_precision_64: 0.7828 - val_recall_64: 0.2376\n","Epoch 4/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0664 - binary_accuracy: 0.9797 - auc_64: 0.9301 - precision_64: 0.7436 - recall_64: 0.2753 - val_loss: 0.0736 - val_binary_accuracy: 0.9799 - val_auc_64: 0.9369 - val_precision_64: 0.6992 - val_recall_64: 0.3106\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0649 - binary_accuracy: 0.9799 - auc_64: 0.9346 - precision_64: 0.7400 - recall_64: 0.2877 - val_loss: 0.0641 - val_binary_accuracy: 0.9801 - val_auc_64: 0.9349 - val_precision_64: 0.7476 - val_recall_64: 0.2801\n","Score for fold 5: F1 score of 0.4075401093075435; loss of 0.06412816792726517; binary_accuracy of 98.01109433174133%\n","Training for fold 6 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0969 - binary_accuracy: 0.9723 - auc_65: 0.8349 - precision_65: 0.3793 - recall_65: 0.1899 - val_loss: 0.4528 - val_binary_accuracy: 0.9788 - val_auc_65: 0.8967 - val_precision_65: 0.7579 - val_recall_65: 0.2102\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0726 - binary_accuracy: 0.9791 - auc_65: 0.9076 - precision_65: 0.7519 - recall_65: 0.2316 - val_loss: 0.2630 - val_binary_accuracy: 0.9792 - val_auc_65: 0.9212 - val_precision_65: 0.7336 - val_recall_65: 0.2517\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_65: 0.9228 - precision_65: 0.7473 - recall_65: 0.2573 - val_loss: 0.1198 - val_binary_accuracy: 0.9796 - val_auc_65: 0.9305 - val_precision_65: 0.7565 - val_recall_65: 0.2544\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_65: 0.9300 - precision_65: 0.7432 - recall_65: 0.2743 - val_loss: 0.0705 - val_binary_accuracy: 0.9796 - val_auc_65: 0.9346 - val_precision_65: 0.7825 - val_recall_65: 0.2443\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_65: 0.9349 - precision_65: 0.7434 - recall_65: 0.2871 - val_loss: 0.0655 - val_binary_accuracy: 0.9798 - val_auc_65: 0.9362 - val_precision_65: 0.7393 - val_recall_65: 0.2807\n","Score for fold 6: F1 score of 0.4069541207638791; loss of 0.06551261246204376; binary_accuracy of 97.97787666320801%\n","Training for fold 7 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 11ms/step - loss: 0.0977 - binary_accuracy: 0.9716 - auc_66: 0.8349 - precision_66: 0.3602 - recall_66: 0.1913 - val_loss: 0.4630 - val_binary_accuracy: 0.9784 - val_auc_66: 0.8964 - val_precision_66: 0.7487 - val_recall_66: 0.2098\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0727 - binary_accuracy: 0.9791 - auc_66: 0.9074 - precision_66: 0.7496 - recall_66: 0.2302 - val_loss: 0.2605 - val_binary_accuracy: 0.9789 - val_auc_66: 0.9197 - val_precision_66: 0.7667 - val_recall_66: 0.2292\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0688 - binary_accuracy: 0.9795 - auc_66: 0.9218 - precision_66: 0.7473 - recall_66: 0.2541 - val_loss: 0.1201 - val_binary_accuracy: 0.9792 - val_auc_66: 0.9294 - val_precision_66: 0.7510 - val_recall_66: 0.2544\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0665 - binary_accuracy: 0.9797 - auc_66: 0.9294 - precision_66: 0.7447 - recall_66: 0.2719 - val_loss: 0.0780 - val_binary_accuracy: 0.9793 - val_auc_66: 0.9343 - val_precision_66: 0.7193 - val_recall_66: 0.2877\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0649 - binary_accuracy: 0.9799 - auc_66: 0.9338 - precision_66: 0.7429 - recall_66: 0.2852 - val_loss: 0.0667 - val_binary_accuracy: 0.9795 - val_auc_66: 0.9336 - val_precision_66: 0.7331 - val_recall_66: 0.2846\n","Score for fold 7: F1 score of 0.4099904972986983; loss of 0.06667501479387283; binary_accuracy of 97.94865250587463%\n","Training for fold 8 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 11ms/step - loss: 0.0982 - binary_accuracy: 0.9718 - auc_67: 0.8288 - precision_67: 0.3653 - recall_67: 0.1891 - val_loss: 0.4088 - val_binary_accuracy: 0.9788 - val_auc_67: 0.8812 - val_precision_67: 0.7884 - val_recall_67: 0.1845\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0735 - binary_accuracy: 0.9791 - auc_67: 0.9026 - precision_67: 0.7538 - recall_67: 0.2283 - val_loss: 0.2362 - val_binary_accuracy: 0.9793 - val_auc_67: 0.9161 - val_precision_67: 0.7516 - val_recall_67: 0.2311\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0690 - binary_accuracy: 0.9794 - auc_67: 0.9213 - precision_67: 0.7455 - recall_67: 0.2563 - val_loss: 0.1167 - val_binary_accuracy: 0.9797 - val_auc_67: 0.9301 - val_precision_67: 0.7377 - val_recall_67: 0.2661\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0665 - binary_accuracy: 0.9797 - auc_67: 0.9296 - precision_67: 0.7438 - recall_67: 0.2730 - val_loss: 0.0744 - val_binary_accuracy: 0.9798 - val_auc_67: 0.9352 - val_precision_67: 0.7283 - val_recall_67: 0.2824\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0650 - binary_accuracy: 0.9799 - auc_67: 0.9337 - precision_67: 0.7412 - recall_67: 0.2858 - val_loss: 0.0660 - val_binary_accuracy: 0.9800 - val_auc_67: 0.9368 - val_precision_67: 0.7199 - val_recall_67: 0.3010\n","Score for fold 8: F1 score of 0.42454746160449675; loss of 0.06602878868579865; binary_accuracy of 97.99987077713013%\n","Training for fold 9 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 13ms/step - loss: 0.0978 - binary_accuracy: 0.9721 - auc_68: 0.8296 - precision_68: 0.3705 - recall_68: 0.1887 - val_loss: 0.4623 - val_binary_accuracy: 0.9784 - val_auc_68: 0.8898 - val_precision_68: 0.7448 - val_recall_68: 0.2122\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0726 - binary_accuracy: 0.9791 - auc_68: 0.9072 - precision_68: 0.7492 - recall_68: 0.2319 - val_loss: 0.2513 - val_binary_accuracy: 0.9790 - val_auc_68: 0.9227 - val_precision_68: 0.7759 - val_recall_68: 0.2280\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0684 - binary_accuracy: 0.9795 - auc_68: 0.9230 - precision_68: 0.7478 - recall_68: 0.2572 - val_loss: 0.1211 - val_binary_accuracy: 0.9792 - val_auc_68: 0.9314 - val_precision_68: 0.7725 - val_recall_68: 0.2419\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_68: 0.9298 - precision_68: 0.7442 - recall_68: 0.2733 - val_loss: 0.0774 - val_binary_accuracy: 0.9794 - val_auc_68: 0.9359 - val_precision_68: 0.7113 - val_recall_68: 0.3011\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_68: 0.9344 - precision_68: 0.7420 - recall_68: 0.2869 - val_loss: 0.0673 - val_binary_accuracy: 0.9796 - val_auc_68: 0.9368 - val_precision_68: 0.7328 - val_recall_68: 0.2896\n","Score for fold 9: F1 score of 0.4151497975678897; loss of 0.06731068342924118; binary_accuracy of 97.95588850975037%\n","Training for fold 10 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 11ms/step - loss: 0.0979 - binary_accuracy: 0.9721 - auc_69: 0.8294 - precision_69: 0.3715 - recall_69: 0.1894 - val_loss: 0.4625 - val_binary_accuracy: 0.9785 - val_auc_69: 0.8849 - val_precision_69: 0.7403 - val_recall_69: 0.2149\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0733 - binary_accuracy: 0.9791 - auc_69: 0.9033 - precision_69: 0.7517 - recall_69: 0.2311 - val_loss: 0.2695 - val_binary_accuracy: 0.9789 - val_auc_69: 0.9190 - val_precision_69: 0.7460 - val_recall_69: 0.2379\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_69: 0.9222 - precision_69: 0.7485 - recall_69: 0.2573 - val_loss: 0.1285 - val_binary_accuracy: 0.9792 - val_auc_69: 0.9305 - val_precision_69: 0.7284 - val_recall_69: 0.2700\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_69: 0.9297 - precision_69: 0.7430 - recall_69: 0.2751 - val_loss: 0.0720 - val_binary_accuracy: 0.9794 - val_auc_69: 0.9352 - val_precision_69: 0.7693 - val_recall_69: 0.2521\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_69: 0.9350 - precision_69: 0.7422 - recall_69: 0.2883 - val_loss: 0.0671 - val_binary_accuracy: 0.9795 - val_auc_69: 0.9362 - val_precision_69: 0.7106 - val_recall_69: 0.3014\n","Score for fold 10: F1 score of 0.42331055724601; loss of 0.06711582839488983; binary_accuracy of 97.94716238975525%\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  128\n","Training for fold 1 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 14ms/step - loss: 0.0968 - binary_accuracy: 0.9720 - auc_70: 0.8357 - precision_70: 0.3735 - recall_70: 0.1929 - val_loss: 0.4495 - val_binary_accuracy: 0.9789 - val_auc_70: 0.8989 - val_precision_70: 0.7411 - val_recall_70: 0.2211\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0724 - binary_accuracy: 0.9791 - auc_70: 0.9088 - precision_70: 0.7495 - recall_70: 0.2339 - val_loss: 0.2542 - val_binary_accuracy: 0.9794 - val_auc_70: 0.9215 - val_precision_70: 0.7628 - val_recall_70: 0.2383\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_70: 0.9224 - precision_70: 0.7476 - recall_70: 0.2572 - val_loss: 0.1235 - val_binary_accuracy: 0.9796 - val_auc_70: 0.9309 - val_precision_70: 0.7439 - val_recall_70: 0.2630\n","Epoch 4/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_70: 0.9297 - precision_70: 0.7424 - recall_70: 0.2754 - val_loss: 0.0722 - val_binary_accuracy: 0.9798 - val_auc_70: 0.9348 - val_precision_70: 0.7540 - val_recall_70: 0.2664\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0648 - binary_accuracy: 0.9799 - auc_70: 0.9345 - precision_70: 0.7420 - recall_70: 0.2870 - val_loss: 0.0651 - val_binary_accuracy: 0.9799 - val_auc_70: 0.9347 - val_precision_70: 0.7461 - val_recall_70: 0.2802\n","Score for fold 1: F1 score of 0.4074113726476111; loss of 0.06505114585161209; binary_accuracy of 97.99399971961975%\n","Training for fold 2 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0970 - binary_accuracy: 0.9720 - auc_71: 0.8363 - precision_71: 0.3753 - recall_71: 0.1943 - val_loss: 0.4431 - val_binary_accuracy: 0.9794 - val_auc_71: 0.9013 - val_precision_71: 0.7554 - val_recall_71: 0.2192\n","Epoch 2/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0723 - binary_accuracy: 0.9791 - auc_71: 0.9100 - precision_71: 0.7481 - recall_71: 0.2346 - val_loss: 0.2527 - val_binary_accuracy: 0.9798 - val_auc_71: 0.9240 - val_precision_71: 0.7443 - val_recall_71: 0.2538\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0685 - binary_accuracy: 0.9794 - auc_71: 0.9236 - precision_71: 0.7441 - recall_71: 0.2591 - val_loss: 0.1252 - val_binary_accuracy: 0.9799 - val_auc_71: 0.9334 - val_precision_71: 0.7049 - val_recall_71: 0.2961\n","Epoch 4/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_71: 0.9303 - precision_71: 0.7420 - recall_71: 0.2759 - val_loss: 0.0758 - val_binary_accuracy: 0.9800 - val_auc_71: 0.9376 - val_precision_71: 0.6934 - val_recall_71: 0.3148\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0648 - binary_accuracy: 0.9799 - auc_71: 0.9348 - precision_71: 0.7411 - recall_71: 0.2886 - val_loss: 0.0639 - val_binary_accuracy: 0.9803 - val_auc_71: 0.9371 - val_precision_71: 0.7395 - val_recall_71: 0.2912\n","Score for fold 2: F1 score of 0.41786883550528225; loss of 0.0638810321688652; binary_accuracy of 98.03321361541748%\n","Training for fold 3 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0976 - binary_accuracy: 0.9723 - auc_72: 0.8302 - precision_72: 0.3784 - recall_72: 0.1876 - val_loss: 0.4559 - val_binary_accuracy: 0.9788 - val_auc_72: 0.8901 - val_precision_72: 0.7456 - val_recall_72: 0.2116\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0732 - binary_accuracy: 0.9791 - auc_72: 0.9046 - precision_72: 0.7511 - recall_72: 0.2297 - val_loss: 0.2482 - val_binary_accuracy: 0.9793 - val_auc_72: 0.9206 - val_precision_72: 0.7993 - val_recall_72: 0.2157\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0687 - binary_accuracy: 0.9795 - auc_72: 0.9225 - precision_72: 0.7461 - recall_72: 0.2571 - val_loss: 0.1107 - val_binary_accuracy: 0.9796 - val_auc_72: 0.9309 - val_precision_72: 0.7780 - val_recall_72: 0.2432\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_72: 0.9300 - precision_72: 0.7440 - recall_72: 0.2745 - val_loss: 0.0754 - val_binary_accuracy: 0.9797 - val_auc_72: 0.9363 - val_precision_72: 0.7141 - val_recall_72: 0.2964\n","Epoch 5/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_72: 0.9349 - precision_72: 0.7402 - recall_72: 0.2875 - val_loss: 0.0653 - val_binary_accuracy: 0.9800 - val_auc_72: 0.9367 - val_precision_72: 0.7540 - val_recall_72: 0.2815\n","Score for fold 3: F1 score of 0.4099111306308286; loss of 0.06531208753585815; binary_accuracy of 98.00153374671936%\n","Training for fold 4 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 11ms/step - loss: 0.0984 - binary_accuracy: 0.9720 - auc_73: 0.8286 - precision_73: 0.3693 - recall_73: 0.1885 - val_loss: 0.4515 - val_binary_accuracy: 0.9788 - val_auc_73: 0.8882 - val_precision_73: 0.7572 - val_recall_73: 0.2082\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0731 - binary_accuracy: 0.9791 - auc_73: 0.9046 - precision_73: 0.7506 - recall_73: 0.2303 - val_loss: 0.2577 - val_binary_accuracy: 0.9793 - val_auc_73: 0.9213 - val_precision_73: 0.7639 - val_recall_73: 0.2341\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0685 - binary_accuracy: 0.9795 - auc_73: 0.9228 - precision_73: 0.7479 - recall_73: 0.2576 - val_loss: 0.1209 - val_binary_accuracy: 0.9795 - val_auc_73: 0.9315 - val_precision_73: 0.7500 - val_recall_73: 0.2577\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_73: 0.9300 - precision_73: 0.7433 - recall_73: 0.2752 - val_loss: 0.0709 - val_binary_accuracy: 0.9797 - val_auc_73: 0.9366 - val_precision_73: 0.7746 - val_recall_73: 0.2529\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_73: 0.9346 - precision_73: 0.7406 - recall_73: 0.2887 - val_loss: 0.0652 - val_binary_accuracy: 0.9797 - val_auc_73: 0.9339 - val_precision_73: 0.7780 - val_recall_73: 0.2524\n","Score for fold 4: F1 score of 0.38115497463956904; loss of 0.06523401290178299; binary_accuracy of 97.97214269638062%\n","Training for fold 5 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0984 - binary_accuracy: 0.9717 - auc_74: 0.8317 - precision_74: 0.3619 - recall_74: 0.1927 - val_loss: 0.4430 - val_binary_accuracy: 0.9785 - val_auc_74: 0.8929 - val_precision_74: 0.7648 - val_recall_74: 0.2042\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0730 - binary_accuracy: 0.9791 - auc_74: 0.9056 - precision_74: 0.7497 - recall_74: 0.2308 - val_loss: 0.2547 - val_binary_accuracy: 0.9788 - val_auc_74: 0.9184 - val_precision_74: 0.8004 - val_recall_74: 0.2061\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0688 - binary_accuracy: 0.9795 - auc_74: 0.9216 - precision_74: 0.7457 - recall_74: 0.2558 - val_loss: 0.1174 - val_binary_accuracy: 0.9792 - val_auc_74: 0.9286 - val_precision_74: 0.7698 - val_recall_74: 0.2426\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0664 - binary_accuracy: 0.9797 - auc_74: 0.9294 - precision_74: 0.7429 - recall_74: 0.2736 - val_loss: 0.0749 - val_binary_accuracy: 0.9794 - val_auc_74: 0.9338 - val_precision_74: 0.7315 - val_recall_74: 0.2822\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_74: 0.9346 - precision_74: 0.7423 - recall_74: 0.2862 - val_loss: 0.0664 - val_binary_accuracy: 0.9795 - val_auc_74: 0.9328 - val_precision_74: 0.7345 - val_recall_74: 0.2873\n","Score for fold 5: F1 score of 0.4129966379109611; loss of 0.06638504564762115; binary_accuracy of 97.95347452163696%\n","Training for fold 6 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0977 - binary_accuracy: 0.9719 - auc_75: 0.8324 - precision_75: 0.3691 - recall_75: 0.1944 - val_loss: 0.4553 - val_binary_accuracy: 0.9785 - val_auc_75: 0.8921 - val_precision_75: 0.7642 - val_recall_75: 0.2040\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0724 - binary_accuracy: 0.9791 - auc_75: 0.9078 - precision_75: 0.7493 - recall_75: 0.2335 - val_loss: 0.2650 - val_binary_accuracy: 0.9791 - val_auc_75: 0.9211 - val_precision_75: 0.7533 - val_recall_75: 0.2432\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0684 - binary_accuracy: 0.9795 - auc_75: 0.9232 - precision_75: 0.7465 - recall_75: 0.2587 - val_loss: 0.1192 - val_binary_accuracy: 0.9794 - val_auc_75: 0.9303 - val_precision_75: 0.7648 - val_recall_75: 0.2506\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0661 - binary_accuracy: 0.9798 - auc_75: 0.9302 - precision_75: 0.7429 - recall_75: 0.2758 - val_loss: 0.0709 - val_binary_accuracy: 0.9795 - val_auc_75: 0.9347 - val_precision_75: 0.7809 - val_recall_75: 0.2467\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_75: 0.9346 - precision_75: 0.7418 - recall_75: 0.2886 - val_loss: 0.0664 - val_binary_accuracy: 0.9796 - val_auc_75: 0.9363 - val_precision_75: 0.7361 - val_recall_75: 0.2875\n","Score for fold 6: F1 score of 0.4135148980278869; loss of 0.06641358882188797; binary_accuracy of 97.96268343925476%\n","Training for fold 7 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0972 - binary_accuracy: 0.9717 - auc_76: 0.8359 - precision_76: 0.3653 - recall_76: 0.1939 - val_loss: 0.4381 - val_binary_accuracy: 0.9790 - val_auc_76: 0.9014 - val_precision_76: 0.7652 - val_recall_76: 0.2089\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0718 - binary_accuracy: 0.9791 - auc_76: 0.9113 - precision_76: 0.7520 - recall_76: 0.2344 - val_loss: 0.2446 - val_binary_accuracy: 0.9794 - val_auc_76: 0.9211 - val_precision_76: 0.7698 - val_recall_76: 0.2298\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0682 - binary_accuracy: 0.9795 - auc_76: 0.9239 - precision_76: 0.7496 - recall_76: 0.2577 - val_loss: 0.1264 - val_binary_accuracy: 0.9796 - val_auc_76: 0.9298 - val_precision_76: 0.7404 - val_recall_76: 0.2651\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_76: 0.9306 - precision_76: 0.7439 - recall_76: 0.2754 - val_loss: 0.0715 - val_binary_accuracy: 0.9797 - val_auc_76: 0.9337 - val_precision_76: 0.7546 - val_recall_76: 0.2584\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_76: 0.9353 - precision_76: 0.7439 - recall_76: 0.2885 - val_loss: 0.0656 - val_binary_accuracy: 0.9798 - val_auc_76: 0.9327 - val_precision_76: 0.7292 - val_recall_76: 0.2826\n","Score for fold 7: F1 score of 0.4073310845851491; loss of 0.06561719626188278; binary_accuracy of 97.97739386558533%\n","Training for fold 8 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 12ms/step - loss: 0.0968 - binary_accuracy: 0.9724 - auc_77: 0.8350 - precision_77: 0.3837 - recall_77: 0.1921 - val_loss: 0.4528 - val_binary_accuracy: 0.9789 - val_auc_77: 0.8998 - val_precision_77: 0.7680 - val_recall_77: 0.2040\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0723 - binary_accuracy: 0.9791 - auc_77: 0.9093 - precision_77: 0.7502 - recall_77: 0.2329 - val_loss: 0.2561 - val_binary_accuracy: 0.9794 - val_auc_77: 0.9238 - val_precision_77: 0.7461 - val_recall_77: 0.2473\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0683 - binary_accuracy: 0.9795 - auc_77: 0.9236 - precision_77: 0.7469 - recall_77: 0.2586 - val_loss: 0.1243 - val_binary_accuracy: 0.9796 - val_auc_77: 0.9321 - val_precision_77: 0.7391 - val_recall_77: 0.2692\n","Epoch 4/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_77: 0.9304 - precision_77: 0.7424 - recall_77: 0.2762 - val_loss: 0.0769 - val_binary_accuracy: 0.9798 - val_auc_77: 0.9366 - val_precision_77: 0.7272 - val_recall_77: 0.2903\n","Epoch 5/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_77: 0.9345 - precision_77: 0.7396 - recall_77: 0.2892 - val_loss: 0.0667 - val_binary_accuracy: 0.9798 - val_auc_77: 0.9373 - val_precision_77: 0.6953 - val_recall_77: 0.3212\n","Score for fold 8: F1 score of 0.4393824136254908; loss of 0.06674779206514359; binary_accuracy of 97.97911047935486%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Cellular Component has 16 filters, with a kernel size of 128 and has an F1 score of 0.4393824136254908\n","Training for fold 9 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 16ms/step - loss: 0.0976 - binary_accuracy: 0.9721 - auc_78: 0.8304 - precision_78: 0.3731 - recall_78: 0.1909 - val_loss: 0.4519 - val_binary_accuracy: 0.9785 - val_auc_78: 0.8918 - val_precision_78: 0.7639 - val_recall_78: 0.2057\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0726 - binary_accuracy: 0.9791 - auc_78: 0.9068 - precision_78: 0.7521 - recall_78: 0.2322 - val_loss: 0.2640 - val_binary_accuracy: 0.9790 - val_auc_78: 0.9200 - val_precision_78: 0.7539 - val_recall_78: 0.2372\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0683 - binary_accuracy: 0.9795 - auc_78: 0.9235 - precision_78: 0.7468 - recall_78: 0.2580 - val_loss: 0.1181 - val_binary_accuracy: 0.9793 - val_auc_78: 0.9308 - val_precision_78: 0.7720 - val_recall_78: 0.2440\n","Epoch 4/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0659 - binary_accuracy: 0.9798 - auc_78: 0.9311 - precision_78: 0.7435 - recall_78: 0.2758 - val_loss: 0.0780 - val_binary_accuracy: 0.9794 - val_auc_78: 0.9354 - val_precision_78: 0.7144 - val_recall_78: 0.2940\n","Epoch 5/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0643 - binary_accuracy: 0.9800 - auc_78: 0.9354 - precision_78: 0.7417 - recall_78: 0.2898 - val_loss: 0.0660 - val_binary_accuracy: 0.9796 - val_auc_78: 0.9349 - val_precision_78: 0.7476 - val_recall_78: 0.2771\n","Score for fold 9: F1 score of 0.4043094466874317; loss of 0.06602612882852554; binary_accuracy of 97.95594811439514%\n","Training for fold 10 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 13ms/step - loss: 0.0977 - binary_accuracy: 0.9716 - auc_79: 0.8344 - precision_79: 0.3613 - recall_79: 0.1918 - val_loss: 0.4594 - val_binary_accuracy: 0.9788 - val_auc_79: 0.8977 - val_precision_79: 0.7237 - val_recall_79: 0.2272\n","Epoch 2/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0726 - binary_accuracy: 0.9791 - auc_79: 0.9081 - precision_79: 0.7494 - recall_79: 0.2307 - val_loss: 0.2603 - val_binary_accuracy: 0.9793 - val_auc_79: 0.9212 - val_precision_79: 0.7568 - val_recall_79: 0.2366\n","Epoch 3/5\n","149/149 [==============================] - 1s 9ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_79: 0.9227 - precision_79: 0.7487 - recall_79: 0.2559 - val_loss: 0.1260 - val_binary_accuracy: 0.9796 - val_auc_79: 0.9311 - val_precision_79: 0.7555 - val_recall_79: 0.2551\n","Epoch 4/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0664 - binary_accuracy: 0.9797 - auc_79: 0.9298 - precision_79: 0.7432 - recall_79: 0.2732 - val_loss: 0.0699 - val_binary_accuracy: 0.9798 - val_auc_79: 0.9361 - val_precision_79: 0.7678 - val_recall_79: 0.2596\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0648 - binary_accuracy: 0.9799 - auc_79: 0.9343 - precision_79: 0.7422 - recall_79: 0.2876 - val_loss: 0.0657 - val_binary_accuracy: 0.9799 - val_auc_79: 0.9381 - val_precision_79: 0.7385 - val_recall_79: 0.2850\n","Score for fold 10: F1 score of 0.4112599603064825; loss of 0.0656781941652298; binary_accuracy of 97.98504710197449%\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  256\n","Training for fold 1 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 18ms/step - loss: 0.0989 - binary_accuracy: 0.9720 - auc_80: 0.8276 - precision_80: 0.3672 - recall_80: 0.1868 - val_loss: 0.4284 - val_binary_accuracy: 0.9784 - val_auc_80: 0.8865 - val_precision_80: 0.7604 - val_recall_80: 0.1987\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0730 - binary_accuracy: 0.9791 - auc_80: 0.9052 - precision_80: 0.7513 - recall_80: 0.2292 - val_loss: 0.2370 - val_binary_accuracy: 0.9790 - val_auc_80: 0.9196 - val_precision_80: 0.7813 - val_recall_80: 0.2209\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0685 - binary_accuracy: 0.9795 - auc_80: 0.9227 - precision_80: 0.7460 - recall_80: 0.2576 - val_loss: 0.1255 - val_binary_accuracy: 0.9793 - val_auc_80: 0.9309 - val_precision_80: 0.7343 - val_recall_80: 0.2691\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_80: 0.9304 - precision_80: 0.7432 - recall_80: 0.2747 - val_loss: 0.0744 - val_binary_accuracy: 0.9794 - val_auc_80: 0.9351 - val_precision_80: 0.7537 - val_recall_80: 0.2626\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_80: 0.9347 - precision_80: 0.7408 - recall_80: 0.2880 - val_loss: 0.0697 - val_binary_accuracy: 0.9792 - val_auc_80: 0.9366 - val_precision_80: 0.6684 - val_recall_80: 0.3367\n","Score for fold 1: F1 score of 0.4478654546494135; loss of 0.06965097039937973; binary_accuracy of 97.92195558547974%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Cellular Component has 16 filters, with a kernel size of 256 and has an F1 score of 0.4478654546494135\n","Training for fold 2 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0995 - binary_accuracy: 0.9721 - auc_81: 0.8249 - precision_81: 0.3694 - recall_81: 0.1832 - val_loss: 0.4553 - val_binary_accuracy: 0.9784 - val_auc_81: 0.8768 - val_precision_81: 0.7362 - val_recall_81: 0.2033\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0739 - binary_accuracy: 0.9791 - auc_81: 0.9005 - precision_81: 0.7528 - recall_81: 0.2267 - val_loss: 0.2503 - val_binary_accuracy: 0.9791 - val_auc_81: 0.9184 - val_precision_81: 0.7592 - val_recall_81: 0.2334\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0687 - binary_accuracy: 0.9795 - auc_81: 0.9221 - precision_81: 0.7461 - recall_81: 0.2570 - val_loss: 0.1188 - val_binary_accuracy: 0.9794 - val_auc_81: 0.9295 - val_precision_81: 0.7344 - val_recall_81: 0.2668\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_81: 0.9301 - precision_81: 0.7439 - recall_81: 0.2752 - val_loss: 0.0765 - val_binary_accuracy: 0.9795 - val_auc_81: 0.9350 - val_precision_81: 0.7297 - val_recall_81: 0.2777\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_81: 0.9349 - precision_81: 0.7410 - recall_81: 0.2893 - val_loss: 0.0679 - val_binary_accuracy: 0.9795 - val_auc_81: 0.9369 - val_precision_81: 0.6940 - val_recall_81: 0.3151\n","Score for fold 2: F1 score of 0.43341838417366074; loss of 0.06785047054290771; binary_accuracy of 97.94996976852417%\n","Training for fold 3 ...\n","Epoch 1/5\n","149/149 [==============================] - 9s 15ms/step - loss: 0.0984 - binary_accuracy: 0.9722 - auc_82: 0.8272 - precision_82: 0.3737 - recall_82: 0.1862 - val_loss: 0.4573 - val_binary_accuracy: 0.9787 - val_auc_82: 0.8833 - val_precision_82: 0.7611 - val_recall_82: 0.2046\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0734 - binary_accuracy: 0.9791 - auc_82: 0.9033 - precision_82: 0.7496 - recall_82: 0.2305 - val_loss: 0.2594 - val_binary_accuracy: 0.9792 - val_auc_82: 0.9209 - val_precision_82: 0.7569 - val_recall_82: 0.2394\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0685 - binary_accuracy: 0.9795 - auc_82: 0.9228 - precision_82: 0.7463 - recall_82: 0.2588 - val_loss: 0.1263 - val_binary_accuracy: 0.9795 - val_auc_82: 0.9319 - val_precision_82: 0.7323 - val_recall_82: 0.2767\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_82: 0.9305 - precision_82: 0.7413 - recall_82: 0.2764 - val_loss: 0.0762 - val_binary_accuracy: 0.9797 - val_auc_82: 0.9367 - val_precision_82: 0.7311 - val_recall_82: 0.2862\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0643 - binary_accuracy: 0.9799 - auc_82: 0.9358 - precision_82: 0.7407 - recall_82: 0.2906 - val_loss: 0.0649 - val_binary_accuracy: 0.9798 - val_auc_82: 0.9342 - val_precision_82: 0.7649 - val_recall_82: 0.2675\n","Score for fold 3: F1 score of 0.3963413430284715; loss of 0.06494779884815216; binary_accuracy of 97.97888398170471%\n","Training for fold 4 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0993 - binary_accuracy: 0.9719 - auc_83: 0.8258 - precision_83: 0.3663 - recall_83: 0.1851 - val_loss: 0.4355 - val_binary_accuracy: 0.9789 - val_auc_83: 0.8820 - val_precision_83: 0.7551 - val_recall_83: 0.2050\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0736 - binary_accuracy: 0.9790 - auc_83: 0.9033 - precision_83: 0.7502 - recall_83: 0.2286 - val_loss: 0.2543 - val_binary_accuracy: 0.9795 - val_auc_83: 0.9209 - val_precision_83: 0.7586 - val_recall_83: 0.2390\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0687 - binary_accuracy: 0.9794 - auc_83: 0.9224 - precision_83: 0.7471 - recall_83: 0.2560 - val_loss: 0.1248 - val_binary_accuracy: 0.9798 - val_auc_83: 0.9317 - val_precision_83: 0.7264 - val_recall_83: 0.2794\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0664 - binary_accuracy: 0.9797 - auc_83: 0.9298 - precision_83: 0.7429 - recall_83: 0.2740 - val_loss: 0.0735 - val_binary_accuracy: 0.9800 - val_auc_83: 0.9360 - val_precision_83: 0.7436 - val_recall_83: 0.2792\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0649 - binary_accuracy: 0.9799 - auc_83: 0.9343 - precision_83: 0.7404 - recall_83: 0.2880 - val_loss: 0.0643 - val_binary_accuracy: 0.9801 - val_auc_83: 0.9367 - val_precision_83: 0.7568 - val_recall_83: 0.2762\n","Score for fold 4: F1 score of 0.40467662549657946; loss of 0.06433689594268799; binary_accuracy of 98.0083703994751%\n","Training for fold 5 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0982 - binary_accuracy: 0.9721 - auc_84: 0.8309 - precision_84: 0.3735 - recall_84: 0.1871 - val_loss: 0.4559 - val_binary_accuracy: 0.9788 - val_auc_84: 0.8924 - val_precision_84: 0.7547 - val_recall_84: 0.2055\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0728 - binary_accuracy: 0.9791 - auc_84: 0.9066 - precision_84: 0.7499 - recall_84: 0.2301 - val_loss: 0.2626 - val_binary_accuracy: 0.9793 - val_auc_84: 0.9231 - val_precision_84: 0.7804 - val_recall_84: 0.2232\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0684 - binary_accuracy: 0.9795 - auc_84: 0.9233 - precision_84: 0.7466 - recall_84: 0.2578 - val_loss: 0.1293 - val_binary_accuracy: 0.9797 - val_auc_84: 0.9333 - val_precision_84: 0.7244 - val_recall_84: 0.2841\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_84: 0.9306 - precision_84: 0.7437 - recall_84: 0.2748 - val_loss: 0.0768 - val_binary_accuracy: 0.9798 - val_auc_84: 0.9376 - val_precision_84: 0.7069 - val_recall_84: 0.3094\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_84: 0.9349 - precision_84: 0.7412 - recall_84: 0.2886 - val_loss: 0.0650 - val_binary_accuracy: 0.9799 - val_auc_84: 0.9378 - val_precision_84: 0.7139 - val_recall_84: 0.3104\n","Score for fold 5: F1 score of 0.4327080553382405; loss of 0.06497904658317566; binary_accuracy of 97.99242615699768%\n","Training for fold 6 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0992 - binary_accuracy: 0.9721 - auc_85: 0.8249 - precision_85: 0.3719 - recall_85: 0.1864 - val_loss: 0.4546 - val_binary_accuracy: 0.9788 - val_auc_85: 0.8805 - val_precision_85: 0.7535 - val_recall_85: 0.2050\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0736 - binary_accuracy: 0.9790 - auc_85: 0.9027 - precision_85: 0.7544 - recall_85: 0.2266 - val_loss: 0.2548 - val_binary_accuracy: 0.9794 - val_auc_85: 0.9198 - val_precision_85: 0.7399 - val_recall_85: 0.2507\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0687 - binary_accuracy: 0.9795 - auc_85: 0.9223 - precision_85: 0.7470 - recall_85: 0.2569 - val_loss: 0.1161 - val_binary_accuracy: 0.9797 - val_auc_85: 0.9309 - val_precision_85: 0.7707 - val_recall_85: 0.2458\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0663 - binary_accuracy: 0.9797 - auc_85: 0.9299 - precision_85: 0.7426 - recall_85: 0.2745 - val_loss: 0.0706 - val_binary_accuracy: 0.9799 - val_auc_85: 0.9355 - val_precision_85: 0.7440 - val_recall_85: 0.2752\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_85: 0.9354 - precision_85: 0.7414 - recall_85: 0.2894 - val_loss: 0.0651 - val_binary_accuracy: 0.9800 - val_auc_85: 0.9349 - val_precision_85: 0.7393 - val_recall_85: 0.2860\n","Score for fold 6: F1 score of 0.4124682916363331; loss of 0.06509235501289368; binary_accuracy of 97.99739122390747%\n","Training for fold 7 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0990 - binary_accuracy: 0.9719 - auc_86: 0.8286 - precision_86: 0.3653 - recall_86: 0.1866 - val_loss: 0.4481 - val_binary_accuracy: 0.9788 - val_auc_86: 0.8917 - val_precision_86: 0.7408 - val_recall_86: 0.2164\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0731 - binary_accuracy: 0.9790 - auc_86: 0.9057 - precision_86: 0.7511 - recall_86: 0.2288 - val_loss: 0.2586 - val_binary_accuracy: 0.9794 - val_auc_86: 0.9213 - val_precision_86: 0.7371 - val_recall_86: 0.2568\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0687 - binary_accuracy: 0.9794 - auc_86: 0.9224 - precision_86: 0.7451 - recall_86: 0.2570 - val_loss: 0.1187 - val_binary_accuracy: 0.9797 - val_auc_86: 0.9316 - val_precision_86: 0.7573 - val_recall_86: 0.2607\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0664 - binary_accuracy: 0.9797 - auc_86: 0.9299 - precision_86: 0.7427 - recall_86: 0.2741 - val_loss: 0.0726 - val_binary_accuracy: 0.9799 - val_auc_86: 0.9359 - val_precision_86: 0.7668 - val_recall_86: 0.2641\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_86: 0.9348 - precision_86: 0.7410 - recall_86: 0.2883 - val_loss: 0.0648 - val_binary_accuracy: 0.9800 - val_auc_86: 0.9357 - val_precision_86: 0.7616 - val_recall_86: 0.2739\n","Score for fold 7: F1 score of 0.40293728327424466; loss of 0.06479691714048386; binary_accuracy of 97.9992926120758%\n","Training for fold 8 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0979 - binary_accuracy: 0.9724 - auc_87: 0.8303 - precision_87: 0.3820 - recall_87: 0.1883 - val_loss: 0.4328 - val_binary_accuracy: 0.9789 - val_auc_87: 0.8894 - val_precision_87: 0.7437 - val_recall_87: 0.2073\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0731 - binary_accuracy: 0.9790 - auc_87: 0.9057 - precision_87: 0.7510 - recall_87: 0.2298 - val_loss: 0.2305 - val_binary_accuracy: 0.9794 - val_auc_87: 0.9180 - val_precision_87: 0.7833 - val_recall_87: 0.2166\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0686 - binary_accuracy: 0.9795 - auc_87: 0.9229 - precision_87: 0.7459 - recall_87: 0.2584 - val_loss: 0.1207 - val_binary_accuracy: 0.9798 - val_auc_87: 0.9305 - val_precision_87: 0.7403 - val_recall_87: 0.2651\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_87: 0.9305 - precision_87: 0.7433 - recall_87: 0.2756 - val_loss: 0.0723 - val_binary_accuracy: 0.9799 - val_auc_87: 0.9341 - val_precision_87: 0.7502 - val_recall_87: 0.2641\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_87: 0.9352 - precision_87: 0.7407 - recall_87: 0.2891 - val_loss: 0.0666 - val_binary_accuracy: 0.9800 - val_auc_87: 0.9357 - val_precision_87: 0.7020 - val_recall_87: 0.3135\n","Score for fold 8: F1 score of 0.43342455911780925; loss of 0.0666317269206047; binary_accuracy of 97.99893498420715%\n","Training for fold 9 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 18ms/step - loss: 0.0989 - binary_accuracy: 0.9720 - auc_88: 0.8263 - precision_88: 0.3675 - recall_88: 0.1858 - val_loss: 0.4614 - val_binary_accuracy: 0.9785 - val_auc_88: 0.8796 - val_precision_88: 0.7563 - val_recall_88: 0.2035\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0736 - binary_accuracy: 0.9791 - auc_88: 0.9016 - precision_88: 0.7517 - recall_88: 0.2285 - val_loss: 0.2503 - val_binary_accuracy: 0.9791 - val_auc_88: 0.9172 - val_precision_88: 0.7802 - val_recall_88: 0.2216\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0684 - binary_accuracy: 0.9795 - auc_88: 0.9229 - precision_88: 0.7483 - recall_88: 0.2577 - val_loss: 0.1200 - val_binary_accuracy: 0.9794 - val_auc_88: 0.9293 - val_precision_88: 0.7423 - val_recall_88: 0.2630\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0660 - binary_accuracy: 0.9798 - auc_88: 0.9307 - precision_88: 0.7431 - recall_88: 0.2761 - val_loss: 0.0736 - val_binary_accuracy: 0.9795 - val_auc_88: 0.9338 - val_precision_88: 0.7254 - val_recall_88: 0.2838\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0642 - binary_accuracy: 0.9800 - auc_88: 0.9359 - precision_88: 0.7422 - recall_88: 0.2903 - val_loss: 0.0661 - val_binary_accuracy: 0.9796 - val_auc_88: 0.9335 - val_precision_88: 0.7477 - val_recall_88: 0.2726\n","Score for fold 9: F1 score of 0.3995041674979445; loss of 0.06612394005060196; binary_accuracy of 97.95839190483093%\n","Training for fold 10 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 14ms/step - loss: 0.0982 - binary_accuracy: 0.9717 - auc_89: 0.8319 - precision_89: 0.3647 - recall_89: 0.1930 - val_loss: 0.4439 - val_binary_accuracy: 0.9787 - val_auc_89: 0.8957 - val_precision_89: 0.7704 - val_recall_89: 0.2007\n","Epoch 2/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0729 - binary_accuracy: 0.9791 - auc_89: 0.9063 - precision_89: 0.7486 - recall_89: 0.2312 - val_loss: 0.2630 - val_binary_accuracy: 0.9791 - val_auc_89: 0.9204 - val_precision_89: 0.7368 - val_recall_89: 0.2495\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0688 - binary_accuracy: 0.9795 - auc_89: 0.9218 - precision_89: 0.7471 - recall_89: 0.2555 - val_loss: 0.1195 - val_binary_accuracy: 0.9793 - val_auc_89: 0.9307 - val_precision_89: 0.7707 - val_recall_89: 0.2380\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0667 - binary_accuracy: 0.9797 - auc_89: 0.9286 - precision_89: 0.7416 - recall_89: 0.2735 - val_loss: 0.0728 - val_binary_accuracy: 0.9795 - val_auc_89: 0.9357 - val_precision_89: 0.7646 - val_recall_89: 0.2544\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0649 - binary_accuracy: 0.9799 - auc_89: 0.9339 - precision_89: 0.7417 - recall_89: 0.2864 - val_loss: 0.0659 - val_binary_accuracy: 0.9797 - val_auc_89: 0.9366 - val_precision_89: 0.7452 - val_recall_89: 0.2787\n","Score for fold 10: F1 score of 0.4056363560099418; loss of 0.0658782571554184; binary_accuracy of 97.97212481498718%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  64\n","Training for fold 1 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0960 - binary_accuracy: 0.9721 - auc_90: 0.8342 - precision_90: 0.3736 - recall_90: 0.1915 - val_loss: 0.4611 - val_binary_accuracy: 0.9788 - val_auc_90: 0.8886 - val_precision_90: 0.7593 - val_recall_90: 0.2125\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0725 - binary_accuracy: 0.9792 - auc_90: 0.9064 - precision_90: 0.7511 - recall_90: 0.2357 - val_loss: 0.2622 - val_binary_accuracy: 0.9794 - val_auc_90: 0.9226 - val_precision_90: 0.7599 - val_recall_90: 0.2453\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0681 - binary_accuracy: 0.9795 - auc_90: 0.9236 - precision_90: 0.7441 - recall_90: 0.2627 - val_loss: 0.1238 - val_binary_accuracy: 0.9796 - val_auc_90: 0.9316 - val_precision_90: 0.7546 - val_recall_90: 0.2618\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0656 - binary_accuracy: 0.9798 - auc_90: 0.9317 - precision_90: 0.7432 - recall_90: 0.2798 - val_loss: 0.0751 - val_binary_accuracy: 0.9798 - val_auc_90: 0.9367 - val_precision_90: 0.7331 - val_recall_90: 0.2942\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_90: 0.9367 - precision_90: 0.7417 - recall_90: 0.2941 - val_loss: 0.0653 - val_binary_accuracy: 0.9799 - val_auc_90: 0.9357 - val_precision_90: 0.7521 - val_recall_90: 0.2801\n","Score for fold 1: F1 score of 0.4082308649849296; loss of 0.06527765840291977; binary_accuracy of 97.98539876937866%\n","Training for fold 2 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0956 - binary_accuracy: 0.9722 - auc_91: 0.8371 - precision_91: 0.3784 - recall_91: 0.1935 - val_loss: 0.4577 - val_binary_accuracy: 0.9788 - val_auc_91: 0.8976 - val_precision_91: 0.7665 - val_recall_91: 0.2112\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0718 - binary_accuracy: 0.9792 - auc_91: 0.9102 - precision_91: 0.7524 - recall_91: 0.2369 - val_loss: 0.2633 - val_binary_accuracy: 0.9793 - val_auc_91: 0.9235 - val_precision_91: 0.7359 - val_recall_91: 0.2602\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0677 - binary_accuracy: 0.9796 - auc_91: 0.9249 - precision_91: 0.7468 - recall_91: 0.2641 - val_loss: 0.1177 - val_binary_accuracy: 0.9795 - val_auc_91: 0.9329 - val_precision_91: 0.7229 - val_recall_91: 0.2847\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0655 - binary_accuracy: 0.9798 - auc_91: 0.9320 - precision_91: 0.7421 - recall_91: 0.2825 - val_loss: 0.0727 - val_binary_accuracy: 0.9797 - val_auc_91: 0.9374 - val_precision_91: 0.7555 - val_recall_91: 0.2695\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_91: 0.9367 - precision_91: 0.7414 - recall_91: 0.2957 - val_loss: 0.0651 - val_binary_accuracy: 0.9797 - val_auc_91: 0.9345 - val_precision_91: 0.7555 - val_recall_91: 0.2735\n","Score for fold 2: F1 score of 0.4016360512538314; loss of 0.06514819711446762; binary_accuracy of 97.97316193580627%\n","Training for fold 3 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0941 - binary_accuracy: 0.9722 - auc_92: 0.8448 - precision_92: 0.3790 - recall_92: 0.1966 - val_loss: 0.4428 - val_binary_accuracy: 0.9788 - val_auc_92: 0.9032 - val_precision_92: 0.7742 - val_recall_92: 0.2074\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0713 - binary_accuracy: 0.9793 - auc_92: 0.9121 - precision_92: 0.7513 - recall_92: 0.2410 - val_loss: 0.2639 - val_binary_accuracy: 0.9794 - val_auc_92: 0.9253 - val_precision_92: 0.7527 - val_recall_92: 0.2518\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0678 - binary_accuracy: 0.9796 - auc_92: 0.9247 - precision_92: 0.7422 - recall_92: 0.2666 - val_loss: 0.1379 - val_binary_accuracy: 0.9795 - val_auc_92: 0.9336 - val_precision_92: 0.7147 - val_recall_92: 0.2913\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0654 - binary_accuracy: 0.9799 - auc_92: 0.9322 - precision_92: 0.7425 - recall_92: 0.2833 - val_loss: 0.0749 - val_binary_accuracy: 0.9796 - val_auc_92: 0.9377 - val_precision_92: 0.7082 - val_recall_92: 0.3030\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0641 - binary_accuracy: 0.9800 - auc_92: 0.9359 - precision_92: 0.7397 - recall_92: 0.2952 - val_loss: 0.0653 - val_binary_accuracy: 0.9798 - val_auc_92: 0.9387 - val_precision_92: 0.7400 - val_recall_92: 0.2905\n","Score for fold 3: F1 score of 0.41721089542430856; loss of 0.06528561562299728; binary_accuracy of 97.98482656478882%\n","Training for fold 4 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0955 - binary_accuracy: 0.9720 - auc_93: 0.8375 - precision_93: 0.3722 - recall_93: 0.1926 - val_loss: 0.4279 - val_binary_accuracy: 0.9785 - val_auc_93: 0.8930 - val_precision_93: 0.7850 - val_recall_93: 0.1948\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0719 - binary_accuracy: 0.9793 - auc_93: 0.9089 - precision_93: 0.7513 - recall_93: 0.2390 - val_loss: 0.2639 - val_binary_accuracy: 0.9790 - val_auc_93: 0.9208 - val_precision_93: 0.7485 - val_recall_93: 0.2441\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0678 - binary_accuracy: 0.9796 - auc_93: 0.9244 - precision_93: 0.7467 - recall_93: 0.2654 - val_loss: 0.1177 - val_binary_accuracy: 0.9792 - val_auc_93: 0.9299 - val_precision_93: 0.7698 - val_recall_93: 0.2412\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0655 - binary_accuracy: 0.9799 - auc_93: 0.9316 - precision_93: 0.7432 - recall_93: 0.2828 - val_loss: 0.0712 - val_binary_accuracy: 0.9793 - val_auc_93: 0.9346 - val_precision_93: 0.7658 - val_recall_93: 0.2537\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0639 - binary_accuracy: 0.9801 - auc_93: 0.9363 - precision_93: 0.7418 - recall_93: 0.2957 - val_loss: 0.0665 - val_binary_accuracy: 0.9793 - val_auc_93: 0.9332 - val_precision_93: 0.7719 - val_recall_93: 0.2507\n","Score for fold 4: F1 score of 0.3785010880674019; loss of 0.06645671278238297; binary_accuracy of 97.93433547019958%\n","Training for fold 5 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0955 - binary_accuracy: 0.9722 - auc_94: 0.8379 - precision_94: 0.3786 - recall_94: 0.1911 - val_loss: 0.4227 - val_binary_accuracy: 0.9789 - val_auc_94: 0.8964 - val_precision_94: 0.7672 - val_recall_94: 0.2033\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0722 - binary_accuracy: 0.9792 - auc_94: 0.9086 - precision_94: 0.7514 - recall_94: 0.2363 - val_loss: 0.2569 - val_binary_accuracy: 0.9795 - val_auc_94: 0.9237 - val_precision_94: 0.7378 - val_recall_94: 0.2580\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0680 - binary_accuracy: 0.9796 - auc_94: 0.9242 - precision_94: 0.7459 - recall_94: 0.2639 - val_loss: 0.1220 - val_binary_accuracy: 0.9798 - val_auc_94: 0.9340 - val_precision_94: 0.7377 - val_recall_94: 0.2772\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0659 - binary_accuracy: 0.9798 - auc_94: 0.9307 - precision_94: 0.7417 - recall_94: 0.2811 - val_loss: 0.0767 - val_binary_accuracy: 0.9799 - val_auc_94: 0.9385 - val_precision_94: 0.7030 - val_recall_94: 0.3134\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0641 - binary_accuracy: 0.9800 - auc_94: 0.9363 - precision_94: 0.7419 - recall_94: 0.2936 - val_loss: 0.0670 - val_binary_accuracy: 0.9797 - val_auc_94: 0.9404 - val_precision_94: 0.6758 - val_recall_94: 0.3371\n","Score for fold 5: F1 score of 0.44982171968108764; loss of 0.06704075634479523; binary_accuracy of 97.97170758247375%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_CC_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Cellular Component has 32 filters, with a kernel size of 64 and has an F1 score of 0.44982171968108764\n","Training for fold 6 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0946 - binary_accuracy: 0.9723 - auc_95: 0.8423 - precision_95: 0.3829 - recall_95: 0.1965 - val_loss: 0.4454 - val_binary_accuracy: 0.9789 - val_auc_95: 0.9024 - val_precision_95: 0.7671 - val_recall_95: 0.2135\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0715 - binary_accuracy: 0.9792 - auc_95: 0.9110 - precision_95: 0.7519 - recall_95: 0.2388 - val_loss: 0.2647 - val_binary_accuracy: 0.9793 - val_auc_95: 0.9248 - val_precision_95: 0.7270 - val_recall_95: 0.2653\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0677 - binary_accuracy: 0.9796 - auc_95: 0.9252 - precision_95: 0.7445 - recall_95: 0.2653 - val_loss: 0.1170 - val_binary_accuracy: 0.9796 - val_auc_95: 0.9334 - val_precision_95: 0.7762 - val_recall_95: 0.2495\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0656 - binary_accuracy: 0.9798 - auc_95: 0.9316 - precision_95: 0.7414 - recall_95: 0.2829 - val_loss: 0.0688 - val_binary_accuracy: 0.9797 - val_auc_95: 0.9365 - val_precision_95: 0.7947 - val_recall_95: 0.2430\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0638 - binary_accuracy: 0.9800 - auc_95: 0.9369 - precision_95: 0.7417 - recall_95: 0.2960 - val_loss: 0.0647 - val_binary_accuracy: 0.9799 - val_auc_95: 0.9360 - val_precision_95: 0.7412 - val_recall_95: 0.2909\n","Score for fold 6: F1 score of 0.41780093084688025; loss of 0.06470781564712524; binary_accuracy of 97.9903519153595%\n","Training for fold 7 ...\n","Epoch 1/5\n","149/149 [==============================] - 14s 14ms/step - loss: 0.0952 - binary_accuracy: 0.9726 - auc_96: 0.8379 - precision_96: 0.3909 - recall_96: 0.1941 - val_loss: 0.4353 - val_binary_accuracy: 0.9786 - val_auc_96: 0.8932 - val_precision_96: 0.7576 - val_recall_96: 0.2107\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0719 - binary_accuracy: 0.9792 - auc_96: 0.9091 - precision_96: 0.7530 - recall_96: 0.2371 - val_loss: 0.2598 - val_binary_accuracy: 0.9791 - val_auc_96: 0.9224 - val_precision_96: 0.7454 - val_recall_96: 0.2472\n","Epoch 3/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0678 - binary_accuracy: 0.9796 - auc_96: 0.9245 - precision_96: 0.7468 - recall_96: 0.2639 - val_loss: 0.1185 - val_binary_accuracy: 0.9794 - val_auc_96: 0.9311 - val_precision_96: 0.7499 - val_recall_96: 0.2608\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0656 - binary_accuracy: 0.9798 - auc_96: 0.9314 - precision_96: 0.7433 - recall_96: 0.2808 - val_loss: 0.0760 - val_binary_accuracy: 0.9795 - val_auc_96: 0.9360 - val_precision_96: 0.7176 - val_recall_96: 0.2956\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0640 - binary_accuracy: 0.9800 - auc_96: 0.9363 - precision_96: 0.7413 - recall_96: 0.2950 - val_loss: 0.0659 - val_binary_accuracy: 0.9795 - val_auc_96: 0.9319 - val_precision_96: 0.7919 - val_recall_96: 0.2444\n","Score for fold 7: F1 score of 0.37346923803154947; loss of 0.06593155115842819; binary_accuracy of 97.95488119125366%\n","Training for fold 8 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0955 - binary_accuracy: 0.9721 - auc_97: 0.8379 - precision_97: 0.3727 - recall_97: 0.1920 - val_loss: 0.4580 - val_binary_accuracy: 0.9787 - val_auc_97: 0.8944 - val_precision_97: 0.7609 - val_recall_97: 0.2118\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0720 - binary_accuracy: 0.9792 - auc_97: 0.9086 - precision_97: 0.7517 - recall_97: 0.2370 - val_loss: 0.2638 - val_binary_accuracy: 0.9792 - val_auc_97: 0.9219 - val_precision_97: 0.7539 - val_recall_97: 0.2444\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0679 - binary_accuracy: 0.9796 - auc_97: 0.9243 - precision_97: 0.7466 - recall_97: 0.2640 - val_loss: 0.1378 - val_binary_accuracy: 0.9793 - val_auc_97: 0.9316 - val_precision_97: 0.6883 - val_recall_97: 0.3067\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0658 - binary_accuracy: 0.9798 - auc_97: 0.9308 - precision_97: 0.7408 - recall_97: 0.2819 - val_loss: 0.0697 - val_binary_accuracy: 0.9796 - val_auc_97: 0.9344 - val_precision_97: 0.7514 - val_recall_97: 0.2712\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0640 - binary_accuracy: 0.9800 - auc_97: 0.9361 - precision_97: 0.7420 - recall_97: 0.2938 - val_loss: 0.0669 - val_binary_accuracy: 0.9797 - val_auc_97: 0.9373 - val_precision_97: 0.7094 - val_recall_97: 0.3116\n","Score for fold 8: F1 score of 0.4330087581117998; loss of 0.066912442445755; binary_accuracy of 97.96598553657532%\n","Training for fold 9 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0945 - binary_accuracy: 0.9721 - auc_98: 0.8429 - precision_98: 0.3792 - recall_98: 0.1959 - val_loss: 0.4512 - val_binary_accuracy: 0.9794 - val_auc_98: 0.9031 - val_precision_98: 0.7673 - val_recall_98: 0.2143\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0716 - binary_accuracy: 0.9792 - auc_98: 0.9114 - precision_98: 0.7493 - recall_98: 0.2408 - val_loss: 0.2538 - val_binary_accuracy: 0.9798 - val_auc_98: 0.9261 - val_precision_98: 0.7649 - val_recall_98: 0.2427\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0678 - binary_accuracy: 0.9795 - auc_98: 0.9252 - precision_98: 0.7442 - recall_98: 0.2664 - val_loss: 0.1284 - val_binary_accuracy: 0.9801 - val_auc_98: 0.9343 - val_precision_98: 0.7264 - val_recall_98: 0.2867\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0656 - binary_accuracy: 0.9798 - auc_98: 0.9323 - precision_98: 0.7404 - recall_98: 0.2845 - val_loss: 0.0680 - val_binary_accuracy: 0.9802 - val_auc_98: 0.9373 - val_precision_98: 0.7591 - val_recall_98: 0.2687\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0640 - binary_accuracy: 0.9800 - auc_98: 0.9366 - precision_98: 0.7407 - recall_98: 0.2962 - val_loss: 0.0633 - val_binary_accuracy: 0.9804 - val_auc_98: 0.9385 - val_precision_98: 0.7365 - val_recall_98: 0.2957\n","Score for fold 9: F1 score of 0.42201248862209995; loss of 0.06328465044498444; binary_accuracy of 98.03765416145325%\n","Training for fold 10 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 14ms/step - loss: 0.0956 - binary_accuracy: 0.9724 - auc_99: 0.8373 - precision_99: 0.3854 - recall_99: 0.1937 - val_loss: 0.4589 - val_binary_accuracy: 0.9794 - val_auc_99: 0.8989 - val_precision_99: 0.7291 - val_recall_99: 0.2359\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0721 - binary_accuracy: 0.9791 - auc_99: 0.9097 - precision_99: 0.7473 - recall_99: 0.2373 - val_loss: 0.2630 - val_binary_accuracy: 0.9799 - val_auc_99: 0.9243 - val_precision_99: 0.7522 - val_recall_99: 0.2539\n","Epoch 3/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0679 - binary_accuracy: 0.9795 - auc_99: 0.9250 - precision_99: 0.7459 - recall_99: 0.2628 - val_loss: 0.1156 - val_binary_accuracy: 0.9802 - val_auc_99: 0.9327 - val_precision_99: 0.7516 - val_recall_99: 0.2688\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0659 - binary_accuracy: 0.9797 - auc_99: 0.9313 - precision_99: 0.7401 - recall_99: 0.2810 - val_loss: 0.0686 - val_binary_accuracy: 0.9802 - val_auc_99: 0.9358 - val_precision_99: 0.7623 - val_recall_99: 0.2639\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0643 - binary_accuracy: 0.9799 - auc_99: 0.9359 - precision_99: 0.7412 - recall_99: 0.2922 - val_loss: 0.0640 - val_binary_accuracy: 0.9804 - val_auc_99: 0.9380 - val_precision_99: 0.7257 - val_recall_99: 0.3054\n","Score for fold 10: F1 score of 0.4298504420148174; loss of 0.06403881311416626; binary_accuracy of 98.0395495891571%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  128\n","Training for fold 1 ...\n","Epoch 1/5\n","149/149 [==============================] - 9s 49ms/step - loss: 0.0949 - binary_accuracy: 0.9723 - auc_100: 0.8417 - precision_100: 0.3818 - recall_100: 0.1959 - val_loss: 0.4297 - val_binary_accuracy: 0.9790 - val_auc_100: 0.9023 - val_precision_100: 0.7687 - val_recall_100: 0.2128\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0713 - binary_accuracy: 0.9792 - auc_100: 0.9122 - precision_100: 0.7496 - recall_100: 0.2412 - val_loss: 0.2604 - val_binary_accuracy: 0.9795 - val_auc_100: 0.9255 - val_precision_100: 0.7638 - val_recall_100: 0.2444\n","Epoch 3/5\n","149/149 [==============================] - 2s 15ms/step - loss: 0.0674 - binary_accuracy: 0.9796 - auc_100: 0.9261 - precision_100: 0.7445 - recall_100: 0.2674 - val_loss: 0.1287 - val_binary_accuracy: 0.9798 - val_auc_100: 0.9341 - val_precision_100: 0.7263 - val_recall_100: 0.2865\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0652 - binary_accuracy: 0.9799 - auc_100: 0.9328 - precision_100: 0.7408 - recall_100: 0.2856 - val_loss: 0.0728 - val_binary_accuracy: 0.9799 - val_auc_100: 0.9378 - val_precision_100: 0.7253 - val_recall_100: 0.2939\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0636 - binary_accuracy: 0.9801 - auc_100: 0.9376 - precision_100: 0.7412 - recall_100: 0.2983 - val_loss: 0.0665 - val_binary_accuracy: 0.9798 - val_auc_100: 0.9397 - val_precision_100: 0.6890 - val_recall_100: 0.3302\n","Score for fold 1: F1 score of 0.4464586927933809; loss of 0.0664513036608696; binary_accuracy of 97.98356890678406%\n","Training for fold 2 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0957 - binary_accuracy: 0.9721 - auc_101: 0.8372 - precision_101: 0.3745 - recall_101: 0.1913 - val_loss: 0.4401 - val_binary_accuracy: 0.9789 - val_auc_101: 0.8947 - val_precision_101: 0.7606 - val_recall_101: 0.2076\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0722 - binary_accuracy: 0.9792 - auc_101: 0.9081 - precision_101: 0.7502 - recall_101: 0.2361 - val_loss: 0.2471 - val_binary_accuracy: 0.9794 - val_auc_101: 0.9223 - val_precision_101: 0.7714 - val_recall_101: 0.2313\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0681 - binary_accuracy: 0.9795 - auc_101: 0.9237 - precision_101: 0.7437 - recall_101: 0.2637 - val_loss: 0.1163 - val_binary_accuracy: 0.9797 - val_auc_101: 0.9315 - val_precision_101: 0.7595 - val_recall_101: 0.2561\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0657 - binary_accuracy: 0.9798 - auc_101: 0.9314 - precision_101: 0.7419 - recall_101: 0.2804 - val_loss: 0.0759 - val_binary_accuracy: 0.9798 - val_auc_101: 0.9364 - val_precision_101: 0.7261 - val_recall_101: 0.2922\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0641 - binary_accuracy: 0.9800 - auc_101: 0.9359 - precision_101: 0.7407 - recall_101: 0.2943 - val_loss: 0.0654 - val_binary_accuracy: 0.9799 - val_auc_101: 0.9371 - val_precision_101: 0.7149 - val_recall_101: 0.3058\n","Score for fold 2: F1 score of 0.42833532353476644; loss of 0.0654120072722435; binary_accuracy of 97.98938035964966%\n","Training for fold 3 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 14ms/step - loss: 0.0952 - binary_accuracy: 0.9721 - auc_102: 0.8409 - precision_102: 0.3779 - recall_102: 0.1944 - val_loss: 0.4378 - val_binary_accuracy: 0.9791 - val_auc_102: 0.8999 - val_precision_102: 0.7508 - val_recall_102: 0.2162\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0718 - binary_accuracy: 0.9792 - auc_102: 0.9110 - precision_102: 0.7495 - recall_102: 0.2378 - val_loss: 0.2509 - val_binary_accuracy: 0.9796 - val_auc_102: 0.9228 - val_precision_102: 0.7544 - val_recall_102: 0.2446\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0680 - binary_accuracy: 0.9795 - auc_102: 0.9246 - precision_102: 0.7451 - recall_102: 0.2640 - val_loss: 0.1200 - val_binary_accuracy: 0.9798 - val_auc_102: 0.9310 - val_precision_102: 0.7553 - val_recall_102: 0.2575\n","Epoch 4/5\n","149/149 [==============================] - 2s 14ms/step - loss: 0.0657 - binary_accuracy: 0.9798 - auc_102: 0.9319 - precision_102: 0.7433 - recall_102: 0.2808 - val_loss: 0.0769 - val_binary_accuracy: 0.9800 - val_auc_102: 0.9359 - val_precision_102: 0.7233 - val_recall_102: 0.2947\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0641 - binary_accuracy: 0.9800 - auc_102: 0.9363 - precision_102: 0.7425 - recall_102: 0.2949 - val_loss: 0.0661 - val_binary_accuracy: 0.9801 - val_auc_102: 0.9368 - val_precision_102: 0.7199 - val_recall_102: 0.3051\n","Score for fold 3: F1 score of 0.4285206603313586; loss of 0.06614116579294205; binary_accuracy of 98.01153540611267%\n","Training for fold 4 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0945 - binary_accuracy: 0.9725 - auc_103: 0.8422 - precision_103: 0.3898 - recall_103: 0.1968 - val_loss: 0.4305 - val_binary_accuracy: 0.9790 - val_auc_103: 0.9018 - val_precision_103: 0.7899 - val_recall_103: 0.1989\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0713 - binary_accuracy: 0.9792 - auc_103: 0.9121 - precision_103: 0.7488 - recall_103: 0.2411 - val_loss: 0.2577 - val_binary_accuracy: 0.9796 - val_auc_103: 0.9253 - val_precision_103: 0.7594 - val_recall_103: 0.2498\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0675 - binary_accuracy: 0.9796 - auc_103: 0.9260 - precision_103: 0.7436 - recall_103: 0.2678 - val_loss: 0.1196 - val_binary_accuracy: 0.9799 - val_auc_103: 0.9336 - val_precision_103: 0.7491 - val_recall_103: 0.2714\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0653 - binary_accuracy: 0.9798 - auc_103: 0.9326 - precision_103: 0.7401 - recall_103: 0.2848 - val_loss: 0.0735 - val_binary_accuracy: 0.9800 - val_auc_103: 0.9374 - val_precision_103: 0.7403 - val_recall_103: 0.2860\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0636 - binary_accuracy: 0.9801 - auc_103: 0.9377 - precision_103: 0.7408 - recall_103: 0.2983 - val_loss: 0.0641 - val_binary_accuracy: 0.9801 - val_auc_103: 0.9358 - val_precision_103: 0.7374 - val_recall_103: 0.2941\n","Score for fold 4: F1 score of 0.42052699074327604; loss of 0.06411214172840118; binary_accuracy of 98.00746440887451%\n","Training for fold 5 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 14ms/step - loss: 0.0956 - binary_accuracy: 0.9725 - auc_104: 0.8353 - precision_104: 0.3873 - recall_104: 0.1914 - val_loss: 0.4479 - val_binary_accuracy: 0.9787 - val_auc_104: 0.8939 - val_precision_104: 0.7625 - val_recall_104: 0.2120\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0719 - binary_accuracy: 0.9792 - auc_104: 0.9090 - precision_104: 0.7474 - recall_104: 0.2397 - val_loss: 0.2473 - val_binary_accuracy: 0.9792 - val_auc_104: 0.9241 - val_precision_104: 0.7795 - val_recall_104: 0.2320\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0675 - binary_accuracy: 0.9796 - auc_104: 0.9258 - precision_104: 0.7438 - recall_104: 0.2668 - val_loss: 0.1195 - val_binary_accuracy: 0.9795 - val_auc_104: 0.9337 - val_precision_104: 0.7589 - val_recall_104: 0.2599\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0652 - binary_accuracy: 0.9799 - auc_104: 0.9328 - precision_104: 0.7393 - recall_104: 0.2853 - val_loss: 0.0747 - val_binary_accuracy: 0.9797 - val_auc_104: 0.9383 - val_precision_104: 0.7344 - val_recall_104: 0.2900\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0636 - binary_accuracy: 0.9801 - auc_104: 0.9374 - precision_104: 0.7398 - recall_104: 0.2981 - val_loss: 0.0651 - val_binary_accuracy: 0.9797 - val_auc_104: 0.9358 - val_precision_104: 0.7348 - val_recall_104: 0.2930\n","Score for fold 5: F1 score of 0.41894526379893476; loss of 0.06510566174983978; binary_accuracy of 97.97133803367615%\n","Training for fold 6 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 14ms/step - loss: 0.0959 - binary_accuracy: 0.9724 - auc_105: 0.8331 - precision_105: 0.3839 - recall_105: 0.1907 - val_loss: 0.4623 - val_binary_accuracy: 0.9786 - val_auc_105: 0.8881 - val_precision_105: 0.7373 - val_recall_105: 0.2210\n","Epoch 2/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0724 - binary_accuracy: 0.9792 - auc_105: 0.9066 - precision_105: 0.7488 - recall_105: 0.2362 - val_loss: 0.2666 - val_binary_accuracy: 0.9793 - val_auc_105: 0.9231 - val_precision_105: 0.7483 - val_recall_105: 0.2535\n","Epoch 3/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0677 - binary_accuracy: 0.9796 - auc_105: 0.9249 - precision_105: 0.7431 - recall_105: 0.2654 - val_loss: 0.1125 - val_binary_accuracy: 0.9795 - val_auc_105: 0.9321 - val_precision_105: 0.7759 - val_recall_105: 0.2471\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0657 - binary_accuracy: 0.9798 - auc_105: 0.9312 - precision_105: 0.7396 - recall_105: 0.2820 - val_loss: 0.0741 - val_binary_accuracy: 0.9797 - val_auc_105: 0.9375 - val_precision_105: 0.7424 - val_recall_105: 0.2829\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_105: 0.9365 - precision_105: 0.7397 - recall_105: 0.2953 - val_loss: 0.0661 - val_binary_accuracy: 0.9797 - val_auc_105: 0.9384 - val_precision_105: 0.7583 - val_recall_105: 0.2743\n","Score for fold 6: F1 score of 0.402896537013338; loss of 0.06611141562461853; binary_accuracy of 97.97362089157104%\n","Training for fold 7 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 13ms/step - loss: 0.0964 - binary_accuracy: 0.9721 - auc_106: 0.8329 - precision_106: 0.3744 - recall_106: 0.1911 - val_loss: 0.4453 - val_binary_accuracy: 0.9788 - val_auc_106: 0.8886 - val_precision_106: 0.7898 - val_recall_106: 0.1953\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0726 - binary_accuracy: 0.9792 - auc_106: 0.9056 - precision_106: 0.7523 - recall_106: 0.2360 - val_loss: 0.2449 - val_binary_accuracy: 0.9794 - val_auc_106: 0.9220 - val_precision_106: 0.7793 - val_recall_106: 0.2297\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0681 - binary_accuracy: 0.9796 - auc_106: 0.9236 - precision_106: 0.7444 - recall_106: 0.2639 - val_loss: 0.1172 - val_binary_accuracy: 0.9796 - val_auc_106: 0.9327 - val_precision_106: 0.7828 - val_recall_106: 0.2416\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0657 - binary_accuracy: 0.9798 - auc_106: 0.9314 - precision_106: 0.7406 - recall_106: 0.2812 - val_loss: 0.0733 - val_binary_accuracy: 0.9798 - val_auc_106: 0.9367 - val_precision_106: 0.7397 - val_recall_106: 0.2790\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0643 - binary_accuracy: 0.9800 - auc_106: 0.9355 - precision_106: 0.7394 - recall_106: 0.2950 - val_loss: 0.0648 - val_binary_accuracy: 0.9799 - val_auc_106: 0.9375 - val_precision_106: 0.7334 - val_recall_106: 0.2903\n","Score for fold 7: F1 score of 0.41597662186568823; loss of 0.06482267379760742; binary_accuracy of 97.9851245880127%\n","Training for fold 8 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 13ms/step - loss: 0.0955 - binary_accuracy: 0.9723 - auc_107: 0.8370 - precision_107: 0.3799 - recall_107: 0.1929 - val_loss: 0.4470 - val_binary_accuracy: 0.9786 - val_auc_107: 0.8949 - val_precision_107: 0.7711 - val_recall_107: 0.2034\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0718 - binary_accuracy: 0.9792 - auc_107: 0.9095 - precision_107: 0.7506 - recall_107: 0.2382 - val_loss: 0.2605 - val_binary_accuracy: 0.9792 - val_auc_107: 0.9234 - val_precision_107: 0.7554 - val_recall_107: 0.2455\n","Epoch 3/5\n","149/149 [==============================] - 1s 10ms/step - loss: 0.0677 - binary_accuracy: 0.9796 - auc_107: 0.9251 - precision_107: 0.7430 - recall_107: 0.2663 - val_loss: 0.1288 - val_binary_accuracy: 0.9793 - val_auc_107: 0.9321 - val_precision_107: 0.7306 - val_recall_107: 0.2728\n","Epoch 4/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0654 - binary_accuracy: 0.9799 - auc_107: 0.9323 - precision_107: 0.7414 - recall_107: 0.2835 - val_loss: 0.0729 - val_binary_accuracy: 0.9796 - val_auc_107: 0.9366 - val_precision_107: 0.7428 - val_recall_107: 0.2775\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0637 - binary_accuracy: 0.9801 - auc_107: 0.9371 - precision_107: 0.7411 - recall_107: 0.2968 - val_loss: 0.0655 - val_binary_accuracy: 0.9796 - val_auc_107: 0.9343 - val_precision_107: 0.7657 - val_recall_107: 0.2643\n","Score for fold 8: F1 score of 0.39294958403225305; loss of 0.06550202518701553; binary_accuracy of 97.96221256256104%\n","Training for fold 9 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0961 - binary_accuracy: 0.9720 - auc_108: 0.8352 - precision_108: 0.3709 - recall_108: 0.1899 - val_loss: 0.4592 - val_binary_accuracy: 0.9790 - val_auc_108: 0.8943 - val_precision_108: 0.7529 - val_recall_108: 0.2196\n","Epoch 2/5\n","149/149 [==============================] - 2s 10ms/step - loss: 0.0721 - binary_accuracy: 0.9792 - auc_108: 0.9085 - precision_108: 0.7494 - recall_108: 0.2374 - val_loss: 0.2525 - val_binary_accuracy: 0.9794 - val_auc_108: 0.9242 - val_precision_108: 0.7840 - val_recall_108: 0.2283\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0680 - binary_accuracy: 0.9796 - auc_108: 0.9236 - precision_108: 0.7435 - recall_108: 0.2647 - val_loss: 0.1462 - val_binary_accuracy: 0.9795 - val_auc_108: 0.9329 - val_precision_108: 0.6804 - val_recall_108: 0.3167\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0658 - binary_accuracy: 0.9798 - auc_108: 0.9310 - precision_108: 0.7408 - recall_108: 0.2816 - val_loss: 0.0730 - val_binary_accuracy: 0.9799 - val_auc_108: 0.9371 - val_precision_108: 0.7444 - val_recall_108: 0.2788\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0640 - binary_accuracy: 0.9800 - auc_108: 0.9365 - precision_108: 0.7401 - recall_108: 0.2940 - val_loss: 0.0658 - val_binary_accuracy: 0.9799 - val_auc_108: 0.9393 - val_precision_108: 0.7181 - val_recall_108: 0.3070\n","Score for fold 9: F1 score of 0.4301441897132179; loss of 0.06577596068382263; binary_accuracy of 97.99391031265259%\n","Training for fold 10 ...\n","Epoch 1/5\n","149/149 [==============================] - 3s 14ms/step - loss: 0.0952 - binary_accuracy: 0.9723 - auc_109: 0.8389 - precision_109: 0.3807 - recall_109: 0.1928 - val_loss: 0.4447 - val_binary_accuracy: 0.9789 - val_auc_109: 0.9011 - val_precision_109: 0.7680 - val_recall_109: 0.2114\n","Epoch 2/5\n","149/149 [==============================] - 2s 14ms/step - loss: 0.0715 - binary_accuracy: 0.9792 - auc_109: 0.9110 - precision_109: 0.7507 - recall_109: 0.2387 - val_loss: 0.2511 - val_binary_accuracy: 0.9793 - val_auc_109: 0.9245 - val_precision_109: 0.7775 - val_recall_109: 0.2325\n","Epoch 3/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0676 - binary_accuracy: 0.9796 - auc_109: 0.9251 - precision_109: 0.7432 - recall_109: 0.2660 - val_loss: 0.1419 - val_binary_accuracy: 0.9794 - val_auc_109: 0.9332 - val_precision_109: 0.6876 - val_recall_109: 0.3105\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0653 - binary_accuracy: 0.9798 - auc_109: 0.9324 - precision_109: 0.7420 - recall_109: 0.2835 - val_loss: 0.0736 - val_binary_accuracy: 0.9797 - val_auc_109: 0.9370 - val_precision_109: 0.7491 - val_recall_109: 0.2733\n","Epoch 5/5\n","149/149 [==============================] - 2s 11ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_109: 0.9366 - precision_109: 0.7401 - recall_109: 0.2964 - val_loss: 0.0646 - val_binary_accuracy: 0.9799 - val_auc_109: 0.9354 - val_precision_109: 0.7616 - val_recall_109: 0.2722\n","Score for fold 10: F1 score of 0.40108548415115586; loss of 0.06463983654975891; binary_accuracy of 97.98504710197449%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  256\n","Training for fold 1 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 20ms/step - loss: 0.0959 - binary_accuracy: 0.9722 - auc_110: 0.8357 - precision_110: 0.3774 - recall_110: 0.1888 - val_loss: 0.4347 - val_binary_accuracy: 0.9787 - val_auc_110: 0.8921 - val_precision_110: 0.7393 - val_recall_110: 0.2130\n","Epoch 2/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0723 - binary_accuracy: 0.9792 - auc_110: 0.9078 - precision_110: 0.7480 - recall_110: 0.2370 - val_loss: 0.2387 - val_binary_accuracy: 0.9792 - val_auc_110: 0.9222 - val_precision_110: 0.7882 - val_recall_110: 0.2164\n","Epoch 3/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0680 - binary_accuracy: 0.9796 - auc_110: 0.9238 - precision_110: 0.7438 - recall_110: 0.2645 - val_loss: 0.1212 - val_binary_accuracy: 0.9796 - val_auc_110: 0.9321 - val_precision_110: 0.7720 - val_recall_110: 0.2504\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0656 - binary_accuracy: 0.9798 - auc_110: 0.9318 - precision_110: 0.7398 - recall_110: 0.2831 - val_loss: 0.0692 - val_binary_accuracy: 0.9796 - val_auc_110: 0.9357 - val_precision_110: 0.8017 - val_recall_110: 0.2329\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_110: 0.9365 - precision_110: 0.7407 - recall_110: 0.2961 - val_loss: 0.0652 - val_binary_accuracy: 0.9799 - val_auc_110: 0.9357 - val_precision_110: 0.7531 - val_recall_110: 0.2768\n","Score for fold 1: F1 score of 0.4047877928446072; loss of 0.06521932780742645; binary_accuracy of 97.98639416694641%\n","Training for fold 2 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 16ms/step - loss: 0.0953 - binary_accuracy: 0.9728 - auc_111: 0.8382 - precision_111: 0.4000 - recall_111: 0.1954 - val_loss: 0.4287 - val_binary_accuracy: 0.9791 - val_auc_111: 0.9013 - val_precision_111: 0.7563 - val_recall_111: 0.2155\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0716 - binary_accuracy: 0.9792 - auc_111: 0.9110 - precision_111: 0.7469 - recall_111: 0.2409 - val_loss: 0.2637 - val_binary_accuracy: 0.9797 - val_auc_111: 0.9261 - val_precision_111: 0.7566 - val_recall_111: 0.2479\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0675 - binary_accuracy: 0.9796 - auc_111: 0.9260 - precision_111: 0.7435 - recall_111: 0.2664 - val_loss: 0.1215 - val_binary_accuracy: 0.9799 - val_auc_111: 0.9343 - val_precision_111: 0.7389 - val_recall_111: 0.2766\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0654 - binary_accuracy: 0.9798 - auc_111: 0.9326 - precision_111: 0.7402 - recall_111: 0.2850 - val_loss: 0.0683 - val_binary_accuracy: 0.9800 - val_auc_111: 0.9376 - val_precision_111: 0.7759 - val_recall_111: 0.2540\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0637 - binary_accuracy: 0.9801 - auc_111: 0.9373 - precision_111: 0.7411 - recall_111: 0.2987 - val_loss: 0.0656 - val_binary_accuracy: 0.9801 - val_auc_111: 0.9390 - val_precision_111: 0.7097 - val_recall_111: 0.3152\n","Score for fold 2: F1 score of 0.4365346312789074; loss of 0.06561540067195892; binary_accuracy of 98.01137447357178%\n","Training for fold 3 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0954 - binary_accuracy: 0.9723 - auc_112: 0.8389 - precision_112: 0.3815 - recall_112: 0.1939 - val_loss: 0.4322 - val_binary_accuracy: 0.9791 - val_auc_112: 0.9019 - val_precision_112: 0.7792 - val_recall_112: 0.2062\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0718 - binary_accuracy: 0.9792 - auc_112: 0.9106 - precision_112: 0.7507 - recall_112: 0.2385 - val_loss: 0.2567 - val_binary_accuracy: 0.9796 - val_auc_112: 0.9259 - val_precision_112: 0.7722 - val_recall_112: 0.2377\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0679 - binary_accuracy: 0.9796 - auc_112: 0.9247 - precision_112: 0.7432 - recall_112: 0.2657 - val_loss: 0.1172 - val_binary_accuracy: 0.9797 - val_auc_112: 0.9348 - val_precision_112: 0.7728 - val_recall_112: 0.2480\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0655 - binary_accuracy: 0.9798 - auc_112: 0.9321 - precision_112: 0.7413 - recall_112: 0.2826 - val_loss: 0.0737 - val_binary_accuracy: 0.9799 - val_auc_112: 0.9388 - val_precision_112: 0.7406 - val_recall_112: 0.2810\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_112: 0.9368 - precision_112: 0.7403 - recall_112: 0.2963 - val_loss: 0.0651 - val_binary_accuracy: 0.9800 - val_auc_112: 0.9396 - val_precision_112: 0.7037 - val_recall_112: 0.3211\n","Score for fold 3: F1 score of 0.44099616577819145; loss of 0.06509551405906677; binary_accuracy of 98.00044894218445%\n","Training for fold 4 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 16ms/step - loss: 0.0966 - binary_accuracy: 0.9718 - auc_113: 0.8356 - precision_113: 0.3662 - recall_113: 0.1916 - val_loss: 0.4280 - val_binary_accuracy: 0.9789 - val_auc_113: 0.8962 - val_precision_113: 0.7832 - val_recall_113: 0.1984\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0720 - binary_accuracy: 0.9792 - auc_113: 0.9091 - precision_113: 0.7515 - recall_113: 0.2357 - val_loss: 0.2541 - val_binary_accuracy: 0.9793 - val_auc_113: 0.9223 - val_precision_113: 0.7310 - val_recall_113: 0.2549\n","Epoch 3/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0679 - binary_accuracy: 0.9796 - auc_113: 0.9245 - precision_113: 0.7453 - recall_113: 0.2635 - val_loss: 0.1209 - val_binary_accuracy: 0.9797 - val_auc_113: 0.9319 - val_precision_113: 0.7229 - val_recall_113: 0.2823\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0655 - binary_accuracy: 0.9798 - auc_113: 0.9322 - precision_113: 0.7411 - recall_113: 0.2815 - val_loss: 0.0759 - val_binary_accuracy: 0.9798 - val_auc_113: 0.9361 - val_precision_113: 0.7383 - val_recall_113: 0.2756\n","Epoch 5/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_113: 0.9367 - precision_113: 0.7407 - recall_113: 0.2955 - val_loss: 0.0647 - val_binary_accuracy: 0.9799 - val_auc_113: 0.9356 - val_precision_113: 0.7320 - val_recall_113: 0.2926\n","Score for fold 4: F1 score of 0.4181185263720684; loss of 0.06474682688713074; binary_accuracy of 97.99471497535706%\n","Training for fold 5 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0962 - binary_accuracy: 0.9719 - auc_114: 0.8356 - precision_114: 0.3694 - recall_114: 0.1904 - val_loss: 0.4466 - val_binary_accuracy: 0.9788 - val_auc_114: 0.8931 - val_precision_114: 0.7400 - val_recall_114: 0.2205\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0720 - binary_accuracy: 0.9792 - auc_114: 0.9087 - precision_114: 0.7509 - recall_114: 0.2379 - val_loss: 0.2510 - val_binary_accuracy: 0.9793 - val_auc_114: 0.9223 - val_precision_114: 0.7672 - val_recall_114: 0.2351\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0676 - binary_accuracy: 0.9796 - auc_114: 0.9255 - precision_114: 0.7458 - recall_114: 0.2663 - val_loss: 0.1110 - val_binary_accuracy: 0.9796 - val_auc_114: 0.9319 - val_precision_114: 0.7680 - val_recall_114: 0.2500\n","Epoch 4/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0653 - binary_accuracy: 0.9798 - auc_114: 0.9326 - precision_114: 0.7405 - recall_114: 0.2846 - val_loss: 0.0728 - val_binary_accuracy: 0.9797 - val_auc_114: 0.9364 - val_precision_114: 0.7110 - val_recall_114: 0.3003\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0636 - binary_accuracy: 0.9801 - auc_114: 0.9375 - precision_114: 0.7411 - recall_114: 0.2985 - val_loss: 0.0649 - val_binary_accuracy: 0.9799 - val_auc_114: 0.9360 - val_precision_114: 0.7266 - val_recall_114: 0.2988\n","Score for fold 5: F1 score of 0.4234704959585886; loss of 0.06489071249961853; binary_accuracy of 97.98564314842224%\n","Training for fold 6 ...\n","Epoch 1/5\n","149/149 [==============================] - 12s 67ms/step - loss: 0.0969 - binary_accuracy: 0.9717 - auc_115: 0.8331 - precision_115: 0.3626 - recall_115: 0.1880 - val_loss: 0.4352 - val_binary_accuracy: 0.9790 - val_auc_115: 0.8888 - val_precision_115: 0.7683 - val_recall_115: 0.2049\n","Epoch 2/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0725 - binary_accuracy: 0.9791 - auc_115: 0.9070 - precision_115: 0.7496 - recall_115: 0.2357 - val_loss: 0.2714 - val_binary_accuracy: 0.9796 - val_auc_115: 0.9232 - val_precision_115: 0.7397 - val_recall_115: 0.2585\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0679 - binary_accuracy: 0.9795 - auc_115: 0.9247 - precision_115: 0.7445 - recall_115: 0.2644 - val_loss: 0.1221 - val_binary_accuracy: 0.9798 - val_auc_115: 0.9331 - val_precision_115: 0.7469 - val_recall_115: 0.2686\n","Epoch 4/5\n","149/149 [==============================] - 2s 14ms/step - loss: 0.0654 - binary_accuracy: 0.9798 - auc_115: 0.9324 - precision_115: 0.7418 - recall_115: 0.2827 - val_loss: 0.0715 - val_binary_accuracy: 0.9799 - val_auc_115: 0.9373 - val_precision_115: 0.7438 - val_recall_115: 0.2766\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_115: 0.9368 - precision_115: 0.7395 - recall_115: 0.2968 - val_loss: 0.0645 - val_binary_accuracy: 0.9800 - val_auc_115: 0.9378 - val_precision_115: 0.7084 - val_recall_115: 0.3160\n","Score for fold 6: F1 score of 0.4370605445261922; loss of 0.06452355533838272; binary_accuracy of 98.00285696983337%\n","Training for fold 7 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0952 - binary_accuracy: 0.9726 - auc_116: 0.8374 - precision_116: 0.3877 - recall_116: 0.1928 - val_loss: 0.4360 - val_binary_accuracy: 0.9786 - val_auc_116: 0.8968 - val_precision_116: 0.7515 - val_recall_116: 0.2164\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0718 - binary_accuracy: 0.9792 - auc_116: 0.9097 - precision_116: 0.7463 - recall_116: 0.2393 - val_loss: 0.2375 - val_binary_accuracy: 0.9791 - val_auc_116: 0.9245 - val_precision_116: 0.8025 - val_recall_116: 0.2187\n","Epoch 3/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0677 - binary_accuracy: 0.9796 - auc_116: 0.9249 - precision_116: 0.7423 - recall_116: 0.2668 - val_loss: 0.1230 - val_binary_accuracy: 0.9795 - val_auc_116: 0.9340 - val_precision_116: 0.7302 - val_recall_116: 0.2855\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0655 - binary_accuracy: 0.9798 - auc_116: 0.9318 - precision_116: 0.7384 - recall_116: 0.2842 - val_loss: 0.0711 - val_binary_accuracy: 0.9796 - val_auc_116: 0.9376 - val_precision_116: 0.7721 - val_recall_116: 0.2626\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0638 - binary_accuracy: 0.9800 - auc_116: 0.9367 - precision_116: 0.7394 - recall_116: 0.2965 - val_loss: 0.0653 - val_binary_accuracy: 0.9797 - val_auc_116: 0.9378 - val_precision_116: 0.7426 - val_recall_116: 0.2915\n","Score for fold 7: F1 score of 0.4186354254841913; loss of 0.06534094363451004; binary_accuracy of 97.97141551971436%\n","Training for fold 8 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 17ms/step - loss: 0.0960 - binary_accuracy: 0.9722 - auc_117: 0.8354 - precision_117: 0.3775 - recall_117: 0.1911 - val_loss: 0.4464 - val_binary_accuracy: 0.9790 - val_auc_117: 0.8970 - val_precision_117: 0.7420 - val_recall_117: 0.2245\n","Epoch 2/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0715 - binary_accuracy: 0.9792 - auc_117: 0.9111 - precision_117: 0.7500 - recall_117: 0.2397 - val_loss: 0.2524 - val_binary_accuracy: 0.9795 - val_auc_117: 0.9267 - val_precision_117: 0.7706 - val_recall_117: 0.2397\n","Epoch 3/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0676 - binary_accuracy: 0.9796 - auc_117: 0.9254 - precision_117: 0.7412 - recall_117: 0.2676 - val_loss: 0.1201 - val_binary_accuracy: 0.9797 - val_auc_117: 0.9350 - val_precision_117: 0.7474 - val_recall_117: 0.2681\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0655 - binary_accuracy: 0.9798 - auc_117: 0.9321 - precision_117: 0.7396 - recall_117: 0.2840 - val_loss: 0.0681 - val_binary_accuracy: 0.9799 - val_auc_117: 0.9374 - val_precision_117: 0.7608 - val_recall_117: 0.2667\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0636 - binary_accuracy: 0.9801 - auc_117: 0.9375 - precision_117: 0.7425 - recall_117: 0.2978 - val_loss: 0.0661 - val_binary_accuracy: 0.9799 - val_auc_117: 0.9397 - val_precision_117: 0.6982 - val_recall_117: 0.3228\n","Score for fold 8: F1 score of 0.44152447340492573; loss of 0.06610958278179169; binary_accuracy of 97.98905849456787%\n","Training for fold 9 ...\n","Epoch 1/5\n","149/149 [==============================] - 28s 21ms/step - loss: 0.0960 - binary_accuracy: 0.9722 - auc_118: 0.8359 - precision_118: 0.3774 - recall_118: 0.1927 - val_loss: 0.4528 - val_binary_accuracy: 0.9789 - val_auc_118: 0.8954 - val_precision_118: 0.7491 - val_recall_118: 0.2200\n","Epoch 2/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0721 - binary_accuracy: 0.9792 - auc_118: 0.9088 - precision_118: 0.7476 - recall_118: 0.2380 - val_loss: 0.2480 - val_binary_accuracy: 0.9794 - val_auc_118: 0.9239 - val_precision_118: 0.7618 - val_recall_118: 0.2454\n","Epoch 3/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0678 - binary_accuracy: 0.9796 - auc_118: 0.9247 - precision_118: 0.7427 - recall_118: 0.2657 - val_loss: 0.1300 - val_binary_accuracy: 0.9796 - val_auc_118: 0.9337 - val_precision_118: 0.7147 - val_recall_118: 0.2938\n","Epoch 4/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0657 - binary_accuracy: 0.9798 - auc_118: 0.9315 - precision_118: 0.7382 - recall_118: 0.2830 - val_loss: 0.0751 - val_binary_accuracy: 0.9798 - val_auc_118: 0.9384 - val_precision_118: 0.7243 - val_recall_118: 0.2990\n","Epoch 5/5\n","149/149 [==============================] - 2s 17ms/step - loss: 0.0637 - binary_accuracy: 0.9801 - auc_118: 0.9373 - precision_118: 0.7409 - recall_118: 0.2972 - val_loss: 0.0646 - val_binary_accuracy: 0.9800 - val_auc_118: 0.9380 - val_precision_118: 0.7622 - val_recall_118: 0.2774\n","Score for fold 9: F1 score of 0.4067941123770686; loss of 0.06456441432237625; binary_accuracy of 97.99606800079346%\n","Training for fold 10 ...\n","Epoch 1/5\n","149/149 [==============================] - 4s 15ms/step - loss: 0.0955 - binary_accuracy: 0.9721 - auc_119: 0.8400 - precision_119: 0.3744 - recall_119: 0.1939 - val_loss: 0.4148 - val_binary_accuracy: 0.9784 - val_auc_119: 0.8972 - val_precision_119: 0.7824 - val_recall_119: 0.1945\n","Epoch 2/5\n","149/149 [==============================] - 2s 12ms/step - loss: 0.0718 - binary_accuracy: 0.9792 - auc_119: 0.9102 - precision_119: 0.7474 - recall_119: 0.2372 - val_loss: 0.2261 - val_binary_accuracy: 0.9787 - val_auc_119: 0.9218 - val_precision_119: 0.8175 - val_recall_119: 0.2006\n","Epoch 3/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0677 - binary_accuracy: 0.9796 - auc_119: 0.9248 - precision_119: 0.7449 - recall_119: 0.2642 - val_loss: 0.1107 - val_binary_accuracy: 0.9791 - val_auc_119: 0.9311 - val_precision_119: 0.7721 - val_recall_119: 0.2429\n","Epoch 4/5\n","149/149 [==============================] - 2s 14ms/step - loss: 0.0654 - binary_accuracy: 0.9799 - auc_119: 0.9320 - precision_119: 0.7414 - recall_119: 0.2822 - val_loss: 0.0716 - val_binary_accuracy: 0.9794 - val_auc_119: 0.9351 - val_precision_119: 0.7691 - val_recall_119: 0.2594\n","Epoch 5/5\n","149/149 [==============================] - 2s 13ms/step - loss: 0.0640 - binary_accuracy: 0.9801 - auc_119: 0.9361 - precision_119: 0.7400 - recall_119: 0.2954 - val_loss: 0.0663 - val_binary_accuracy: 0.9795 - val_auc_119: 0.9354 - val_precision_119: 0.7277 - val_recall_119: 0.3002\n","Score for fold 10: F1 score of 0.4250720226015885; loss of 0.06629552692174911; binary_accuracy of 97.95494079589844%\n","=======================================================================\n","Training for Molecular Function\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  64\n","Training for fold 1 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 16ms/step - loss: 0.1244 - binary_accuracy: 0.9624 - auc_120: 0.8059 - precision_120: 0.2843 - recall_120: 0.1491 - val_loss: 0.5432 - val_binary_accuracy: 0.9724 - val_auc_120: 0.8709 - val_precision_120: 0.7196 - val_recall_120: 0.1752\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0911 - binary_accuracy: 0.9732 - auc_120: 0.8918 - precision_120: 0.7155 - recall_120: 0.2090 - val_loss: 0.4073 - val_binary_accuracy: 0.9733 - val_auc_120: 0.9094 - val_precision_120: 0.7252 - val_recall_120: 0.2178\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0845 - binary_accuracy: 0.9740 - auc_120: 0.9149 - precision_120: 0.7169 - recall_120: 0.2495 - val_loss: 0.2864 - val_binary_accuracy: 0.9739 - val_auc_120: 0.9239 - val_precision_120: 0.7238 - val_recall_120: 0.2505\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0811 - binary_accuracy: 0.9744 - auc_120: 0.9244 - precision_120: 0.7161 - recall_120: 0.2747 - val_loss: 0.1797 - val_binary_accuracy: 0.9743 - val_auc_120: 0.9306 - val_precision_120: 0.7124 - val_recall_120: 0.2804\n","Epoch 5/5\n","98/98 [==============================] - 1s 8ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_120: 0.9315 - precision_120: 0.7197 - recall_120: 0.2933 - val_loss: 0.1173 - val_binary_accuracy: 0.9745 - val_auc_120: 0.9347 - val_precision_120: 0.6923 - val_recall_120: 0.3147\n","Score for fold 1: F1 score of 0.43271499873681657; loss of 0.11733852326869965; binary_accuracy of 97.45030999183655%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_MF_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_MF_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Molecular Function has 16 filters, with a kernel size of 64 and has an F1 score of 0.43271499873681657\n","Training for fold 2 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 13ms/step - loss: 0.1240 - binary_accuracy: 0.9630 - auc_121: 0.8070 - precision_121: 0.2980 - recall_121: 0.1495 - val_loss: 0.5399 - val_binary_accuracy: 0.9731 - val_auc_121: 0.8767 - val_precision_121: 0.7101 - val_recall_121: 0.1892\n","Epoch 2/5\n","98/98 [==============================] - 1s 8ms/step - loss: 0.0906 - binary_accuracy: 0.9732 - auc_121: 0.8949 - precision_121: 0.7140 - recall_121: 0.2135 - val_loss: 0.4088 - val_binary_accuracy: 0.9740 - val_auc_121: 0.9121 - val_precision_121: 0.7065 - val_recall_121: 0.2412\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_121: 0.9162 - precision_121: 0.7148 - recall_121: 0.2509 - val_loss: 0.2824 - val_binary_accuracy: 0.9745 - val_auc_121: 0.9249 - val_precision_121: 0.7215 - val_recall_121: 0.2566\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0809 - binary_accuracy: 0.9744 - auc_121: 0.9256 - precision_121: 0.7158 - recall_121: 0.2751 - val_loss: 0.1789 - val_binary_accuracy: 0.9749 - val_auc_121: 0.9313 - val_precision_121: 0.7093 - val_recall_121: 0.2889\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_121: 0.9317 - precision_121: 0.7185 - recall_121: 0.2946 - val_loss: 0.1146 - val_binary_accuracy: 0.9752 - val_auc_121: 0.9355 - val_precision_121: 0.7051 - val_recall_121: 0.3114\n","Score for fold 2: F1 score of 0.4319794553212335; loss of 0.11461225152015686; binary_accuracy of 97.5175142288208%\n","Training for fold 3 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1245 - binary_accuracy: 0.9627 - auc_122: 0.8065 - precision_122: 0.2924 - recall_122: 0.1502 - val_loss: 0.5408 - val_binary_accuracy: 0.9728 - val_auc_122: 0.8698 - val_precision_122: 0.7097 - val_recall_122: 0.1728\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0918 - binary_accuracy: 0.9731 - auc_122: 0.8902 - precision_122: 0.7176 - recall_122: 0.2042 - val_loss: 0.3998 - val_binary_accuracy: 0.9736 - val_auc_122: 0.9047 - val_precision_122: 0.7266 - val_recall_122: 0.2040\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0850 - binary_accuracy: 0.9739 - auc_122: 0.9137 - precision_122: 0.7165 - recall_122: 0.2467 - val_loss: 0.2802 - val_binary_accuracy: 0.9741 - val_auc_122: 0.9201 - val_precision_122: 0.7282 - val_recall_122: 0.2313\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0814 - binary_accuracy: 0.9743 - auc_122: 0.9242 - precision_122: 0.7172 - recall_122: 0.2724 - val_loss: 0.1835 - val_binary_accuracy: 0.9745 - val_auc_122: 0.9278 - val_precision_122: 0.6915 - val_recall_122: 0.2875\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0790 - binary_accuracy: 0.9747 - auc_122: 0.9302 - precision_122: 0.7170 - recall_122: 0.2922 - val_loss: 0.1214 - val_binary_accuracy: 0.9748 - val_auc_122: 0.9324 - val_precision_122: 0.6858 - val_recall_122: 0.3081\n","Score for fold 3: F1 score of 0.42521566614394685; loss of 0.1213582307100296; binary_accuracy of 97.47663736343384%\n","Training for fold 4 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1238 - binary_accuracy: 0.9630 - auc_123: 0.8079 - precision_123: 0.2959 - recall_123: 0.1492 - val_loss: 0.5434 - val_binary_accuracy: 0.9723 - val_auc_123: 0.8714 - val_precision_123: 0.7138 - val_recall_123: 0.1791\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0906 - binary_accuracy: 0.9733 - auc_123: 0.8933 - precision_123: 0.7187 - recall_123: 0.2103 - val_loss: 0.4026 - val_binary_accuracy: 0.9733 - val_auc_123: 0.9085 - val_precision_123: 0.7052 - val_recall_123: 0.2429\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0843 - binary_accuracy: 0.9740 - auc_123: 0.9153 - precision_123: 0.7147 - recall_123: 0.2514 - val_loss: 0.2828 - val_binary_accuracy: 0.9738 - val_auc_123: 0.9230 - val_precision_123: 0.7104 - val_recall_123: 0.2642\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0808 - binary_accuracy: 0.9744 - auc_123: 0.9251 - precision_123: 0.7151 - recall_123: 0.2764 - val_loss: 0.1680 - val_binary_accuracy: 0.9741 - val_auc_123: 0.9295 - val_precision_123: 0.7392 - val_recall_123: 0.2539\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_123: 0.9311 - precision_123: 0.7169 - recall_123: 0.2950 - val_loss: 0.1160 - val_binary_accuracy: 0.9745 - val_auc_123: 0.9342 - val_precision_123: 0.7135 - val_recall_123: 0.2985\n","Score for fold 4: F1 score of 0.4209029743217489; loss of 0.11604820191860199; binary_accuracy of 97.45035767555237%\n","Training for fold 5 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 13ms/step - loss: 0.1229 - binary_accuracy: 0.9631 - auc_124: 0.8114 - precision_124: 0.3016 - recall_124: 0.1546 - val_loss: 0.5298 - val_binary_accuracy: 0.9724 - val_auc_124: 0.8829 - val_precision_124: 0.7118 - val_recall_124: 0.1932\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0889 - binary_accuracy: 0.9734 - auc_124: 0.9009 - precision_124: 0.7099 - recall_124: 0.2203 - val_loss: 0.4006 - val_binary_accuracy: 0.9731 - val_auc_124: 0.9109 - val_precision_124: 0.7141 - val_recall_124: 0.2334\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0836 - binary_accuracy: 0.9740 - auc_124: 0.9178 - precision_124: 0.7132 - recall_124: 0.2541 - val_loss: 0.2728 - val_binary_accuracy: 0.9736 - val_auc_124: 0.9230 - val_precision_124: 0.7496 - val_recall_124: 0.2324\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0805 - binary_accuracy: 0.9745 - auc_124: 0.9260 - precision_124: 0.7151 - recall_124: 0.2778 - val_loss: 0.1773 - val_binary_accuracy: 0.9742 - val_auc_124: 0.9299 - val_precision_124: 0.7271 - val_recall_124: 0.2772\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0782 - binary_accuracy: 0.9749 - auc_124: 0.9318 - precision_124: 0.7175 - recall_124: 0.2967 - val_loss: 0.1048 - val_binary_accuracy: 0.9743 - val_auc_124: 0.9334 - val_precision_124: 0.7572 - val_recall_124: 0.2582\n","Score for fold 5: F1 score of 0.38507849242920655; loss of 0.10483665764331818; binary_accuracy of 97.42546081542969%\n","Training for fold 6 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1248 - binary_accuracy: 0.9625 - auc_125: 0.8057 - precision_125: 0.2862 - recall_125: 0.1499 - val_loss: 0.5332 - val_binary_accuracy: 0.9725 - val_auc_125: 0.8739 - val_precision_125: 0.7230 - val_recall_125: 0.1788\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0907 - binary_accuracy: 0.9732 - auc_125: 0.8936 - precision_125: 0.7148 - recall_125: 0.2114 - val_loss: 0.4093 - val_binary_accuracy: 0.9735 - val_auc_125: 0.9098 - val_precision_125: 0.7238 - val_recall_125: 0.2300\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0845 - binary_accuracy: 0.9739 - auc_125: 0.9151 - precision_125: 0.7161 - recall_125: 0.2488 - val_loss: 0.2741 - val_binary_accuracy: 0.9740 - val_auc_125: 0.9228 - val_precision_125: 0.7223 - val_recall_125: 0.2572\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0811 - binary_accuracy: 0.9744 - auc_125: 0.9246 - precision_125: 0.7166 - recall_125: 0.2738 - val_loss: 0.1785 - val_binary_accuracy: 0.9744 - val_auc_125: 0.9292 - val_precision_125: 0.7189 - val_recall_125: 0.2773\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0786 - binary_accuracy: 0.9748 - auc_125: 0.9309 - precision_125: 0.7202 - recall_125: 0.2921 - val_loss: 0.1161 - val_binary_accuracy: 0.9747 - val_auc_125: 0.9343 - val_precision_125: 0.7134 - val_recall_125: 0.3026\n","Score for fold 6: F1 score of 0.42488017617051704; loss of 0.11610742658376694; binary_accuracy of 97.47236967086792%\n","Training for fold 7 ...\n","Epoch 1/5\n","98/98 [==============================] - 2s 12ms/step - loss: 0.1244 - binary_accuracy: 0.9625 - auc_126: 0.8073 - precision_126: 0.2872 - recall_126: 0.1502 - val_loss: 0.5522 - val_binary_accuracy: 0.9727 - val_auc_126: 0.8706 - val_precision_126: 0.7214 - val_recall_126: 0.1793\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0911 - binary_accuracy: 0.9732 - auc_126: 0.8922 - precision_126: 0.7132 - recall_126: 0.2098 - val_loss: 0.4058 - val_binary_accuracy: 0.9736 - val_auc_126: 0.9079 - val_precision_126: 0.7195 - val_recall_126: 0.2264\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0846 - binary_accuracy: 0.9739 - auc_126: 0.9150 - precision_126: 0.7127 - recall_126: 0.2497 - val_loss: 0.2830 - val_binary_accuracy: 0.9741 - val_auc_126: 0.9222 - val_precision_126: 0.7138 - val_recall_126: 0.2610\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - auc_126: 0.9252 - precision_126: 0.7149 - recall_126: 0.2752 - val_loss: 0.1810 - val_binary_accuracy: 0.9745 - val_auc_126: 0.9295 - val_precision_126: 0.7134 - val_recall_126: 0.2846\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0786 - binary_accuracy: 0.9748 - auc_126: 0.9311 - precision_126: 0.7175 - recall_126: 0.2945 - val_loss: 0.1096 - val_binary_accuracy: 0.9747 - val_auc_126: 0.9334 - val_precision_126: 0.7378 - val_recall_126: 0.2747\n","Score for fold 7: F1 score of 0.40032742003467364; loss of 0.10958180576562881; binary_accuracy of 97.4747359752655%\n","Training for fold 8 ...\n","Epoch 1/5\n","98/98 [==============================] - 2s 12ms/step - loss: 0.1247 - binary_accuracy: 0.9619 - auc_127: 0.8079 - precision_127: 0.2786 - recall_127: 0.1510 - val_loss: 0.5431 - val_binary_accuracy: 0.9727 - val_auc_127: 0.8756 - val_precision_127: 0.7150 - val_recall_127: 0.1759\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0906 - binary_accuracy: 0.9732 - auc_127: 0.8947 - precision_127: 0.7158 - recall_127: 0.2115 - val_loss: 0.4023 - val_binary_accuracy: 0.9736 - val_auc_127: 0.9102 - val_precision_127: 0.7095 - val_recall_127: 0.2319\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0844 - binary_accuracy: 0.9739 - auc_127: 0.9155 - precision_127: 0.7141 - recall_127: 0.2519 - val_loss: 0.2777 - val_binary_accuracy: 0.9742 - val_auc_127: 0.9239 - val_precision_127: 0.7228 - val_recall_127: 0.2510\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0808 - binary_accuracy: 0.9744 - auc_127: 0.9256 - precision_127: 0.7158 - recall_127: 0.2770 - val_loss: 0.1694 - val_binary_accuracy: 0.9744 - val_auc_127: 0.9302 - val_precision_127: 0.7358 - val_recall_127: 0.2540\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_127: 0.9315 - precision_127: 0.7197 - recall_127: 0.2960 - val_loss: 0.1136 - val_binary_accuracy: 0.9748 - val_auc_127: 0.9345 - val_precision_127: 0.7117 - val_recall_127: 0.2981\n","Score for fold 8: F1 score of 0.4201688025402039; loss of 0.11361784487962723; binary_accuracy of 97.48482704162598%\n","Training for fold 9 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 16ms/step - loss: 0.1249 - binary_accuracy: 0.9623 - auc_128: 0.8050 - precision_128: 0.2811 - recall_128: 0.1456 - val_loss: 0.5277 - val_binary_accuracy: 0.9727 - val_auc_128: 0.8676 - val_precision_128: 0.7216 - val_recall_128: 0.1737\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0914 - binary_accuracy: 0.9732 - auc_128: 0.8907 - precision_128: 0.7168 - recall_128: 0.2079 - val_loss: 0.4003 - val_binary_accuracy: 0.9736 - val_auc_128: 0.9074 - val_precision_128: 0.7196 - val_recall_128: 0.2220\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0846 - binary_accuracy: 0.9739 - auc_128: 0.9147 - precision_128: 0.7148 - recall_128: 0.2491 - val_loss: 0.2830 - val_binary_accuracy: 0.9742 - val_auc_128: 0.9222 - val_precision_128: 0.7062 - val_recall_128: 0.2686\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - auc_128: 0.9250 - precision_128: 0.7158 - recall_128: 0.2755 - val_loss: 0.1853 - val_binary_accuracy: 0.9746 - val_auc_128: 0.9296 - val_precision_128: 0.7139 - val_recall_128: 0.2841\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0787 - binary_accuracy: 0.9748 - auc_128: 0.9306 - precision_128: 0.7166 - recall_128: 0.2953 - val_loss: 0.1181 - val_binary_accuracy: 0.9750 - val_auc_128: 0.9344 - val_precision_128: 0.7056 - val_recall_128: 0.3106\n","Score for fold 9: F1 score of 0.4313110019260559; loss of 0.1181129589676857; binary_accuracy of 97.4976122379303%\n","Training for fold 10 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1261 - binary_accuracy: 0.9621 - auc_129: 0.8016 - precision_129: 0.2737 - recall_129: 0.1415 - val_loss: 0.5441 - val_binary_accuracy: 0.9727 - val_auc_129: 0.8691 - val_precision_129: 0.7079 - val_recall_129: 0.1728\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0917 - binary_accuracy: 0.9731 - auc_129: 0.8896 - precision_129: 0.7179 - recall_129: 0.2055 - val_loss: 0.4037 - val_binary_accuracy: 0.9737 - val_auc_129: 0.9103 - val_precision_129: 0.7236 - val_recall_129: 0.2174\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0851 - binary_accuracy: 0.9739 - auc_129: 0.9133 - precision_129: 0.7146 - recall_129: 0.2484 - val_loss: 0.2800 - val_binary_accuracy: 0.9742 - val_auc_129: 0.9236 - val_precision_129: 0.7317 - val_recall_129: 0.2418\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0815 - binary_accuracy: 0.9743 - auc_129: 0.9236 - precision_129: 0.7164 - recall_129: 0.2726 - val_loss: 0.1864 - val_binary_accuracy: 0.9746 - val_auc_129: 0.9306 - val_precision_129: 0.7049 - val_recall_129: 0.2864\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0791 - binary_accuracy: 0.9747 - auc_129: 0.9298 - precision_129: 0.7176 - recall_129: 0.2919 - val_loss: 0.1168 - val_binary_accuracy: 0.9749 - val_auc_129: 0.9343 - val_precision_129: 0.7188 - val_recall_129: 0.2883\n","Score for fold 10: F1 score of 0.4115634669430646; loss of 0.11675946414470673; binary_accuracy of 97.4918782711029%\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  128\n","Training for fold 1 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 16ms/step - loss: 0.1245 - binary_accuracy: 0.9623 - auc_130: 0.8065 - precision_130: 0.2823 - recall_130: 0.1481 - val_loss: 0.5345 - val_binary_accuracy: 0.9727 - val_auc_130: 0.8731 - val_precision_130: 0.7166 - val_recall_130: 0.1745\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0909 - binary_accuracy: 0.9732 - auc_130: 0.8935 - precision_130: 0.7167 - recall_130: 0.2089 - val_loss: 0.4014 - val_binary_accuracy: 0.9738 - val_auc_130: 0.9105 - val_precision_130: 0.7107 - val_recall_130: 0.2364\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0845 - binary_accuracy: 0.9739 - auc_130: 0.9152 - precision_130: 0.7161 - recall_130: 0.2497 - val_loss: 0.2727 - val_binary_accuracy: 0.9742 - val_auc_130: 0.9239 - val_precision_130: 0.7300 - val_recall_130: 0.2447\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0809 - binary_accuracy: 0.9744 - auc_130: 0.9251 - precision_130: 0.7164 - recall_130: 0.2762 - val_loss: 0.1660 - val_binary_accuracy: 0.9744 - val_auc_130: 0.9304 - val_precision_130: 0.7422 - val_recall_130: 0.2468\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0786 - binary_accuracy: 0.9748 - auc_130: 0.9307 - precision_130: 0.7175 - recall_130: 0.2956 - val_loss: 0.1130 - val_binary_accuracy: 0.9747 - val_auc_130: 0.9345 - val_precision_130: 0.6885 - val_recall_130: 0.3132\n","Score for fold 1: F1 score of 0.43052897476668145; loss of 0.11301387846469879; binary_accuracy of 97.47217297554016%\n","Training for fold 2 ...\n","Epoch 1/5\n","98/98 [==============================] - 2s 12ms/step - loss: 0.1235 - binary_accuracy: 0.9631 - auc_131: 0.8098 - precision_131: 0.3006 - recall_131: 0.1528 - val_loss: 0.5107 - val_binary_accuracy: 0.9724 - val_auc_131: 0.8777 - val_precision_131: 0.7125 - val_recall_131: 0.1763\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0894 - binary_accuracy: 0.9733 - auc_131: 0.8991 - precision_131: 0.7108 - recall_131: 0.2205 - val_loss: 0.3705 - val_binary_accuracy: 0.9732 - val_auc_131: 0.9119 - val_precision_131: 0.7229 - val_recall_131: 0.2140\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0835 - binary_accuracy: 0.9741 - auc_131: 0.9182 - precision_131: 0.7146 - recall_131: 0.2565 - val_loss: 0.2843 - val_binary_accuracy: 0.9740 - val_auc_131: 0.9249 - val_precision_131: 0.6965 - val_recall_131: 0.2772\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0802 - binary_accuracy: 0.9745 - auc_131: 0.9270 - precision_131: 0.7157 - recall_131: 0.2805 - val_loss: 0.1673 - val_binary_accuracy: 0.9743 - val_auc_131: 0.9314 - val_precision_131: 0.7292 - val_recall_131: 0.2663\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0779 - binary_accuracy: 0.9749 - auc_131: 0.9326 - precision_131: 0.7173 - recall_131: 0.2998 - val_loss: 0.1049 - val_binary_accuracy: 0.9746 - val_auc_131: 0.9348 - val_precision_131: 0.7418 - val_recall_131: 0.2701\n","Score for fold 2: F1 score of 0.39605358272081365; loss of 0.10491441190242767; binary_accuracy of 97.45908975601196%\n","Training for fold 3 ...\n","Epoch 1/5\n","98/98 [==============================] - 2s 12ms/step - loss: 0.1240 - binary_accuracy: 0.9629 - auc_132: 0.8083 - precision_132: 0.2995 - recall_132: 0.1564 - val_loss: 0.5252 - val_binary_accuracy: 0.9726 - val_auc_132: 0.8732 - val_precision_132: 0.7217 - val_recall_132: 0.1769\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0909 - binary_accuracy: 0.9732 - auc_132: 0.8930 - precision_132: 0.7128 - recall_132: 0.2105 - val_loss: 0.3966 - val_binary_accuracy: 0.9733 - val_auc_132: 0.9065 - val_precision_132: 0.7015 - val_recall_132: 0.2299\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0845 - binary_accuracy: 0.9739 - auc_132: 0.9151 - precision_132: 0.7138 - recall_132: 0.2501 - val_loss: 0.2814 - val_binary_accuracy: 0.9739 - val_auc_132: 0.9225 - val_precision_132: 0.7145 - val_recall_132: 0.2543\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0809 - binary_accuracy: 0.9744 - auc_132: 0.9252 - precision_132: 0.7142 - recall_132: 0.2769 - val_loss: 0.1701 - val_binary_accuracy: 0.9741 - val_auc_132: 0.9301 - val_precision_132: 0.7618 - val_recall_132: 0.2278\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0786 - binary_accuracy: 0.9748 - auc_132: 0.9308 - precision_132: 0.7162 - recall_132: 0.2945 - val_loss: 0.1122 - val_binary_accuracy: 0.9747 - val_auc_132: 0.9347 - val_precision_132: 0.7146 - val_recall_132: 0.2945\n","Score for fold 3: F1 score of 0.4171079284944166; loss of 0.11223210394382477; binary_accuracy of 97.46773838996887%\n","Training for fold 4 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1252 - binary_accuracy: 0.9627 - auc_133: 0.8037 - precision_133: 0.2885 - recall_133: 0.1478 - val_loss: 0.5305 - val_binary_accuracy: 0.9723 - val_auc_133: 0.8683 - val_precision_133: 0.7178 - val_recall_133: 0.1711\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0915 - binary_accuracy: 0.9732 - auc_133: 0.8899 - precision_133: 0.7166 - recall_133: 0.2080 - val_loss: 0.4148 - val_binary_accuracy: 0.9733 - val_auc_133: 0.9078 - val_precision_133: 0.7034 - val_recall_133: 0.2375\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0847 - binary_accuracy: 0.9739 - auc_133: 0.9141 - precision_133: 0.7141 - recall_133: 0.2498 - val_loss: 0.2762 - val_binary_accuracy: 0.9737 - val_auc_133: 0.9218 - val_precision_133: 0.7291 - val_recall_133: 0.2359\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - auc_133: 0.9246 - precision_133: 0.7157 - recall_133: 0.2753 - val_loss: 0.1748 - val_binary_accuracy: 0.9743 - val_auc_133: 0.9296 - val_precision_133: 0.7302 - val_recall_133: 0.2673\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_133: 0.9312 - precision_133: 0.7172 - recall_133: 0.2954 - val_loss: 0.1170 - val_binary_accuracy: 0.9747 - val_auc_133: 0.9347 - val_precision_133: 0.7124 - val_recall_133: 0.3035\n","Score for fold 4: F1 score of 0.42562277585195923; loss of 0.11703505367040634; binary_accuracy of 97.46935963630676%\n","Training for fold 5 ...\n","Epoch 1/5\n","98/98 [==============================] - 2s 12ms/step - loss: 0.1249 - binary_accuracy: 0.9621 - auc_134: 0.8056 - precision_134: 0.2813 - recall_134: 0.1509 - val_loss: 0.5354 - val_binary_accuracy: 0.9726 - val_auc_134: 0.8706 - val_precision_134: 0.6887 - val_recall_134: 0.1933\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0907 - binary_accuracy: 0.9732 - auc_134: 0.8938 - precision_134: 0.7152 - recall_134: 0.2117 - val_loss: 0.3979 - val_binary_accuracy: 0.9735 - val_auc_134: 0.9088 - val_precision_134: 0.7097 - val_recall_134: 0.2267\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_134: 0.9156 - precision_134: 0.7147 - recall_134: 0.2516 - val_loss: 0.2768 - val_binary_accuracy: 0.9740 - val_auc_134: 0.9222 - val_precision_134: 0.7292 - val_recall_134: 0.2428\n","Epoch 4/5\n","98/98 [==============================] - 1s 8ms/step - loss: 0.0808 - binary_accuracy: 0.9744 - auc_134: 0.9253 - precision_134: 0.7167 - recall_134: 0.2761 - val_loss: 0.1691 - val_binary_accuracy: 0.9744 - val_auc_134: 0.9288 - val_precision_134: 0.7246 - val_recall_134: 0.2638\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0785 - binary_accuracy: 0.9748 - auc_134: 0.9311 - precision_134: 0.7176 - recall_134: 0.2961 - val_loss: 0.1106 - val_binary_accuracy: 0.9746 - val_auc_134: 0.9323 - val_precision_134: 0.7114 - val_recall_134: 0.2880\n","Score for fold 5: F1 score of 0.41000499045560385; loss of 0.11057444661855698; binary_accuracy of 97.45933413505554%\n","Training for fold 6 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 12ms/step - loss: 0.1249 - binary_accuracy: 0.9623 - auc_135: 0.8062 - precision_135: 0.2849 - recall_135: 0.1517 - val_loss: 0.5269 - val_binary_accuracy: 0.9725 - val_auc_135: 0.8755 - val_precision_135: 0.7189 - val_recall_135: 0.1786\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0905 - binary_accuracy: 0.9732 - auc_135: 0.8953 - precision_135: 0.7112 - recall_135: 0.2124 - val_loss: 0.3868 - val_binary_accuracy: 0.9733 - val_auc_135: 0.9085 - val_precision_135: 0.7386 - val_recall_135: 0.2084\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0844 - binary_accuracy: 0.9739 - auc_135: 0.9155 - precision_135: 0.7146 - recall_135: 0.2506 - val_loss: 0.2758 - val_binary_accuracy: 0.9739 - val_auc_135: 0.9211 - val_precision_135: 0.7278 - val_recall_135: 0.2444\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - auc_135: 0.9249 - precision_135: 0.7160 - recall_135: 0.2752 - val_loss: 0.1794 - val_binary_accuracy: 0.9743 - val_auc_135: 0.9285 - val_precision_135: 0.6983 - val_recall_135: 0.2940\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0789 - binary_accuracy: 0.9748 - auc_135: 0.9299 - precision_135: 0.7152 - recall_135: 0.2940 - val_loss: 0.1131 - val_binary_accuracy: 0.9746 - val_auc_135: 0.9329 - val_precision_135: 0.7265 - val_recall_135: 0.2830\n","Score for fold 6: F1 score of 0.4073573977530784; loss of 0.11305457353591919; binary_accuracy of 97.46175408363342%\n","Training for fold 7 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1251 - binary_accuracy: 0.9622 - auc_136: 0.8063 - precision_136: 0.2826 - recall_136: 0.1497 - val_loss: 0.5297 - val_binary_accuracy: 0.9729 - val_auc_136: 0.8734 - val_precision_136: 0.7251 - val_recall_136: 0.1671\n","Epoch 2/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0911 - binary_accuracy: 0.9731 - auc_136: 0.8928 - precision_136: 0.7143 - recall_136: 0.2102 - val_loss: 0.3920 - val_binary_accuracy: 0.9737 - val_auc_136: 0.9094 - val_precision_136: 0.7312 - val_recall_136: 0.2080\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0846 - binary_accuracy: 0.9739 - auc_136: 0.9149 - precision_136: 0.7160 - recall_136: 0.2498 - val_loss: 0.2858 - val_binary_accuracy: 0.9744 - val_auc_136: 0.9239 - val_precision_136: 0.7071 - val_recall_136: 0.2633\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0811 - binary_accuracy: 0.9744 - auc_136: 0.9249 - precision_136: 0.7161 - recall_136: 0.2755 - val_loss: 0.1939 - val_binary_accuracy: 0.9748 - val_auc_136: 0.9310 - val_precision_136: 0.6962 - val_recall_136: 0.2983\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0786 - binary_accuracy: 0.9748 - auc_136: 0.9311 - precision_136: 0.7175 - recall_136: 0.2951 - val_loss: 0.1121 - val_binary_accuracy: 0.9751 - val_auc_136: 0.9348 - val_precision_136: 0.7092 - val_recall_136: 0.3027\n","Score for fold 7: F1 score of 0.4242593893617769; loss of 0.11212291568517685; binary_accuracy of 97.51202464103699%\n","Training for fold 8 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 18ms/step - loss: 0.1250 - binary_accuracy: 0.9625 - auc_137: 0.8052 - precision_137: 0.2864 - recall_137: 0.1496 - val_loss: 0.5253 - val_binary_accuracy: 0.9725 - val_auc_137: 0.8733 - val_precision_137: 0.7204 - val_recall_137: 0.1767\n","Epoch 2/5\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0906 - binary_accuracy: 0.9732 - auc_137: 0.8939 - precision_137: 0.7134 - recall_137: 0.2129 - val_loss: 0.3909 - val_binary_accuracy: 0.9734 - val_auc_137: 0.9113 - val_precision_137: 0.7397 - val_recall_137: 0.2086\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_137: 0.9156 - precision_137: 0.7119 - recall_137: 0.2524 - val_loss: 0.2967 - val_binary_accuracy: 0.9740 - val_auc_137: 0.9241 - val_precision_137: 0.7135 - val_recall_137: 0.2601\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0807 - binary_accuracy: 0.9744 - auc_137: 0.9258 - precision_137: 0.7158 - recall_137: 0.2768 - val_loss: 0.1813 - val_binary_accuracy: 0.9743 - val_auc_137: 0.9310 - val_precision_137: 0.7145 - val_recall_137: 0.2729\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_137: 0.9313 - precision_137: 0.7157 - recall_137: 0.2964 - val_loss: 0.1119 - val_binary_accuracy: 0.9747 - val_auc_137: 0.9352 - val_precision_137: 0.7282 - val_recall_137: 0.2831\n","Score for fold 8: F1 score of 0.40772430823302297; loss of 0.11188235133886337; binary_accuracy of 97.46816754341125%\n","Training for fold 9 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 19ms/step - loss: 0.1252 - binary_accuracy: 0.9624 - auc_138: 0.8036 - precision_138: 0.2794 - recall_138: 0.1434 - val_loss: 0.5201 - val_binary_accuracy: 0.9724 - val_auc_138: 0.8686 - val_precision_138: 0.7396 - val_recall_138: 0.1605\n","Epoch 2/5\n","98/98 [==============================] - 1s 8ms/step - loss: 0.0912 - binary_accuracy: 0.9732 - auc_138: 0.8915 - precision_138: 0.7143 - recall_138: 0.2103 - val_loss: 0.4004 - val_binary_accuracy: 0.9735 - val_auc_138: 0.9078 - val_precision_138: 0.7213 - val_recall_138: 0.2261\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0846 - binary_accuracy: 0.9739 - auc_138: 0.9146 - precision_138: 0.7147 - recall_138: 0.2490 - val_loss: 0.2876 - val_binary_accuracy: 0.9741 - val_auc_138: 0.9219 - val_precision_138: 0.7189 - val_recall_138: 0.2600\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0811 - binary_accuracy: 0.9744 - auc_138: 0.9246 - precision_138: 0.7153 - recall_138: 0.2747 - val_loss: 0.1855 - val_binary_accuracy: 0.9744 - val_auc_138: 0.9290 - val_precision_138: 0.7012 - val_recall_138: 0.2943\n","Epoch 5/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0787 - binary_accuracy: 0.9748 - auc_138: 0.9306 - precision_138: 0.7158 - recall_138: 0.2936 - val_loss: 0.1100 - val_binary_accuracy: 0.9745 - val_auc_138: 0.9324 - val_precision_138: 0.7260 - val_recall_138: 0.2776\n","Score for fold 9: F1 score of 0.4016053898353137; loss of 0.11004196852445602; binary_accuracy of 97.4530577659607%\n","Training for fold 10 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 16ms/step - loss: 0.1248 - binary_accuracy: 0.9626 - auc_139: 0.8056 - precision_139: 0.2906 - recall_139: 0.1512 - val_loss: 0.5340 - val_binary_accuracy: 0.9729 - val_auc_139: 0.8736 - val_precision_139: 0.7204 - val_recall_139: 0.1819\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0907 - binary_accuracy: 0.9732 - auc_139: 0.8940 - precision_139: 0.7113 - recall_139: 0.2141 - val_loss: 0.4084 - val_binary_accuracy: 0.9739 - val_auc_139: 0.9115 - val_precision_139: 0.7173 - val_recall_139: 0.2379\n","Epoch 3/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_139: 0.9157 - precision_139: 0.7141 - recall_139: 0.2524 - val_loss: 0.2803 - val_binary_accuracy: 0.9744 - val_auc_139: 0.9248 - val_precision_139: 0.7167 - val_recall_139: 0.2641\n","Epoch 4/5\n","98/98 [==============================] - 1s 9ms/step - loss: 0.0809 - binary_accuracy: 0.9744 - auc_139: 0.9253 - precision_139: 0.7145 - recall_139: 0.2776 - val_loss: 0.1670 - val_binary_accuracy: 0.9746 - val_auc_139: 0.9305 - val_precision_139: 0.7301 - val_recall_139: 0.2663\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_139: 0.9314 - precision_139: 0.7167 - recall_139: 0.2968 - val_loss: 0.1074 - val_binary_accuracy: 0.9749 - val_auc_139: 0.9347 - val_precision_139: 0.7174 - val_recall_139: 0.2933\n","Score for fold 10: F1 score of 0.41636805271728244; loss of 0.10736539959907532; binary_accuracy of 97.49064445495605%\n","----------------------------------------------------------------------\n","The number of filters is  16\n","The size of the kernel is  256\n","Training for fold 1 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 23ms/step - loss: 0.1258 - binary_accuracy: 0.9620 - auc_140: 0.8050 - precision_140: 0.2781 - recall_140: 0.1499 - val_loss: 0.5146 - val_binary_accuracy: 0.9723 - val_auc_140: 0.8732 - val_precision_140: 0.7266 - val_recall_140: 0.1714\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0908 - binary_accuracy: 0.9732 - auc_140: 0.8938 - precision_140: 0.7125 - recall_140: 0.2098 - val_loss: 0.3819 - val_binary_accuracy: 0.9732 - val_auc_140: 0.9080 - val_precision_140: 0.7209 - val_recall_140: 0.2199\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0845 - binary_accuracy: 0.9739 - auc_140: 0.9152 - precision_140: 0.7148 - recall_140: 0.2490 - val_loss: 0.2671 - val_binary_accuracy: 0.9737 - val_auc_140: 0.9216 - val_precision_140: 0.7144 - val_recall_140: 0.2521\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - auc_140: 0.9250 - precision_140: 0.7155 - recall_140: 0.2741 - val_loss: 0.1636 - val_binary_accuracy: 0.9741 - val_auc_140: 0.9282 - val_precision_140: 0.7343 - val_recall_140: 0.2551\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0787 - binary_accuracy: 0.9748 - auc_140: 0.9305 - precision_140: 0.7165 - recall_140: 0.2929 - val_loss: 0.1189 - val_binary_accuracy: 0.9743 - val_auc_140: 0.9328 - val_precision_140: 0.6942 - val_recall_140: 0.3075\n","Score for fold 1: F1 score of 0.42617438554100084; loss of 0.11894916743040085; binary_accuracy of 97.43441939353943%\n","Training for fold 2 ...\n","Epoch 1/5\n","98/98 [==============================] - 10s 78ms/step - loss: 0.1259 - binary_accuracy: 0.9624 - auc_141: 0.8048 - precision_141: 0.2839 - recall_141: 0.1483 - val_loss: 0.5218 - val_binary_accuracy: 0.9723 - val_auc_141: 0.8745 - val_precision_141: 0.7129 - val_recall_141: 0.1768\n","Epoch 2/5\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0912 - binary_accuracy: 0.9731 - auc_141: 0.8924 - precision_141: 0.7124 - recall_141: 0.2065 - val_loss: 0.3798 - val_binary_accuracy: 0.9733 - val_auc_141: 0.9086 - val_precision_141: 0.7334 - val_recall_141: 0.2150\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0847 - binary_accuracy: 0.9739 - auc_141: 0.9148 - precision_141: 0.7137 - recall_141: 0.2471 - val_loss: 0.2818 - val_binary_accuracy: 0.9739 - val_auc_141: 0.9226 - val_precision_141: 0.7254 - val_recall_141: 0.2507\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0811 - binary_accuracy: 0.9744 - auc_141: 0.9248 - precision_141: 0.7163 - recall_141: 0.2727 - val_loss: 0.1646 - val_binary_accuracy: 0.9742 - val_auc_141: 0.9289 - val_precision_141: 0.7433 - val_recall_141: 0.2548\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0787 - binary_accuracy: 0.9748 - auc_141: 0.9307 - precision_141: 0.7172 - recall_141: 0.2919 - val_loss: 0.1106 - val_binary_accuracy: 0.9745 - val_auc_141: 0.9328 - val_precision_141: 0.7242 - val_recall_141: 0.2841\n","Score for fold 2: F1 score of 0.40808485540360284; loss of 0.1105937510728836; binary_accuracy of 97.44792580604553%\n","Training for fold 3 ...\n","Epoch 1/5\n","98/98 [==============================] - 10s 88ms/step - loss: 0.1269 - binary_accuracy: 0.9619 - auc_142: 0.8009 - precision_142: 0.2712 - recall_142: 0.1425 - val_loss: 0.5247 - val_binary_accuracy: 0.9727 - val_auc_142: 0.8665 - val_precision_142: 0.7162 - val_recall_142: 0.1636\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0929 - binary_accuracy: 0.9729 - auc_142: 0.8859 - precision_142: 0.7175 - recall_142: 0.1971 - val_loss: 0.3912 - val_binary_accuracy: 0.9737 - val_auc_142: 0.9033 - val_precision_142: 0.7287 - val_recall_142: 0.2084\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0853 - binary_accuracy: 0.9738 - auc_142: 0.9127 - precision_142: 0.7134 - recall_142: 0.2463 - val_loss: 0.2782 - val_binary_accuracy: 0.9743 - val_auc_142: 0.9204 - val_precision_142: 0.7044 - val_recall_142: 0.2603\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0813 - binary_accuracy: 0.9743 - auc_142: 0.9245 - precision_142: 0.7144 - recall_142: 0.2733 - val_loss: 0.1849 - val_binary_accuracy: 0.9747 - val_auc_142: 0.9291 - val_precision_142: 0.6939 - val_recall_142: 0.2939\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0788 - binary_accuracy: 0.9747 - auc_142: 0.9306 - precision_142: 0.7159 - recall_142: 0.2937 - val_loss: 0.1157 - val_binary_accuracy: 0.9750 - val_auc_142: 0.9342 - val_precision_142: 0.7035 - val_recall_142: 0.3038\n","Score for fold 3: F1 score of 0.4243581257855249; loss of 0.11573369055986404; binary_accuracy of 97.50230312347412%\n","Training for fold 4 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1250 - binary_accuracy: 0.9630 - auc_143: 0.8051 - precision_143: 0.2936 - recall_143: 0.1459 - val_loss: 0.5249 - val_binary_accuracy: 0.9726 - val_auc_143: 0.8744 - val_precision_143: 0.7211 - val_recall_143: 0.1678\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0905 - binary_accuracy: 0.9732 - auc_143: 0.8949 - precision_143: 0.7122 - recall_143: 0.2144 - val_loss: 0.3943 - val_binary_accuracy: 0.9736 - val_auc_143: 0.9113 - val_precision_143: 0.7070 - val_recall_143: 0.2330\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_143: 0.9158 - precision_143: 0.7133 - recall_143: 0.2525 - val_loss: 0.2737 - val_binary_accuracy: 0.9741 - val_auc_143: 0.9246 - val_precision_143: 0.7106 - val_recall_143: 0.2575\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0807 - binary_accuracy: 0.9744 - auc_143: 0.9257 - precision_143: 0.7157 - recall_143: 0.2775 - val_loss: 0.1764 - val_binary_accuracy: 0.9745 - val_auc_143: 0.9316 - val_precision_143: 0.6993 - val_recall_143: 0.2898\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0783 - binary_accuracy: 0.9748 - auc_143: 0.9317 - precision_143: 0.7164 - recall_143: 0.2977 - val_loss: 0.1104 - val_binary_accuracy: 0.9748 - val_auc_143: 0.9358 - val_precision_143: 0.7252 - val_recall_143: 0.2824\n","Score for fold 4: F1 score of 0.4065481504400907; loss of 0.11038510501384735; binary_accuracy of 97.47908115386963%\n","Training for fold 5 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1256 - binary_accuracy: 0.9628 - auc_144: 0.8026 - precision_144: 0.2864 - recall_144: 0.1428 - val_loss: 0.5268 - val_binary_accuracy: 0.9724 - val_auc_144: 0.8673 - val_precision_144: 0.7101 - val_recall_144: 0.1778\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0918 - binary_accuracy: 0.9731 - auc_144: 0.8890 - precision_144: 0.7141 - recall_144: 0.2075 - val_loss: 0.3848 - val_binary_accuracy: 0.9733 - val_auc_144: 0.9059 - val_precision_144: 0.7401 - val_recall_144: 0.2047\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0848 - binary_accuracy: 0.9739 - auc_144: 0.9139 - precision_144: 0.7152 - recall_144: 0.2481 - val_loss: 0.2790 - val_binary_accuracy: 0.9740 - val_auc_144: 0.9219 - val_precision_144: 0.6978 - val_recall_144: 0.2768\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0813 - binary_accuracy: 0.9744 - auc_144: 0.9240 - precision_144: 0.7138 - recall_144: 0.2737 - val_loss: 0.1757 - val_binary_accuracy: 0.9744 - val_auc_144: 0.9286 - val_precision_144: 0.7163 - val_recall_144: 0.2791\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0785 - binary_accuracy: 0.9748 - auc_144: 0.9312 - precision_144: 0.7172 - recall_144: 0.2948 - val_loss: 0.1168 - val_binary_accuracy: 0.9747 - val_auc_144: 0.9339 - val_precision_144: 0.6995 - val_recall_144: 0.3124\n","Score for fold 5: F1 score of 0.43195507113446713; loss of 0.11675741523504257; binary_accuracy of 97.46938943862915%\n","Training for fold 6 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1260 - binary_accuracy: 0.9625 - auc_145: 0.8030 - precision_145: 0.2798 - recall_145: 0.1408 - val_loss: 0.5304 - val_binary_accuracy: 0.9727 - val_auc_145: 0.8727 - val_precision_145: 0.7106 - val_recall_145: 0.1726\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0908 - binary_accuracy: 0.9732 - auc_145: 0.8938 - precision_145: 0.7131 - recall_145: 0.2105 - val_loss: 0.3964 - val_binary_accuracy: 0.9737 - val_auc_145: 0.9124 - val_precision_145: 0.7194 - val_recall_145: 0.2250\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_145: 0.9162 - precision_145: 0.7149 - recall_145: 0.2516 - val_loss: 0.2817 - val_binary_accuracy: 0.9743 - val_auc_145: 0.9243 - val_precision_145: 0.7069 - val_recall_145: 0.2641\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0809 - binary_accuracy: 0.9744 - auc_145: 0.9255 - precision_145: 0.7166 - recall_145: 0.2755 - val_loss: 0.1712 - val_binary_accuracy: 0.9745 - val_auc_145: 0.9304 - val_precision_145: 0.7356 - val_recall_145: 0.2547\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0785 - binary_accuracy: 0.9748 - auc_145: 0.9311 - precision_145: 0.7169 - recall_145: 0.2949 - val_loss: 0.1106 - val_binary_accuracy: 0.9748 - val_auc_145: 0.9338 - val_precision_145: 0.7067 - val_recall_145: 0.2931\n","Score for fold 6: F1 score of 0.4143279609596034; loss of 0.110623799264431; binary_accuracy of 97.47647047042847%\n","Training for fold 7 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1265 - binary_accuracy: 0.9622 - auc_146: 0.8023 - precision_146: 0.2751 - recall_146: 0.1417 - val_loss: 0.5011 - val_binary_accuracy: 0.9723 - val_auc_146: 0.8696 - val_precision_146: 0.7266 - val_recall_146: 0.1636\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0923 - binary_accuracy: 0.9731 - auc_146: 0.8873 - precision_146: 0.7139 - recall_146: 0.2034 - val_loss: 0.3510 - val_binary_accuracy: 0.9730 - val_auc_146: 0.9042 - val_precision_146: 0.7606 - val_recall_146: 0.1828\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0853 - binary_accuracy: 0.9738 - auc_146: 0.9121 - precision_146: 0.7124 - recall_146: 0.2464 - val_loss: 0.2544 - val_binary_accuracy: 0.9737 - val_auc_146: 0.9210 - val_precision_146: 0.7280 - val_recall_146: 0.2397\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0814 - binary_accuracy: 0.9743 - auc_146: 0.9239 - precision_146: 0.7149 - recall_146: 0.2718 - val_loss: 0.1850 - val_binary_accuracy: 0.9743 - val_auc_146: 0.9301 - val_precision_146: 0.6984 - val_recall_146: 0.2976\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0789 - binary_accuracy: 0.9747 - auc_146: 0.9299 - precision_146: 0.7156 - recall_146: 0.2918 - val_loss: 0.1146 - val_binary_accuracy: 0.9747 - val_auc_146: 0.9344 - val_precision_146: 0.7097 - val_recall_146: 0.3042\n","Score for fold 7: F1 score of 0.4258821743003508; loss of 0.11458718031644821; binary_accuracy of 97.46633768081665%\n","Training for fold 8 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1269 - binary_accuracy: 0.9618 - auc_147: 0.8009 - precision_147: 0.2708 - recall_147: 0.1442 - val_loss: 0.5191 - val_binary_accuracy: 0.9726 - val_auc_147: 0.8699 - val_precision_147: 0.7268 - val_recall_147: 0.1717\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0917 - binary_accuracy: 0.9731 - auc_147: 0.8898 - precision_147: 0.7141 - recall_147: 0.2055 - val_loss: 0.3719 - val_binary_accuracy: 0.9735 - val_auc_147: 0.9077 - val_precision_147: 0.7421 - val_recall_147: 0.2080\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0849 - binary_accuracy: 0.9739 - auc_147: 0.9141 - precision_147: 0.7148 - recall_147: 0.2465 - val_loss: 0.2612 - val_binary_accuracy: 0.9741 - val_auc_147: 0.9215 - val_precision_147: 0.7293 - val_recall_147: 0.2507\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0811 - binary_accuracy: 0.9743 - auc_147: 0.9247 - precision_147: 0.7145 - recall_147: 0.2725 - val_loss: 0.1706 - val_binary_accuracy: 0.9745 - val_auc_147: 0.9302 - val_precision_147: 0.7195 - val_recall_147: 0.2782\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_147: 0.9305 - precision_147: 0.7152 - recall_147: 0.2928 - val_loss: 0.1134 - val_binary_accuracy: 0.9749 - val_auc_147: 0.9348 - val_precision_147: 0.7127 - val_recall_147: 0.3037\n","Score for fold 8: F1 score of 0.4259062502733868; loss of 0.11343355476856232; binary_accuracy of 97.48628735542297%\n","Training for fold 9 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 21ms/step - loss: 0.1260 - binary_accuracy: 0.9622 - auc_148: 0.8044 - precision_148: 0.2814 - recall_148: 0.1476 - val_loss: 0.5163 - val_binary_accuracy: 0.9727 - val_auc_148: 0.8758 - val_precision_148: 0.7180 - val_recall_148: 0.1704\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0908 - binary_accuracy: 0.9731 - auc_148: 0.8944 - precision_148: 0.7124 - recall_148: 0.2092 - val_loss: 0.3718 - val_binary_accuracy: 0.9736 - val_auc_148: 0.9086 - val_precision_148: 0.7142 - val_recall_148: 0.2197\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0847 - binary_accuracy: 0.9739 - auc_148: 0.9150 - precision_148: 0.7137 - recall_148: 0.2489 - val_loss: 0.2751 - val_binary_accuracy: 0.9743 - val_auc_148: 0.9230 - val_precision_148: 0.7064 - val_recall_148: 0.2633\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0811 - binary_accuracy: 0.9743 - auc_148: 0.9250 - precision_148: 0.7148 - recall_148: 0.2742 - val_loss: 0.1726 - val_binary_accuracy: 0.9746 - val_auc_148: 0.9304 - val_precision_148: 0.7164 - val_recall_148: 0.2751\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0788 - binary_accuracy: 0.9747 - auc_148: 0.9304 - precision_148: 0.7166 - recall_148: 0.2935 - val_loss: 0.1170 - val_binary_accuracy: 0.9749 - val_auc_148: 0.9348 - val_precision_148: 0.6946 - val_recall_148: 0.3139\n","Score for fold 9: F1 score of 0.43236870755610146; loss of 0.11702064424753189; binary_accuracy of 97.49292135238647%\n","Training for fold 10 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1268 - binary_accuracy: 0.9620 - auc_149: 0.8019 - precision_149: 0.2752 - recall_149: 0.1461 - val_loss: 0.5343 - val_binary_accuracy: 0.9724 - val_auc_149: 0.8688 - val_precision_149: 0.6989 - val_recall_149: 0.1794\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0914 - binary_accuracy: 0.9731 - auc_149: 0.8915 - precision_149: 0.7133 - recall_149: 0.2082 - val_loss: 0.3916 - val_binary_accuracy: 0.9734 - val_auc_149: 0.9102 - val_precision_149: 0.7265 - val_recall_149: 0.2174\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_149: 0.9159 - precision_149: 0.7130 - recall_149: 0.2515 - val_loss: 0.2761 - val_binary_accuracy: 0.9739 - val_auc_149: 0.9228 - val_precision_149: 0.7284 - val_recall_149: 0.2410\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - auc_149: 0.9251 - precision_149: 0.7147 - recall_149: 0.2750 - val_loss: 0.1809 - val_binary_accuracy: 0.9743 - val_auc_149: 0.9297 - val_precision_149: 0.7004 - val_recall_149: 0.2897\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0785 - binary_accuracy: 0.9748 - auc_149: 0.9311 - precision_149: 0.7171 - recall_149: 0.2942 - val_loss: 0.1042 - val_binary_accuracy: 0.9745 - val_auc_149: 0.9336 - val_precision_149: 0.7477 - val_recall_149: 0.2599\n","Score for fold 10: F1 score of 0.3857541609432461; loss of 0.10424839705228806; binary_accuracy of 97.45240807533264%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  64\n","Training for fold 1 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1212 - binary_accuracy: 0.9627 - auc_150: 0.8159 - precision_150: 0.2972 - recall_150: 0.1575 - val_loss: 0.5318 - val_binary_accuracy: 0.9727 - val_auc_150: 0.8795 - val_precision_150: 0.7280 - val_recall_150: 0.1836\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0890 - binary_accuracy: 0.9735 - auc_150: 0.8985 - precision_150: 0.7164 - recall_150: 0.2248 - val_loss: 0.3965 - val_binary_accuracy: 0.9737 - val_auc_150: 0.9137 - val_precision_150: 0.7207 - val_recall_150: 0.2380\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0827 - binary_accuracy: 0.9742 - auc_150: 0.9195 - precision_150: 0.7144 - recall_150: 0.2661 - val_loss: 0.2657 - val_binary_accuracy: 0.9741 - val_auc_150: 0.9267 - val_precision_150: 0.7469 - val_recall_150: 0.2392\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0794 - binary_accuracy: 0.9747 - auc_150: 0.9283 - precision_150: 0.7167 - recall_150: 0.2902 - val_loss: 0.1868 - val_binary_accuracy: 0.9745 - val_auc_150: 0.9331 - val_precision_150: 0.6974 - val_recall_150: 0.3057\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0771 - binary_accuracy: 0.9751 - auc_150: 0.9339 - precision_150: 0.7182 - recall_150: 0.3093 - val_loss: 0.1139 - val_binary_accuracy: 0.9748 - val_auc_150: 0.9365 - val_precision_150: 0.7157 - val_recall_150: 0.3032\n","Score for fold 1: F1 score of 0.42592051065165193; loss of 0.1138860359787941; binary_accuracy of 97.48318791389465%\n","Training for fold 2 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1220 - binary_accuracy: 0.9626 - auc_151: 0.8141 - precision_151: 0.2935 - recall_151: 0.1546 - val_loss: 0.5367 - val_binary_accuracy: 0.9727 - val_auc_151: 0.8775 - val_precision_151: 0.7233 - val_recall_151: 0.1789\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0896 - binary_accuracy: 0.9734 - auc_151: 0.8970 - precision_151: 0.7156 - recall_151: 0.2195 - val_loss: 0.3963 - val_binary_accuracy: 0.9737 - val_auc_151: 0.9121 - val_precision_151: 0.7218 - val_recall_151: 0.2313\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0833 - binary_accuracy: 0.9741 - auc_151: 0.9181 - precision_151: 0.7154 - recall_151: 0.2607 - val_loss: 0.2803 - val_binary_accuracy: 0.9743 - val_auc_151: 0.9254 - val_precision_151: 0.7199 - val_recall_151: 0.2634\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0798 - binary_accuracy: 0.9746 - auc_151: 0.9276 - precision_151: 0.7151 - recall_151: 0.2873 - val_loss: 0.1891 - val_binary_accuracy: 0.9745 - val_auc_151: 0.9322 - val_precision_151: 0.7050 - val_recall_151: 0.2914\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0778 - binary_accuracy: 0.9750 - auc_151: 0.9324 - precision_151: 0.7163 - recall_151: 0.3050 - val_loss: 0.1136 - val_binary_accuracy: 0.9749 - val_auc_151: 0.9359 - val_precision_151: 0.7112 - val_recall_151: 0.3049\n","Score for fold 2: F1 score of 0.4267997672512515; loss of 0.11363956332206726; binary_accuracy of 97.48736619949341%\n","Training for fold 3 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 13ms/step - loss: 0.1208 - binary_accuracy: 0.9627 - auc_152: 0.8170 - precision_152: 0.3008 - recall_152: 0.1615 - val_loss: 0.5335 - val_binary_accuracy: 0.9731 - val_auc_152: 0.8858 - val_precision_152: 0.7140 - val_recall_152: 0.1995\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0885 - binary_accuracy: 0.9735 - auc_152: 0.9015 - precision_152: 0.7131 - recall_152: 0.2287 - val_loss: 0.3841 - val_binary_accuracy: 0.9738 - val_auc_152: 0.9155 - val_precision_152: 0.7399 - val_recall_152: 0.2192\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0828 - binary_accuracy: 0.9742 - auc_152: 0.9194 - precision_152: 0.7146 - recall_152: 0.2651 - val_loss: 0.2830 - val_binary_accuracy: 0.9746 - val_auc_152: 0.9277 - val_precision_152: 0.7193 - val_recall_152: 0.2733\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0794 - binary_accuracy: 0.9747 - auc_152: 0.9288 - precision_152: 0.7167 - recall_152: 0.2898 - val_loss: 0.1769 - val_binary_accuracy: 0.9748 - val_auc_152: 0.9331 - val_precision_152: 0.7437 - val_recall_152: 0.2643\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0771 - binary_accuracy: 0.9751 - auc_152: 0.9340 - precision_152: 0.7194 - recall_152: 0.3079 - val_loss: 0.1272 - val_binary_accuracy: 0.9749 - val_auc_152: 0.9368 - val_precision_152: 0.6637 - val_recall_152: 0.3590\n","Score for fold 3: F1 score of 0.46599281869895987; loss of 0.12723691761493683; binary_accuracy of 97.49030470848083%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_MF_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_MF_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Molecular Function has 32 filters, with a kernel size of 64 and has an F1 score of 0.46599281869895987\n","Training for fold 4 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1215 - binary_accuracy: 0.9626 - auc_153: 0.8142 - precision_153: 0.2938 - recall_153: 0.1573 - val_loss: 0.5436 - val_binary_accuracy: 0.9727 - val_auc_153: 0.8755 - val_precision_153: 0.7255 - val_recall_153: 0.1879\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0890 - binary_accuracy: 0.9735 - auc_153: 0.8985 - precision_153: 0.7132 - recall_153: 0.2256 - val_loss: 0.3984 - val_binary_accuracy: 0.9735 - val_auc_153: 0.9129 - val_precision_153: 0.7196 - val_recall_153: 0.2365\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0829 - binary_accuracy: 0.9742 - auc_153: 0.9188 - precision_153: 0.7145 - recall_153: 0.2642 - val_loss: 0.2830 - val_binary_accuracy: 0.9740 - val_auc_153: 0.9244 - val_precision_153: 0.7214 - val_recall_153: 0.2593\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0797 - binary_accuracy: 0.9746 - auc_153: 0.9276 - precision_153: 0.7147 - recall_153: 0.2880 - val_loss: 0.1825 - val_binary_accuracy: 0.9744 - val_auc_153: 0.9312 - val_precision_153: 0.7192 - val_recall_153: 0.2843\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0772 - binary_accuracy: 0.9751 - auc_153: 0.9336 - precision_153: 0.7189 - recall_153: 0.3081 - val_loss: 0.1079 - val_binary_accuracy: 0.9745 - val_auc_153: 0.9339 - val_precision_153: 0.7331 - val_recall_153: 0.2775\n","Score for fold 4: F1 score of 0.40256689758229813; loss of 0.10787194967269897; binary_accuracy of 97.45277762413025%\n","Training for fold 5 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9630 - auc_154: 0.8191 - precision_154: 0.3026 - recall_154: 0.1584 - val_loss: 0.5286 - val_binary_accuracy: 0.9728 - val_auc_154: 0.8861 - val_precision_154: 0.7346 - val_recall_154: 0.1836\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0880 - binary_accuracy: 0.9735 - auc_154: 0.9038 - precision_154: 0.7116 - recall_154: 0.2284 - val_loss: 0.3928 - val_binary_accuracy: 0.9736 - val_auc_154: 0.9152 - val_precision_154: 0.7367 - val_recall_154: 0.2259\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0825 - binary_accuracy: 0.9742 - auc_154: 0.9207 - precision_154: 0.7138 - recall_154: 0.2646 - val_loss: 0.2672 - val_binary_accuracy: 0.9741 - val_auc_154: 0.9253 - val_precision_154: 0.7391 - val_recall_154: 0.2464\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0794 - binary_accuracy: 0.9747 - auc_154: 0.9287 - precision_154: 0.7160 - recall_154: 0.2887 - val_loss: 0.1868 - val_binary_accuracy: 0.9746 - val_auc_154: 0.9313 - val_precision_154: 0.7180 - val_recall_154: 0.2933\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0772 - binary_accuracy: 0.9751 - auc_154: 0.9337 - precision_154: 0.7182 - recall_154: 0.3083 - val_loss: 0.1111 - val_binary_accuracy: 0.9748 - val_auc_154: 0.9352 - val_precision_154: 0.7311 - val_recall_154: 0.2905\n","Score for fold 5: F1 score of 0.41577783670286556; loss of 0.11107737571001053; binary_accuracy of 97.48060703277588%\n","Training for fold 6 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1218 - binary_accuracy: 0.9625 - auc_155: 0.8146 - precision_155: 0.2961 - recall_155: 0.1613 - val_loss: 0.5343 - val_binary_accuracy: 0.9729 - val_auc_155: 0.8800 - val_precision_155: 0.7184 - val_recall_155: 0.1899\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0893 - binary_accuracy: 0.9735 - auc_155: 0.8981 - precision_155: 0.7154 - recall_155: 0.2239 - val_loss: 0.3895 - val_binary_accuracy: 0.9735 - val_auc_155: 0.9119 - val_precision_155: 0.7376 - val_recall_155: 0.2134\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0832 - binary_accuracy: 0.9742 - auc_155: 0.9182 - precision_155: 0.7149 - recall_155: 0.2629 - val_loss: 0.2895 - val_binary_accuracy: 0.9744 - val_auc_155: 0.9270 - val_precision_155: 0.7018 - val_recall_155: 0.2909\n","Epoch 4/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0798 - binary_accuracy: 0.9746 - auc_155: 0.9275 - precision_155: 0.7156 - recall_155: 0.2871 - val_loss: 0.1831 - val_binary_accuracy: 0.9747 - val_auc_155: 0.9331 - val_precision_155: 0.6992 - val_recall_155: 0.3081\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0776 - binary_accuracy: 0.9750 - auc_155: 0.9327 - precision_155: 0.7171 - recall_155: 0.3050 - val_loss: 0.1123 - val_binary_accuracy: 0.9751 - val_auc_155: 0.9366 - val_precision_155: 0.7184 - val_recall_155: 0.3084\n","Score for fold 6: F1 score of 0.431605291813546; loss of 0.11228401958942413; binary_accuracy of 97.50678539276123%\n","Training for fold 7 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1213 - binary_accuracy: 0.9630 - auc_156: 0.8146 - precision_156: 0.3028 - recall_156: 0.1584 - val_loss: 0.5432 - val_binary_accuracy: 0.9726 - val_auc_156: 0.8819 - val_precision_156: 0.7199 - val_recall_156: 0.1914\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0887 - binary_accuracy: 0.9734 - auc_156: 0.9009 - precision_156: 0.7122 - recall_156: 0.2238 - val_loss: 0.4009 - val_binary_accuracy: 0.9733 - val_auc_156: 0.9124 - val_precision_156: 0.7290 - val_recall_156: 0.2220\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0831 - binary_accuracy: 0.9742 - auc_156: 0.9186 - precision_156: 0.7149 - recall_156: 0.2612 - val_loss: 0.2745 - val_binary_accuracy: 0.9740 - val_auc_156: 0.9258 - val_precision_156: 0.7552 - val_recall_156: 0.2374\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0798 - binary_accuracy: 0.9746 - auc_156: 0.9273 - precision_156: 0.7162 - recall_156: 0.2850 - val_loss: 0.1695 - val_binary_accuracy: 0.9744 - val_auc_156: 0.9316 - val_precision_156: 0.7286 - val_recall_156: 0.2799\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0776 - binary_accuracy: 0.9750 - auc_156: 0.9326 - precision_156: 0.7183 - recall_156: 0.3041 - val_loss: 0.1228 - val_binary_accuracy: 0.9746 - val_auc_156: 0.9358 - val_precision_156: 0.6831 - val_recall_156: 0.3394\n","Score for fold 7: F1 score of 0.45352322244299725; loss of 0.12282425910234451; binary_accuracy of 97.463858127594%\n","Training for fold 8 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1213 - binary_accuracy: 0.9630 - auc_157: 0.8139 - precision_157: 0.3032 - recall_157: 0.1559 - val_loss: 0.5192 - val_binary_accuracy: 0.9729 - val_auc_157: 0.8743 - val_precision_157: 0.7171 - val_recall_157: 0.1760\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0900 - binary_accuracy: 0.9734 - auc_157: 0.8953 - precision_157: 0.7141 - recall_157: 0.2218 - val_loss: 0.3851 - val_binary_accuracy: 0.9736 - val_auc_157: 0.9105 - val_precision_157: 0.7318 - val_recall_157: 0.2037\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0834 - binary_accuracy: 0.9741 - auc_157: 0.9178 - precision_157: 0.7148 - recall_157: 0.2620 - val_loss: 0.2837 - val_binary_accuracy: 0.9745 - val_auc_157: 0.9256 - val_precision_157: 0.7183 - val_recall_157: 0.2571\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0802 - binary_accuracy: 0.9745 - auc_157: 0.9269 - precision_157: 0.7142 - recall_157: 0.2863 - val_loss: 0.1866 - val_binary_accuracy: 0.9748 - val_auc_157: 0.9325 - val_precision_157: 0.6836 - val_recall_157: 0.3115\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0776 - binary_accuracy: 0.9750 - auc_157: 0.9333 - precision_157: 0.7182 - recall_157: 0.3055 - val_loss: 0.1201 - val_binary_accuracy: 0.9752 - val_auc_157: 0.9367 - val_precision_157: 0.6873 - val_recall_157: 0.3312\n","Score for fold 8: F1 score of 0.4470086730434029; loss of 0.12008985877037048; binary_accuracy of 97.51866459846497%\n","Training for fold 9 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 19ms/step - loss: 0.1223 - binary_accuracy: 0.9622 - auc_158: 0.8130 - precision_158: 0.2863 - recall_158: 0.1527 - val_loss: 0.5178 - val_binary_accuracy: 0.9731 - val_auc_158: 0.8755 - val_precision_158: 0.7278 - val_recall_158: 0.1740\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0904 - binary_accuracy: 0.9733 - auc_158: 0.8941 - precision_158: 0.7136 - recall_158: 0.2192 - val_loss: 0.3758 - val_binary_accuracy: 0.9738 - val_auc_158: 0.9102 - val_precision_158: 0.7190 - val_recall_158: 0.2180\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0838 - binary_accuracy: 0.9741 - auc_158: 0.9168 - precision_158: 0.7147 - recall_158: 0.2605 - val_loss: 0.2671 - val_binary_accuracy: 0.9745 - val_auc_158: 0.9250 - val_precision_158: 0.7352 - val_recall_158: 0.2410\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0802 - binary_accuracy: 0.9745 - auc_158: 0.9267 - precision_158: 0.7151 - recall_158: 0.2851 - val_loss: 0.1809 - val_binary_accuracy: 0.9749 - val_auc_158: 0.9325 - val_precision_158: 0.6887 - val_recall_158: 0.3086\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0777 - binary_accuracy: 0.9750 - auc_158: 0.9328 - precision_158: 0.7188 - recall_158: 0.3050 - val_loss: 0.1182 - val_binary_accuracy: 0.9753 - val_auc_158: 0.9372 - val_precision_158: 0.7026 - val_recall_158: 0.3136\n","Score for fold 9: F1 score of 0.4336230931645287; loss of 0.11822777986526489; binary_accuracy of 97.52981662750244%\n","Training for fold 10 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 14ms/step - loss: 0.1214 - binary_accuracy: 0.9630 - auc_159: 0.8145 - precision_159: 0.2988 - recall_159: 0.1529 - val_loss: 0.5494 - val_binary_accuracy: 0.9726 - val_auc_159: 0.8781 - val_precision_159: 0.7137 - val_recall_159: 0.1909\n","Epoch 2/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0892 - binary_accuracy: 0.9734 - auc_159: 0.8982 - precision_159: 0.7124 - recall_159: 0.2231 - val_loss: 0.3996 - val_binary_accuracy: 0.9734 - val_auc_159: 0.9133 - val_precision_159: 0.7296 - val_recall_159: 0.2251\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0830 - binary_accuracy: 0.9742 - auc_159: 0.9189 - precision_159: 0.7142 - recall_159: 0.2627 - val_loss: 0.2887 - val_binary_accuracy: 0.9740 - val_auc_159: 0.9254 - val_precision_159: 0.6974 - val_recall_159: 0.2846\n","Epoch 4/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0796 - binary_accuracy: 0.9747 - auc_159: 0.9281 - precision_159: 0.7157 - recall_159: 0.2878 - val_loss: 0.1970 - val_binary_accuracy: 0.9743 - val_auc_159: 0.9309 - val_precision_159: 0.6930 - val_recall_159: 0.3032\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0773 - binary_accuracy: 0.9750 - auc_159: 0.9335 - precision_159: 0.7175 - recall_159: 0.3064 - val_loss: 0.1125 - val_binary_accuracy: 0.9747 - val_auc_159: 0.9352 - val_precision_159: 0.7177 - val_recall_159: 0.3002\n","Score for fold 10: F1 score of 0.42333917146334804; loss of 0.11247411370277405; binary_accuracy of 97.46683239936829%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  128\n","Training for fold 1 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 19ms/step - loss: 0.1229 - binary_accuracy: 0.9623 - auc_160: 0.8095 - precision_160: 0.2862 - recall_160: 0.1520 - val_loss: 0.5308 - val_binary_accuracy: 0.9728 - val_auc_160: 0.8703 - val_precision_160: 0.7167 - val_recall_160: 0.1782\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0905 - binary_accuracy: 0.9733 - auc_160: 0.8927 - precision_160: 0.7135 - recall_160: 0.2193 - val_loss: 0.3973 - val_binary_accuracy: 0.9737 - val_auc_160: 0.9116 - val_precision_160: 0.7221 - val_recall_160: 0.2276\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0836 - binary_accuracy: 0.9741 - auc_160: 0.9169 - precision_160: 0.7144 - recall_160: 0.2607 - val_loss: 0.2760 - val_binary_accuracy: 0.9742 - val_auc_160: 0.9257 - val_precision_160: 0.7407 - val_recall_160: 0.2392\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0802 - binary_accuracy: 0.9746 - auc_160: 0.9267 - precision_160: 0.7152 - recall_160: 0.2852 - val_loss: 0.1855 - val_binary_accuracy: 0.9747 - val_auc_160: 0.9327 - val_precision_160: 0.7165 - val_recall_160: 0.2835\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0778 - binary_accuracy: 0.9750 - auc_160: 0.9324 - precision_160: 0.7183 - recall_160: 0.3051 - val_loss: 0.1228 - val_binary_accuracy: 0.9748 - val_auc_160: 0.9358 - val_precision_160: 0.6735 - val_recall_160: 0.3355\n","Score for fold 1: F1 score of 0.4478755867368251; loss of 0.12280263751745224; binary_accuracy of 97.47526049613953%\n","Training for fold 2 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 15ms/step - loss: 0.1219 - binary_accuracy: 0.9620 - auc_161: 0.8141 - precision_161: 0.2835 - recall_161: 0.1551 - val_loss: 0.5270 - val_binary_accuracy: 0.9729 - val_auc_161: 0.8797 - val_precision_161: 0.7383 - val_recall_161: 0.1775\n","Epoch 2/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0892 - binary_accuracy: 0.9734 - auc_161: 0.8985 - precision_161: 0.7132 - recall_161: 0.2237 - val_loss: 0.3851 - val_binary_accuracy: 0.9739 - val_auc_161: 0.9155 - val_precision_161: 0.7292 - val_recall_161: 0.2359\n","Epoch 3/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0828 - binary_accuracy: 0.9742 - auc_161: 0.9193 - precision_161: 0.7121 - recall_161: 0.2659 - val_loss: 0.2808 - val_binary_accuracy: 0.9745 - val_auc_161: 0.9280 - val_precision_161: 0.7069 - val_recall_161: 0.2853\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0795 - binary_accuracy: 0.9747 - auc_161: 0.9280 - precision_161: 0.7151 - recall_161: 0.2907 - val_loss: 0.1839 - val_binary_accuracy: 0.9749 - val_auc_161: 0.9344 - val_precision_161: 0.7214 - val_recall_161: 0.2958\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0771 - binary_accuracy: 0.9751 - auc_161: 0.9337 - precision_161: 0.7182 - recall_161: 0.3101 - val_loss: 0.1270 - val_binary_accuracy: 0.9750 - val_auc_161: 0.9378 - val_precision_161: 0.6803 - val_recall_161: 0.3478\n","Score for fold 2: F1 score of 0.46028686936819285; loss of 0.12697692215442657; binary_accuracy of 97.49957323074341%\n","Training for fold 3 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1218 - binary_accuracy: 0.9630 - auc_162: 0.8122 - precision_162: 0.2989 - recall_162: 0.1529 - val_loss: 0.5309 - val_binary_accuracy: 0.9728 - val_auc_162: 0.8804 - val_precision_162: 0.7191 - val_recall_162: 0.1903\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0888 - binary_accuracy: 0.9734 - auc_162: 0.9009 - precision_162: 0.7112 - recall_162: 0.2248 - val_loss: 0.3886 - val_binary_accuracy: 0.9737 - val_auc_162: 0.9159 - val_precision_162: 0.7499 - val_recall_162: 0.2175\n","Epoch 3/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0829 - binary_accuracy: 0.9741 - auc_162: 0.9196 - precision_162: 0.7136 - recall_162: 0.2620 - val_loss: 0.2850 - val_binary_accuracy: 0.9744 - val_auc_162: 0.9276 - val_precision_162: 0.7209 - val_recall_162: 0.2739\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0795 - binary_accuracy: 0.9746 - auc_162: 0.9283 - precision_162: 0.7161 - recall_162: 0.2876 - val_loss: 0.1987 - val_binary_accuracy: 0.9746 - val_auc_162: 0.9335 - val_precision_162: 0.6771 - val_recall_162: 0.3359\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0774 - binary_accuracy: 0.9750 - auc_162: 0.9332 - precision_162: 0.7171 - recall_162: 0.3072 - val_loss: 0.1271 - val_binary_accuracy: 0.9750 - val_auc_162: 0.9366 - val_precision_162: 0.6943 - val_recall_162: 0.3375\n","Score for fold 3: F1 score of 0.4541701731962356; loss of 0.1270546317100525; binary_accuracy of 97.50272631645203%\n","Training for fold 4 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 23ms/step - loss: 0.1213 - binary_accuracy: 0.9628 - auc_163: 0.8152 - precision_163: 0.2969 - recall_163: 0.1563 - val_loss: 0.5283 - val_binary_accuracy: 0.9726 - val_auc_163: 0.8830 - val_precision_163: 0.7345 - val_recall_163: 0.1779\n","Epoch 2/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0885 - binary_accuracy: 0.9734 - auc_163: 0.9016 - precision_163: 0.7101 - recall_163: 0.2262 - val_loss: 0.3837 - val_binary_accuracy: 0.9735 - val_auc_163: 0.9153 - val_precision_163: 0.7226 - val_recall_163: 0.2298\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0829 - binary_accuracy: 0.9742 - auc_163: 0.9193 - precision_163: 0.7155 - recall_163: 0.2625 - val_loss: 0.2722 - val_binary_accuracy: 0.9740 - val_auc_163: 0.9262 - val_precision_163: 0.7162 - val_recall_163: 0.2651\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0796 - binary_accuracy: 0.9747 - auc_163: 0.9279 - precision_163: 0.7157 - recall_163: 0.2877 - val_loss: 0.1836 - val_binary_accuracy: 0.9745 - val_auc_163: 0.9323 - val_precision_163: 0.7036 - val_recall_163: 0.3006\n","Epoch 5/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0773 - binary_accuracy: 0.9751 - auc_163: 0.9337 - precision_163: 0.7181 - recall_163: 0.3070 - val_loss: 0.1136 - val_binary_accuracy: 0.9748 - val_auc_163: 0.9365 - val_precision_163: 0.7122 - val_recall_163: 0.3106\n","Score for fold 4: F1 score of 0.4325574495238236; loss of 0.11363265663385391; binary_accuracy of 97.48071432113647%\n","Training for fold 5 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 18ms/step - loss: 0.1221 - binary_accuracy: 0.9624 - auc_164: 0.8140 - precision_164: 0.2922 - recall_164: 0.1584 - val_loss: 0.5302 - val_binary_accuracy: 0.9731 - val_auc_164: 0.8848 - val_precision_164: 0.7112 - val_recall_164: 0.2004\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0889 - binary_accuracy: 0.9734 - auc_164: 0.9007 - precision_164: 0.7135 - recall_164: 0.2230 - val_loss: 0.3993 - val_binary_accuracy: 0.9739 - val_auc_164: 0.9139 - val_precision_164: 0.7122 - val_recall_164: 0.2454\n","Epoch 3/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0833 - binary_accuracy: 0.9741 - auc_164: 0.9185 - precision_164: 0.7137 - recall_164: 0.2593 - val_loss: 0.2754 - val_binary_accuracy: 0.9745 - val_auc_164: 0.9254 - val_precision_164: 0.7239 - val_recall_164: 0.2654\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0800 - binary_accuracy: 0.9745 - auc_164: 0.9271 - precision_164: 0.7141 - recall_164: 0.2851 - val_loss: 0.1915 - val_binary_accuracy: 0.9747 - val_auc_164: 0.9309 - val_precision_164: 0.6856 - val_recall_164: 0.3204\n","Epoch 5/5\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0777 - binary_accuracy: 0.9749 - auc_164: 0.9329 - precision_164: 0.7171 - recall_164: 0.3036 - val_loss: 0.1037 - val_binary_accuracy: 0.9750 - val_auc_164: 0.9355 - val_precision_164: 0.7337 - val_recall_164: 0.2868\n","Score for fold 5: F1 score of 0.4123850728987031; loss of 0.10366176068782806; binary_accuracy of 97.5018322467804%\n","Training for fold 6 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 21ms/step - loss: 0.1218 - binary_accuracy: 0.9629 - auc_165: 0.8132 - precision_165: 0.3008 - recall_165: 0.1552 - val_loss: 0.5369 - val_binary_accuracy: 0.9732 - val_auc_165: 0.8781 - val_precision_165: 0.7087 - val_recall_165: 0.1952\n","Epoch 2/5\n","98/98 [==============================] - 15s 151ms/step - loss: 0.0896 - binary_accuracy: 0.9733 - auc_165: 0.8972 - precision_165: 0.7133 - recall_165: 0.2221 - val_loss: 0.3821 - val_binary_accuracy: 0.9741 - val_auc_165: 0.9133 - val_precision_165: 0.7228 - val_recall_165: 0.2341\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0831 - binary_accuracy: 0.9741 - auc_165: 0.9188 - precision_165: 0.7142 - recall_165: 0.2632 - val_loss: 0.2690 - val_binary_accuracy: 0.9746 - val_auc_165: 0.9245 - val_precision_165: 0.7400 - val_recall_165: 0.2456\n","Epoch 4/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0799 - binary_accuracy: 0.9746 - auc_165: 0.9274 - precision_165: 0.7168 - recall_165: 0.2877 - val_loss: 0.1887 - val_binary_accuracy: 0.9751 - val_auc_165: 0.9320 - val_precision_165: 0.6951 - val_recall_165: 0.3122\n","Epoch 5/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0775 - binary_accuracy: 0.9750 - auc_165: 0.9331 - precision_165: 0.7183 - recall_165: 0.3075 - val_loss: 0.1169 - val_binary_accuracy: 0.9753 - val_auc_165: 0.9351 - val_precision_165: 0.7054 - val_recall_165: 0.3134\n","Score for fold 6: F1 score of 0.43402572913993376; loss of 0.11692576855421066; binary_accuracy of 97.5283145904541%\n","Training for fold 7 ...\n","Epoch 1/5\n","98/98 [==============================] - 9s 20ms/step - loss: 0.1222 - binary_accuracy: 0.9624 - auc_166: 0.8135 - precision_166: 0.2895 - recall_166: 0.1543 - val_loss: 0.5390 - val_binary_accuracy: 0.9729 - val_auc_166: 0.8789 - val_precision_166: 0.7065 - val_recall_166: 0.1965\n","Epoch 2/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0894 - binary_accuracy: 0.9734 - auc_166: 0.8980 - precision_166: 0.7134 - recall_166: 0.2218 - val_loss: 0.3892 - val_binary_accuracy: 0.9738 - val_auc_166: 0.9130 - val_precision_166: 0.7318 - val_recall_166: 0.2282\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0830 - binary_accuracy: 0.9741 - auc_166: 0.9188 - precision_166: 0.7134 - recall_166: 0.2635 - val_loss: 0.2724 - val_binary_accuracy: 0.9742 - val_auc_166: 0.9257 - val_precision_166: 0.7394 - val_recall_166: 0.2426\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0797 - binary_accuracy: 0.9746 - auc_166: 0.9279 - precision_166: 0.7158 - recall_166: 0.2877 - val_loss: 0.1853 - val_binary_accuracy: 0.9747 - val_auc_166: 0.9323 - val_precision_166: 0.7015 - val_recall_166: 0.3058\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0773 - binary_accuracy: 0.9750 - auc_166: 0.9337 - precision_166: 0.7180 - recall_166: 0.3078 - val_loss: 0.1087 - val_binary_accuracy: 0.9749 - val_auc_166: 0.9358 - val_precision_166: 0.7194 - val_recall_166: 0.2975\n","Score for fold 7: F1 score of 0.42091683673088565; loss of 0.10865619778633118; binary_accuracy of 97.49112129211426%\n","Training for fold 8 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 20ms/step - loss: 0.1215 - binary_accuracy: 0.9625 - auc_167: 0.8148 - precision_167: 0.2909 - recall_167: 0.1544 - val_loss: 0.5257 - val_binary_accuracy: 0.9727 - val_auc_167: 0.8795 - val_precision_167: 0.7136 - val_recall_167: 0.1862\n","Epoch 2/5\n","98/98 [==============================] - 2s 25ms/step - loss: 0.0890 - binary_accuracy: 0.9734 - auc_167: 0.8996 - precision_167: 0.7122 - recall_167: 0.2243 - val_loss: 0.3887 - val_binary_accuracy: 0.9736 - val_auc_167: 0.9139 - val_precision_167: 0.7033 - val_recall_167: 0.2432\n","Epoch 3/5\n","98/98 [==============================] - 2s 23ms/step - loss: 0.0829 - binary_accuracy: 0.9742 - auc_167: 0.9193 - precision_167: 0.7148 - recall_167: 0.2634 - val_loss: 0.2565 - val_binary_accuracy: 0.9739 - val_auc_167: 0.9255 - val_precision_167: 0.7514 - val_recall_167: 0.2288\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0795 - binary_accuracy: 0.9747 - auc_167: 0.9280 - precision_167: 0.7169 - recall_167: 0.2888 - val_loss: 0.1647 - val_binary_accuracy: 0.9745 - val_auc_167: 0.9320 - val_precision_167: 0.7276 - val_recall_167: 0.2718\n","Epoch 5/5\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0772 - binary_accuracy: 0.9751 - auc_167: 0.9337 - precision_167: 0.7188 - recall_167: 0.3080 - val_loss: 0.1184 - val_binary_accuracy: 0.9748 - val_auc_167: 0.9354 - val_precision_167: 0.7129 - val_recall_167: 0.3008\n","Score for fold 8: F1 score of 0.42310386787486104; loss of 0.1183934137225151; binary_accuracy of 97.47613072395325%\n","Training for fold 9 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 22ms/step - loss: 0.1220 - binary_accuracy: 0.9627 - auc_168: 0.8126 - precision_168: 0.2936 - recall_168: 0.1533 - val_loss: 0.5316 - val_binary_accuracy: 0.9724 - val_auc_168: 0.8748 - val_precision_168: 0.7233 - val_recall_168: 0.1803\n","Epoch 2/5\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0893 - binary_accuracy: 0.9734 - auc_168: 0.8981 - precision_168: 0.7126 - recall_168: 0.2238 - val_loss: 0.4160 - val_binary_accuracy: 0.9734 - val_auc_168: 0.9129 - val_precision_168: 0.6998 - val_recall_168: 0.2503\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0830 - binary_accuracy: 0.9742 - auc_168: 0.9185 - precision_168: 0.7137 - recall_168: 0.2626 - val_loss: 0.2701 - val_binary_accuracy: 0.9739 - val_auc_168: 0.9254 - val_precision_168: 0.7254 - val_recall_168: 0.2563\n","Epoch 4/5\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0797 - binary_accuracy: 0.9746 - auc_168: 0.9277 - precision_168: 0.7154 - recall_168: 0.2863 - val_loss: 0.1865 - val_binary_accuracy: 0.9743 - val_auc_168: 0.9317 - val_precision_168: 0.7098 - val_recall_168: 0.2913\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0773 - binary_accuracy: 0.9751 - auc_168: 0.9334 - precision_168: 0.7182 - recall_168: 0.3065 - val_loss: 0.1215 - val_binary_accuracy: 0.9744 - val_auc_168: 0.9351 - val_precision_168: 0.6862 - val_recall_168: 0.3238\n","Score for fold 9: F1 score of 0.4399845029097734; loss of 0.12146652489900589; binary_accuracy of 97.44063019752502%\n","Training for fold 10 ...\n","Epoch 1/5\n","98/98 [==============================] - 6s 34ms/step - loss: 0.1218 - binary_accuracy: 0.9630 - auc_169: 0.8113 - precision_169: 0.2989 - recall_169: 0.1539 - val_loss: 0.5319 - val_binary_accuracy: 0.9727 - val_auc_169: 0.8761 - val_precision_169: 0.7061 - val_recall_169: 0.1930\n","Epoch 2/5\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0890 - binary_accuracy: 0.9735 - auc_169: 0.8993 - precision_169: 0.7144 - recall_169: 0.2251 - val_loss: 0.3805 - val_binary_accuracy: 0.9737 - val_auc_169: 0.9161 - val_precision_169: 0.7262 - val_recall_169: 0.2321\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0826 - binary_accuracy: 0.9742 - auc_169: 0.9202 - precision_169: 0.7129 - recall_169: 0.2650 - val_loss: 0.2785 - val_binary_accuracy: 0.9743 - val_auc_169: 0.9269 - val_precision_169: 0.7099 - val_recall_169: 0.2764\n","Epoch 4/5\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0794 - binary_accuracy: 0.9747 - auc_169: 0.9284 - precision_169: 0.7150 - recall_169: 0.2901 - val_loss: 0.1727 - val_binary_accuracy: 0.9747 - val_auc_169: 0.9322 - val_precision_169: 0.7204 - val_recall_169: 0.2907\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0770 - binary_accuracy: 0.9751 - auc_169: 0.9343 - precision_169: 0.7190 - recall_169: 0.3087 - val_loss: 0.1072 - val_binary_accuracy: 0.9749 - val_auc_169: 0.9363 - val_precision_169: 0.7325 - val_recall_169: 0.2891\n","Score for fold 10: F1 score of 0.41462139674065307; loss of 0.10722034424543381; binary_accuracy of 97.49228358268738%\n","----------------------------------------------------------------------\n","The number of filters is  32\n","The size of the kernel is  256\n","Training for fold 1 ...\n","Epoch 1/5\n","98/98 [==============================] - 5s 26ms/step - loss: 0.1226 - binary_accuracy: 0.9630 - auc_170: 0.8102 - precision_170: 0.2934 - recall_170: 0.1465 - val_loss: 0.5080 - val_binary_accuracy: 0.9722 - val_auc_170: 0.8759 - val_precision_170: 0.7332 - val_recall_170: 0.1737\n","Epoch 2/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0891 - binary_accuracy: 0.9734 - auc_170: 0.8990 - precision_170: 0.7119 - recall_170: 0.2229 - val_loss: 0.3558 - val_binary_accuracy: 0.9730 - val_auc_170: 0.9133 - val_precision_170: 0.7541 - val_recall_170: 0.2022\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0828 - binary_accuracy: 0.9742 - auc_170: 0.9194 - precision_170: 0.7130 - recall_170: 0.2631 - val_loss: 0.2733 - val_binary_accuracy: 0.9738 - val_auc_170: 0.9262 - val_precision_170: 0.7370 - val_recall_170: 0.2492\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0794 - binary_accuracy: 0.9747 - auc_170: 0.9282 - precision_170: 0.7151 - recall_170: 0.2893 - val_loss: 0.1733 - val_binary_accuracy: 0.9743 - val_auc_170: 0.9326 - val_precision_170: 0.7387 - val_recall_170: 0.2721\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0771 - binary_accuracy: 0.9751 - auc_170: 0.9338 - precision_170: 0.7176 - recall_170: 0.3079 - val_loss: 0.1111 - val_binary_accuracy: 0.9746 - val_auc_170: 0.9361 - val_precision_170: 0.7220 - val_recall_170: 0.3017\n","Score for fold 1: F1 score of 0.42555734893951097; loss of 0.11105341464281082; binary_accuracy of 97.45851755142212%\n","Training for fold 2 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 20ms/step - loss: 0.1223 - binary_accuracy: 0.9624 - auc_171: 0.8139 - precision_171: 0.2890 - recall_171: 0.1548 - val_loss: 0.5193 - val_binary_accuracy: 0.9728 - val_auc_171: 0.8806 - val_precision_171: 0.7118 - val_recall_171: 0.1882\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0894 - binary_accuracy: 0.9734 - auc_171: 0.8982 - precision_171: 0.7123 - recall_171: 0.2222 - val_loss: 0.3861 - val_binary_accuracy: 0.9737 - val_auc_171: 0.9146 - val_precision_171: 0.7146 - val_recall_171: 0.2356\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0830 - binary_accuracy: 0.9741 - auc_171: 0.9194 - precision_171: 0.7132 - recall_171: 0.2621 - val_loss: 0.2612 - val_binary_accuracy: 0.9742 - val_auc_171: 0.9272 - val_precision_171: 0.7183 - val_recall_171: 0.2603\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0796 - binary_accuracy: 0.9746 - auc_171: 0.9283 - precision_171: 0.7148 - recall_171: 0.2879 - val_loss: 0.1842 - val_binary_accuracy: 0.9747 - val_auc_171: 0.9333 - val_precision_171: 0.6930 - val_recall_171: 0.3090\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0772 - binary_accuracy: 0.9750 - auc_171: 0.9340 - precision_171: 0.7178 - recall_171: 0.3073 - val_loss: 0.1327 - val_binary_accuracy: 0.9747 - val_auc_171: 0.9365 - val_precision_171: 0.6563 - val_recall_171: 0.3615\n","Score for fold 2: F1 score of 0.46617622430431505; loss of 0.1326635777950287; binary_accuracy of 97.46745228767395%\n","INFO:tensorflow:Assets written to: ./models/CNNMod1/best_MF_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./models/CNNMod1/best_MF_model/assets\n"]},{"name":"stdout","output_type":"stream","text":["Current best model for Molecular Function has 32 filters, with a kernel size of 256 and has an F1 score of 0.46617622430431505\n","Training for fold 3 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 18ms/step - loss: 0.1234 - binary_accuracy: 0.9622 - auc_172: 0.8100 - precision_172: 0.2813 - recall_172: 0.1496 - val_loss: 0.5001 - val_binary_accuracy: 0.9727 - val_auc_172: 0.8771 - val_precision_172: 0.7373 - val_recall_172: 0.1689\n","Epoch 2/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0895 - binary_accuracy: 0.9734 - auc_172: 0.8976 - precision_172: 0.7144 - recall_172: 0.2217 - val_loss: 0.3792 - val_binary_accuracy: 0.9737 - val_auc_172: 0.9137 - val_precision_172: 0.7372 - val_recall_172: 0.2198\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0831 - binary_accuracy: 0.9741 - auc_172: 0.9188 - precision_172: 0.7128 - recall_172: 0.2631 - val_loss: 0.2678 - val_binary_accuracy: 0.9742 - val_auc_172: 0.9254 - val_precision_172: 0.7106 - val_recall_172: 0.2698\n","Epoch 4/5\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0796 - binary_accuracy: 0.9746 - auc_172: 0.9278 - precision_172: 0.7163 - recall_172: 0.2878 - val_loss: 0.1749 - val_binary_accuracy: 0.9746 - val_auc_172: 0.9323 - val_precision_172: 0.7123 - val_recall_172: 0.2896\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0773 - binary_accuracy: 0.9750 - auc_172: 0.9335 - precision_172: 0.7180 - recall_172: 0.3077 - val_loss: 0.1120 - val_binary_accuracy: 0.9748 - val_auc_172: 0.9357 - val_precision_172: 0.7191 - val_recall_172: 0.2947\n","Score for fold 3: F1 score of 0.41804022772771965; loss of 0.11204986274242401; binary_accuracy of 97.48305678367615%\n","Training for fold 4 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 21ms/step - loss: 0.1221 - binary_accuracy: 0.9630 - auc_173: 0.8117 - precision_173: 0.2985 - recall_173: 0.1527 - val_loss: 0.5162 - val_binary_accuracy: 0.9730 - val_auc_173: 0.8812 - val_precision_173: 0.7174 - val_recall_173: 0.1919\n","Epoch 2/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0889 - binary_accuracy: 0.9734 - auc_173: 0.9004 - precision_173: 0.7113 - recall_173: 0.2252 - val_loss: 0.3859 - val_binary_accuracy: 0.9738 - val_auc_173: 0.9155 - val_precision_173: 0.7152 - val_recall_173: 0.2349\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0828 - binary_accuracy: 0.9742 - auc_173: 0.9200 - precision_173: 0.7149 - recall_173: 0.2634 - val_loss: 0.2770 - val_binary_accuracy: 0.9746 - val_auc_173: 0.9280 - val_precision_173: 0.7180 - val_recall_173: 0.2756\n","Epoch 4/5\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0794 - binary_accuracy: 0.9747 - auc_173: 0.9287 - precision_173: 0.7155 - recall_173: 0.2905 - val_loss: 0.1672 - val_binary_accuracy: 0.9747 - val_auc_173: 0.9334 - val_precision_173: 0.7473 - val_recall_173: 0.2586\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0771 - binary_accuracy: 0.9751 - auc_173: 0.9340 - precision_173: 0.7180 - recall_173: 0.3092 - val_loss: 0.1117 - val_binary_accuracy: 0.9751 - val_auc_173: 0.9378 - val_precision_173: 0.7313 - val_recall_173: 0.2927\n","Score for fold 4: F1 score of 0.41806099473830777; loss of 0.11167678982019424; binary_accuracy of 97.51399755477905%\n","Training for fold 5 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1229 - binary_accuracy: 0.9626 - auc_174: 0.8108 - precision_174: 0.2905 - recall_174: 0.1515 - val_loss: 0.5098 - val_binary_accuracy: 0.9727 - val_auc_174: 0.8814 - val_precision_174: 0.7251 - val_recall_174: 0.1792\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0889 - binary_accuracy: 0.9734 - auc_174: 0.9006 - precision_174: 0.7125 - recall_174: 0.2225 - val_loss: 0.3780 - val_binary_accuracy: 0.9735 - val_auc_174: 0.9139 - val_precision_174: 0.7211 - val_recall_174: 0.2261\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0831 - binary_accuracy: 0.9741 - auc_174: 0.9189 - precision_174: 0.7139 - recall_174: 0.2599 - val_loss: 0.2827 - val_binary_accuracy: 0.9742 - val_auc_174: 0.9259 - val_precision_174: 0.6956 - val_recall_174: 0.2842\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0799 - binary_accuracy: 0.9746 - auc_174: 0.9275 - precision_174: 0.7142 - recall_174: 0.2859 - val_loss: 0.1777 - val_binary_accuracy: 0.9745 - val_auc_174: 0.9323 - val_precision_174: 0.7292 - val_recall_174: 0.2720\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0774 - binary_accuracy: 0.9750 - auc_174: 0.9334 - precision_174: 0.7182 - recall_174: 0.3042 - val_loss: 0.1144 - val_binary_accuracy: 0.9749 - val_auc_174: 0.9358 - val_precision_174: 0.7150 - val_recall_174: 0.3076\n","Score for fold 5: F1 score of 0.4301380783972557; loss of 0.11439398676156998; binary_accuracy of 97.49478697776794%\n","Training for fold 6 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1211 - binary_accuracy: 0.9627 - auc_175: 0.8169 - precision_175: 0.2973 - recall_175: 0.1595 - val_loss: 0.5119 - val_binary_accuracy: 0.9724 - val_auc_175: 0.8867 - val_precision_175: 0.7044 - val_recall_175: 0.2076\n","Epoch 2/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0879 - binary_accuracy: 0.9735 - auc_175: 0.9032 - precision_175: 0.7110 - recall_175: 0.2281 - val_loss: 0.3800 - val_binary_accuracy: 0.9732 - val_auc_175: 0.9149 - val_precision_175: 0.7359 - val_recall_175: 0.2267\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0823 - binary_accuracy: 0.9743 - auc_175: 0.9207 - precision_175: 0.7154 - recall_175: 0.2653 - val_loss: 0.2663 - val_binary_accuracy: 0.9737 - val_auc_175: 0.9252 - val_precision_175: 0.7406 - val_recall_175: 0.2476\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0793 - binary_accuracy: 0.9747 - auc_175: 0.9284 - precision_175: 0.7142 - recall_175: 0.2892 - val_loss: 0.1818 - val_binary_accuracy: 0.9743 - val_auc_175: 0.9313 - val_precision_175: 0.7331 - val_recall_175: 0.2822\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0767 - binary_accuracy: 0.9752 - auc_175: 0.9346 - precision_175: 0.7190 - recall_175: 0.3092 - val_loss: 0.1111 - val_binary_accuracy: 0.9744 - val_auc_175: 0.9358 - val_precision_175: 0.7482 - val_recall_175: 0.2776\n","Score for fold 6: F1 score of 0.40492416815572124; loss of 0.11110765486955643; binary_accuracy of 97.44270443916321%\n","Training for fold 7 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1231 - binary_accuracy: 0.9620 - auc_176: 0.8125 - precision_176: 0.2833 - recall_176: 0.1546 - val_loss: 0.5106 - val_binary_accuracy: 0.9732 - val_auc_176: 0.8833 - val_precision_176: 0.7058 - val_recall_176: 0.1937\n","Epoch 2/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0894 - binary_accuracy: 0.9733 - auc_176: 0.8996 - precision_176: 0.7090 - recall_176: 0.2218 - val_loss: 0.3846 - val_binary_accuracy: 0.9740 - val_auc_176: 0.9124 - val_precision_176: 0.7169 - val_recall_176: 0.2286\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0838 - binary_accuracy: 0.9740 - auc_176: 0.9171 - precision_176: 0.7145 - recall_176: 0.2577 - val_loss: 0.2679 - val_binary_accuracy: 0.9744 - val_auc_176: 0.9245 - val_precision_176: 0.7472 - val_recall_176: 0.2280\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0806 - binary_accuracy: 0.9745 - auc_176: 0.9258 - precision_176: 0.7138 - recall_176: 0.2831 - val_loss: 0.1889 - val_binary_accuracy: 0.9750 - val_auc_176: 0.9312 - val_precision_176: 0.7017 - val_recall_176: 0.2973\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0780 - binary_accuracy: 0.9749 - auc_176: 0.9322 - precision_176: 0.7189 - recall_176: 0.3021 - val_loss: 0.1273 - val_binary_accuracy: 0.9749 - val_auc_176: 0.9359 - val_precision_176: 0.6599 - val_recall_176: 0.3462\n","Score for fold 7: F1 score of 0.4540934596977764; loss of 0.1273464560508728; binary_accuracy of 97.48726487159729%\n","Training for fold 8 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1234 - binary_accuracy: 0.9621 - auc_177: 0.8098 - precision_177: 0.2799 - recall_177: 0.1501 - val_loss: 0.5142 - val_binary_accuracy: 0.9727 - val_auc_177: 0.8725 - val_precision_177: 0.7229 - val_recall_177: 0.1788\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0905 - binary_accuracy: 0.9733 - auc_177: 0.8940 - precision_177: 0.7127 - recall_177: 0.2156 - val_loss: 0.3670 - val_binary_accuracy: 0.9736 - val_auc_177: 0.9093 - val_precision_177: 0.7459 - val_recall_177: 0.2081\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0841 - binary_accuracy: 0.9740 - auc_177: 0.9157 - precision_177: 0.7105 - recall_177: 0.2563 - val_loss: 0.2776 - val_binary_accuracy: 0.9742 - val_auc_177: 0.9238 - val_precision_177: 0.7155 - val_recall_177: 0.2621\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0802 - binary_accuracy: 0.9745 - auc_177: 0.9267 - precision_177: 0.7142 - recall_177: 0.2834 - val_loss: 0.1782 - val_binary_accuracy: 0.9747 - val_auc_177: 0.9306 - val_precision_177: 0.7271 - val_recall_177: 0.2768\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0779 - binary_accuracy: 0.9749 - auc_177: 0.9322 - precision_177: 0.7164 - recall_177: 0.3030 - val_loss: 0.1162 - val_binary_accuracy: 0.9749 - val_auc_177: 0.9352 - val_precision_177: 0.7030 - val_recall_177: 0.3139\n","Score for fold 8: F1 score of 0.4340460363551878; loss of 0.11622846126556396; binary_accuracy of 97.4914014339447%\n","Training for fold 9 ...\n","Epoch 1/5\n","98/98 [==============================] - 4s 25ms/step - loss: 0.1220 - binary_accuracy: 0.9628 - auc_178: 0.8133 - precision_178: 0.2987 - recall_178: 0.1550 - val_loss: 0.5137 - val_binary_accuracy: 0.9731 - val_auc_178: 0.8816 - val_precision_178: 0.7271 - val_recall_178: 0.1783\n","Epoch 2/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0893 - binary_accuracy: 0.9733 - auc_178: 0.8992 - precision_178: 0.7114 - recall_178: 0.2224 - val_loss: 0.3651 - val_binary_accuracy: 0.9738 - val_auc_178: 0.9127 - val_precision_178: 0.7461 - val_recall_178: 0.2004\n","Epoch 3/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0832 - binary_accuracy: 0.9741 - auc_178: 0.9188 - precision_178: 0.7128 - recall_178: 0.2621 - val_loss: 0.2834 - val_binary_accuracy: 0.9747 - val_auc_178: 0.9267 - val_precision_178: 0.7008 - val_recall_178: 0.2824\n","Epoch 4/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0796 - binary_accuracy: 0.9746 - auc_178: 0.9283 - precision_178: 0.7151 - recall_178: 0.2888 - val_loss: 0.2000 - val_binary_accuracy: 0.9747 - val_auc_178: 0.9324 - val_precision_178: 0.6656 - val_recall_178: 0.3270\n","Epoch 5/5\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0774 - binary_accuracy: 0.9750 - auc_178: 0.9335 - precision_178: 0.7164 - recall_178: 0.3087 - val_loss: 0.1123 - val_binary_accuracy: 0.9752 - val_auc_178: 0.9362 - val_precision_178: 0.7111 - val_recall_178: 0.3044\n","Score for fold 9: F1 score of 0.42630290501878765; loss of 0.11228518187999725; binary_accuracy of 97.5240409374237%\n","Training for fold 10 ...\n","Epoch 1/5\n","98/98 [==============================] - 3s 17ms/step - loss: 0.1224 - binary_accuracy: 0.9626 - auc_179: 0.8122 - precision_179: 0.2889 - recall_179: 0.1493 - val_loss: 0.5088 - val_binary_accuracy: 0.9726 - val_auc_179: 0.8822 - val_precision_179: 0.7262 - val_recall_179: 0.1762\n","Epoch 2/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0885 - binary_accuracy: 0.9735 - auc_179: 0.9020 - precision_179: 0.7110 - recall_179: 0.2269 - val_loss: 0.3649 - val_binary_accuracy: 0.9735 - val_auc_179: 0.9159 - val_precision_179: 0.7396 - val_recall_179: 0.2140\n","Epoch 3/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0828 - binary_accuracy: 0.9742 - auc_179: 0.9194 - precision_179: 0.7129 - recall_179: 0.2646 - val_loss: 0.2757 - val_binary_accuracy: 0.9742 - val_auc_179: 0.9268 - val_precision_179: 0.7489 - val_recall_179: 0.2402\n","Epoch 4/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0795 - binary_accuracy: 0.9746 - auc_179: 0.9285 - precision_179: 0.7163 - recall_179: 0.2875 - val_loss: 0.1784 - val_binary_accuracy: 0.9746 - val_auc_179: 0.9327 - val_precision_179: 0.6986 - val_recall_179: 0.3042\n","Epoch 5/5\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0771 - binary_accuracy: 0.9751 - auc_179: 0.9342 - precision_179: 0.7188 - recall_179: 0.3076 - val_loss: 0.1130 - val_binary_accuracy: 0.9749 - val_auc_179: 0.9365 - val_precision_179: 0.7175 - val_recall_179: 0.3025\n","Score for fold 10: F1 score of 0.42555801203836907; loss of 0.1129915714263916; binary_accuracy of 97.48945236206055%\n"]}],"source":["for dataset in train_data_dict:\n","  dataset_name = dataset\n","  data = train_data_dict[dataset]\n","  model1_training(dataset_name, data)"]},{"cell_type":"markdown","metadata":{"id":"ivDJswKpFM9A"},"source":["## Model 2 Architecture: CNN with LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPRk3Ferc2fr"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNbcfO+ZO4YZwXnzQOmKuDh","gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
