{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyP6bDrYFgL/WiV5V+sI+Yby"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Feed-forward Neural Networks\n","\n","This note book will be used to test Feed-forward neural networks on each of the 3 ontologies."],"metadata":{"id":"rrM-gFkvkbOx"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"INY5-pvaEKak","executionInfo":{"status":"ok","timestamp":1708292955436,"user_tz":-60,"elapsed":5107,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import f1_score\n","import itertools\n","import pprint"]},{"cell_type":"code","source":["print(\"TensorFlow v\" + tf.__version__)\n","print(\"Numpy v\" + np.__version__)"],"metadata":{"id":"FQzydhXnRN-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708292955437,"user_tz":-60,"elapsed":8,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}},"outputId":"b51a5ee4-2d55-4eb9-c1f2-57b390b932ad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow v2.15.0\n","Numpy v1.25.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"EHNRK5u9RRIt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708293019816,"user_tz":-60,"elapsed":64384,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}},"outputId":"ff04495c-86c4-4079-b385-1b184c03e7fd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["#%%capture\n","!unzip '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data.zip'"],"metadata":{"id":"Dz1LtwZFRRzw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708293042156,"user_tz":-60,"elapsed":22351,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}},"outputId":"2750c01c-384d-4332-f1df-86caa96d5b07"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data.zip\n","  inflating: bio_data/75percent_train_embeddings_BiologicalProcesses.pkl  \n","  inflating: bio_data/75percent_train_labels_BiologicalProcesses.pkl  \n","  inflating: bio_data/train_embeddings_CellularComponent.pkl  \n","  inflating: bio_data/train_embeddings_MolecularFunction.pkl  \n","  inflating: bio_data/train_labels_CellularComponent.pkl  \n","  inflating: bio_data/train_labels_MolecularFunction.pkl  \n"]}]},{"cell_type":"code","source":["BP_train_df = pd.read_pickle('/content/bio_data/75percent_train_embeddings_BiologicalProcesses.pkl')\n","CC_train_df = pd.read_pickle('/content/bio_data/train_embeddings_CellularComponent.pkl')\n","MF_train_df = pd.read_pickle('/content/bio_data/train_embeddings_MolecularFunction.pkl')"],"metadata":{"id":"EgQNBoLEFwNF","executionInfo":{"status":"ok","timestamp":1708293042698,"user_tz":-60,"elapsed":551,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["BP_label_df = pd.read_pickle('/content/bio_data/75percent_train_labels_BiologicalProcesses.pkl')\n","CC_label_df = pd.read_pickle('/content/bio_data/train_labels_CellularComponent.pkl')\n","MF_label_df = pd.read_pickle('/content/bio_data/train_labels_MolecularFunction.pkl')"],"metadata":{"id":"LQQzfrFeYosg","executionInfo":{"status":"ok","timestamp":1708293044719,"user_tz":-60,"elapsed":2023,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_data_dict = {'Biological Processes': [BP_train_df, BP_label_df],\n","                   'Cellular Component': [CC_train_df, CC_label_df],\n","                   'Molecular Function': [MF_train_df, MF_label_df]\n","}"],"metadata":{"id":"fN_1hLZRq1JW","executionInfo":{"status":"ok","timestamp":1708293044720,"user_tz":-60,"elapsed":12,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OdUudkyKj3ID","executionInfo":{"status":"ok","timestamp":1708293044720,"user_tz":-60,"elapsed":10,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"outputs":[],"source":["num_labels = 1500\n","num_folds = 10"]},{"cell_type":"markdown","source":["## Model 1 Architecture: All Dense layers of the same size"],"metadata":{"id":"NApU98ealM6R"}},{"cell_type":"code","source":["BATCH_SIZE = 256"],"metadata":{"id":"62fohGyUlVrU","executionInfo":{"status":"ok","timestamp":1708293044720,"user_tz":-60,"elapsed":10,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def model1_training(dataset_name, data):\n","  train = data[0]\n","  label = data[1]\n","\n","  INPUT_SHAPE = [train.shape[1]]\n","\n","  best_f1 = 0\n","  print('=======================================================================')\n","  print(f'Training for {dataset_name}')\n","\n","  for unit_param, act_param in itertools.product([512, 256, 128], ['relu', 'tanh']):\n","    print('----------------------------------------------------------------------')\n","    print('The number of units in each layer is ', unit_param)\n","    print('The activation function in each layer is ', act_param)\n","\n","    kfold = KFold(n_splits=num_folds, shuffle=True)\n","    fold_no = 1\n","\n","    for train_fold, test_fold in kfold.split(train, label):\n","\n","      model1 = tf.keras.Sequential([\n","          tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),\n","          tf.keras.layers.Dense(units = unit_param, activation = act_param),\n","          tf.keras.layers.Dense(units = unit_param, activation = act_param),\n","          tf.keras.layers.Dense(units = unit_param, activation = act_param),\n","          tf.keras.layers.Dense(units = num_labels, activation = 'sigmoid')\n","          ])\n","\n","      # Compile model\n","      model1.compile(\n","          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","          loss='binary_crossentropy',\n","          metrics=['binary_accuracy',\n","                  tf.keras.metrics.AUC(),\n","                  tf.keras.metrics.Precision(),\n","                  tf.keras.metrics.Recall(),\n","                  ] # tf.keras.metrics.F1Score() not appropriate as it is calculated batchwise\n","          )\n","\n","      print(f'Training for fold {fold_no} ...')\n","\n","      # Fit the data to the model\n","      history = model1.fit(\n","          train, label,\n","          batch_size=BATCH_SIZE,\n","          epochs=5\n","          )\n","\n","      # Generate metrics\n","      scores = model1.evaluate(train, label, verbose=0)\n","      precision = scores[3]\n","      recall = scores[4]\n","      F1_score = 2*precision*recall / (precision + recall)\n","      print(f'Score for fold {fold_no}: F1 score of {F1_score}; {model1.metrics_names[0]} of {scores[0]}; {model1.metrics_names[1]} of {scores[1]*100}%')\n","\n","      if F1_score > best_f1:\n","        best_f1 = F1_score\n","        if dataset_name == 'Biological Processes':\n","          tf.keras.models.save_model(\n","              model1,\n","              '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data/FFNNMod1/best_BP_model',\n","          )\n","          print(f'Current best model for Biological Processes has {unit_param} units in each layer, uses {act_param} activation function and has an F1 score of {F1_score}')\n","\n","        elif dataset_name == 'Molecular Function':\n","          tf.keras.models.save_model(\n","              model1,\n","              '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data/FFNNMod1/best_MF_model',\n","          )\n","          print(f'Current best model for Molecular Function has {unit_param} units in each layer, uses {act_param} activation function and has an F1 score of {F1_score}')\n","\n","        else:\n","          tf.keras.models.save_model(\n","              model1,\n","              '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data/FFNNMod1/best_CC_model',\n","          )\n","          print(f'Current best model for Cellular Component has {unit_param} units in each layer, uses {act_param} activation function and has an F1 score of {F1_score}')\n","\n","      fold_no += 1"],"metadata":{"id":"dkj2GTgvrg7S","executionInfo":{"status":"ok","timestamp":1708293044720,"user_tz":-60,"elapsed":9,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for dataset in train_data_dict:\n","  dataset_name = dataset\n","  data = train_data_dict[dataset]\n","  model1_training(dataset_name, data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yMgob7Ir4dh","outputId":"b435f1a3-78b8-4aaa-9a4c-e6752f0c014c","executionInfo":{"status":"ok","timestamp":1708302755490,"user_tz":-60,"elapsed":9710779,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================================================================\n","Training for Biological Processes\n","----------------------------------------------------------------------\n","The number of units in each layer is  512\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 33ms/step - loss: 0.1028 - binary_accuracy: 0.9698 - auc: 0.8591 - precision: 0.4234 - recall: 0.1660\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0788 - binary_accuracy: 0.9750 - auc: 0.9226 - precision: 0.6766 - recall: 0.2355\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc: 0.9318 - precision: 0.6828 - recall: 0.2649\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0729 - binary_accuracy: 0.9760 - auc: 0.9374 - precision: 0.6895 - recall: 0.2865\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0707 - binary_accuracy: 0.9764 - auc: 0.9421 - precision: 0.6973 - recall: 0.3065\n","Score for fold 1: F1 score of 0.4687332350606924; loss of 0.06806392222642899; binary_accuracy of 97.70029783248901%\n","Current best model for Biological Processes has 512 units in each layer, uses relu activation function and has an F1 score of 0.4687332350606924\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1025 - binary_accuracy: 0.9697 - auc_1: 0.8607 - precision_1: 0.4221 - recall_1: 0.1675\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0786 - binary_accuracy: 0.9750 - auc_1: 0.9229 - precision_1: 0.6771 - recall_1: 0.2367\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0751 - binary_accuracy: 0.9756 - auc_1: 0.9321 - precision_1: 0.6837 - recall_1: 0.2666\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_1: 0.9379 - precision_1: 0.6905 - recall_1: 0.2883\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0705 - binary_accuracy: 0.9764 - auc_1: 0.9425 - precision_1: 0.6976 - recall_1: 0.3080\n","Score for fold 2: F1 score of 0.4383225108478719; loss of 0.0681770071387291; binary_accuracy of 97.69333004951477%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1026 - binary_accuracy: 0.9696 - auc_2: 0.8606 - precision_2: 0.4205 - recall_2: 0.1697\n","Epoch 2/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_2: 0.9227 - precision_2: 0.6769 - recall_2: 0.2367\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_2: 0.9321 - precision_2: 0.6828 - recall_2: 0.2660\n","Epoch 4/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_2: 0.9379 - precision_2: 0.6902 - recall_2: 0.2886\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0706 - binary_accuracy: 0.9764 - auc_2: 0.9423 - precision_2: 0.6970 - recall_2: 0.3077\n","Score for fold 3: F1 score of 0.4424663807824361; loss of 0.06769152730703354; binary_accuracy of 97.70452380180359%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1031 - binary_accuracy: 0.9696 - auc_3: 0.8585 - precision_3: 0.4160 - recall_3: 0.1655\n","Epoch 2/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_3: 0.9229 - precision_3: 0.6766 - recall_3: 0.2363\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_3: 0.9322 - precision_3: 0.6831 - recall_3: 0.2658\n","Epoch 4/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_3: 0.9378 - precision_3: 0.6907 - recall_3: 0.2875\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0706 - binary_accuracy: 0.9764 - auc_3: 0.9423 - precision_3: 0.6970 - recall_3: 0.3068\n","Score for fold 4: F1 score of 0.43073955152469007; loss of 0.06767462193965912; binary_accuracy of 97.69535660743713%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1023 - binary_accuracy: 0.9697 - auc_4: 0.8610 - precision_4: 0.4226 - recall_4: 0.1675\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_4: 0.9228 - precision_4: 0.6765 - recall_4: 0.2358\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc_4: 0.9321 - precision_4: 0.6839 - recall_4: 0.2646\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_4: 0.9378 - precision_4: 0.6904 - recall_4: 0.2882\n","Epoch 5/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0706 - binary_accuracy: 0.9764 - auc_4: 0.9421 - precision_4: 0.6973 - recall_4: 0.3077\n","Score for fold 5: F1 score of 0.4462182807080199; loss of 0.0676453560590744; binary_accuracy of 97.7098822593689%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 31ms/step - loss: 0.1027 - binary_accuracy: 0.9695 - auc_5: 0.8604 - precision_5: 0.4150 - recall_5: 0.1671\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_5: 0.9228 - precision_5: 0.6767 - recall_5: 0.2370\n","Epoch 3/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc_5: 0.9319 - precision_5: 0.6833 - recall_5: 0.2658\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_5: 0.9379 - precision_5: 0.6908 - recall_5: 0.2887\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0704 - binary_accuracy: 0.9765 - auc_5: 0.9427 - precision_5: 0.6986 - recall_5: 0.3086\n","Score for fold 6: F1 score of 0.4496712028641977; loss of 0.06762971729040146; binary_accuracy of 97.70951271057129%\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 31ms/step - loss: 0.1022 - binary_accuracy: 0.9698 - auc_6: 0.8608 - precision_6: 0.4252 - recall_6: 0.1684\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0787 - binary_accuracy: 0.9750 - auc_6: 0.9227 - precision_6: 0.6769 - recall_6: 0.2375\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc_6: 0.9320 - precision_6: 0.6829 - recall_6: 0.2656\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_6: 0.9377 - precision_6: 0.6901 - recall_6: 0.2878\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0705 - binary_accuracy: 0.9765 - auc_6: 0.9424 - precision_6: 0.6978 - recall_6: 0.3085\n","Score for fold 7: F1 score of 0.446423372030615; loss of 0.06782334297895432; binary_accuracy of 97.70745635032654%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 31ms/step - loss: 0.1033 - binary_accuracy: 0.9695 - auc_7: 0.8589 - precision_7: 0.4148 - recall_7: 0.1666\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0789 - binary_accuracy: 0.9750 - auc_7: 0.9222 - precision_7: 0.6774 - recall_7: 0.2349\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0753 - binary_accuracy: 0.9755 - auc_7: 0.9317 - precision_7: 0.6828 - recall_7: 0.2642\n","Epoch 4/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0728 - binary_accuracy: 0.9760 - auc_7: 0.9375 - precision_7: 0.6894 - recall_7: 0.2869\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0706 - binary_accuracy: 0.9764 - auc_7: 0.9422 - precision_7: 0.6974 - recall_7: 0.3064\n","Score for fold 8: F1 score of 0.4485306366841345; loss of 0.06778261065483093; binary_accuracy of 97.70308136940002%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 32ms/step - loss: 0.1031 - binary_accuracy: 0.9695 - auc_8: 0.8589 - precision_8: 0.4154 - recall_8: 0.1658\n","Epoch 2/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0788 - binary_accuracy: 0.9750 - auc_8: 0.9225 - precision_8: 0.6751 - recall_8: 0.2359\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0754 - binary_accuracy: 0.9755 - auc_8: 0.9315 - precision_8: 0.6828 - recall_8: 0.2644\n","Epoch 4/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0728 - binary_accuracy: 0.9760 - auc_8: 0.9375 - precision_8: 0.6897 - recall_8: 0.2866\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0707 - binary_accuracy: 0.9764 - auc_8: 0.9420 - precision_8: 0.6962 - recall_8: 0.3061\n","Score for fold 9: F1 score of 0.4204574650241395; loss of 0.06811127066612244; binary_accuracy of 97.68357872962952%\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1025 - binary_accuracy: 0.9696 - auc_9: 0.8612 - precision_9: 0.4176 - recall_9: 0.1690\n","Epoch 2/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0786 - binary_accuracy: 0.9750 - auc_9: 0.9230 - precision_9: 0.6769 - recall_9: 0.2380\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_9: 0.9321 - precision_9: 0.6831 - recall_9: 0.2665\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_9: 0.9378 - precision_9: 0.6908 - recall_9: 0.2882\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0705 - binary_accuracy: 0.9764 - auc_9: 0.9424 - precision_9: 0.6974 - recall_9: 0.3086\n","Score for fold 10: F1 score of 0.46233703805349; loss of 0.06771817058324814; binary_accuracy of 97.69899249076843%\n","----------------------------------------------------------------------\n","The number of units in each layer is  512\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 33ms/step - loss: 0.1197 - binary_accuracy: 0.9578 - auc_10: 0.8436 - precision_10: 0.2092 - recall_10: 0.1727\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0811 - binary_accuracy: 0.9746 - auc_10: 0.9168 - precision_10: 0.6735 - recall_10: 0.2134\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0778 - binary_accuracy: 0.9750 - auc_10: 0.9259 - precision_10: 0.6781 - recall_10: 0.2392\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0755 - binary_accuracy: 0.9754 - auc_10: 0.9315 - precision_10: 0.6823 - recall_10: 0.2603\n","Epoch 5/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0738 - binary_accuracy: 0.9758 - auc_10: 0.9355 - precision_10: 0.6865 - recall_10: 0.2772\n","Score for fold 1: F1 score of 0.41435706370395453; loss of 0.07172391563653946; binary_accuracy of 97.62027263641357%\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 33ms/step - loss: 0.1189 - binary_accuracy: 0.9584 - auc_11: 0.8453 - precision_11: 0.2119 - recall_11: 0.1685\n","Epoch 2/5\n","244/244 [==============================] - 8s 34ms/step - loss: 0.0814 - binary_accuracy: 0.9745 - auc_11: 0.9159 - precision_11: 0.6722 - recall_11: 0.2104\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0780 - binary_accuracy: 0.9750 - auc_11: 0.9253 - precision_11: 0.6771 - recall_11: 0.2386\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0757 - binary_accuracy: 0.9754 - auc_11: 0.9310 - precision_11: 0.6837 - recall_11: 0.2587\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0738 - binary_accuracy: 0.9758 - auc_11: 0.9354 - precision_11: 0.6871 - recall_11: 0.2763\n","Score for fold 2: F1 score of 0.3860827040074961; loss of 0.07190167903900146; binary_accuracy of 97.61155843734741%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 31ms/step - loss: 0.1192 - binary_accuracy: 0.9579 - auc_12: 0.8482 - precision_12: 0.2091 - recall_12: 0.1715\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0807 - binary_accuracy: 0.9746 - auc_12: 0.9178 - precision_12: 0.6741 - recall_12: 0.2156\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0775 - binary_accuracy: 0.9751 - auc_12: 0.9267 - precision_12: 0.6782 - recall_12: 0.2418\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0754 - binary_accuracy: 0.9755 - auc_12: 0.9319 - precision_12: 0.6831 - recall_12: 0.2617\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0776 - binary_accuracy: 0.9748 - auc_12: 0.9290 - precision_12: 0.6513 - recall_12: 0.2549\n","Score for fold 3: F1 score of 0.3841002366974632; loss of 0.07516442239284515; binary_accuracy of 97.54834175109863%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 31ms/step - loss: 0.1195 - binary_accuracy: 0.9578 - auc_13: 0.8482 - precision_13: 0.2088 - recall_13: 0.1723\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0810 - binary_accuracy: 0.9746 - auc_13: 0.9171 - precision_13: 0.6736 - recall_13: 0.2135\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0777 - binary_accuracy: 0.9751 - auc_13: 0.9261 - precision_13: 0.6798 - recall_13: 0.2407\n","Epoch 4/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0755 - binary_accuracy: 0.9755 - auc_13: 0.9315 - precision_13: 0.6838 - recall_13: 0.2612\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0738 - binary_accuracy: 0.9757 - auc_13: 0.9354 - precision_13: 0.6855 - recall_13: 0.2768\n","Score for fold 4: F1 score of 0.40207456531085084; loss of 0.07189636677503586; binary_accuracy of 97.61656522750854%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1200 - binary_accuracy: 0.9577 - auc_14: 0.8433 - precision_14: 0.2071 - recall_14: 0.1707\n","Epoch 2/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0814 - binary_accuracy: 0.9745 - auc_14: 0.9159 - precision_14: 0.6726 - recall_14: 0.2105\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0781 - binary_accuracy: 0.9750 - auc_14: 0.9251 - precision_14: 0.6785 - recall_14: 0.2371\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0790 - binary_accuracy: 0.9745 - auc_14: 0.9253 - precision_14: 0.6449 - recall_14: 0.2404\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0754 - binary_accuracy: 0.9755 - auc_14: 0.9318 - precision_14: 0.6818 - recall_14: 0.2622\n","Score for fold 5: F1 score of 0.3901193018212332; loss of 0.07339908927679062; binary_accuracy of 97.58326411247253%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 33ms/step - loss: 0.1192 - binary_accuracy: 0.9579 - auc_15: 0.8470 - precision_15: 0.2110 - recall_15: 0.1739\n","Epoch 2/5\n","244/244 [==============================] - 8s 31ms/step - loss: 0.0810 - binary_accuracy: 0.9746 - auc_15: 0.9172 - precision_15: 0.6717 - recall_15: 0.2139\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0777 - binary_accuracy: 0.9751 - auc_15: 0.9261 - precision_15: 0.6780 - recall_15: 0.2414\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0754 - binary_accuracy: 0.9754 - auc_15: 0.9317 - precision_15: 0.6822 - recall_15: 0.2608\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0766 - binary_accuracy: 0.9751 - auc_15: 0.9312 - precision_15: 0.6579 - recall_15: 0.2621\n","Score for fold 6: F1 score of 0.3560717258525723; loss of 0.07442225515842438; binary_accuracy of 97.55138158798218%\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 33ms/step - loss: 0.1202 - binary_accuracy: 0.9577 - auc_16: 0.8429 - precision_16: 0.2034 - recall_16: 0.1649\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0815 - binary_accuracy: 0.9745 - auc_16: 0.9155 - precision_16: 0.6743 - recall_16: 0.2092\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0782 - binary_accuracy: 0.9750 - auc_16: 0.9248 - precision_16: 0.6768 - recall_16: 0.2361\n","Epoch 4/5\n","244/244 [==============================] - 8s 34ms/step - loss: 0.0759 - binary_accuracy: 0.9754 - auc_16: 0.9306 - precision_16: 0.6826 - recall_16: 0.2572\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0740 - binary_accuracy: 0.9757 - auc_16: 0.9349 - precision_16: 0.6873 - recall_16: 0.2741\n","Score for fold 7: F1 score of 0.4123702353717269; loss of 0.07185284048318863; binary_accuracy of 97.62117266654968%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 11s 32ms/step - loss: 0.1208 - binary_accuracy: 0.9576 - auc_17: 0.8419 - precision_17: 0.2036 - recall_17: 0.1672\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0817 - binary_accuracy: 0.9745 - auc_17: 0.9152 - precision_17: 0.6729 - recall_17: 0.2078\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_17: 0.9244 - precision_17: 0.6770 - recall_17: 0.2347\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0760 - binary_accuracy: 0.9754 - auc_17: 0.9303 - precision_17: 0.6828 - recall_17: 0.2547\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0742 - binary_accuracy: 0.9757 - auc_17: 0.9345 - precision_17: 0.6872 - recall_17: 0.2722\n","Score for fold 8: F1 score of 0.39648597735050506; loss of 0.0723629966378212; binary_accuracy of 97.60302901268005%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1192 - binary_accuracy: 0.9582 - auc_18: 0.8455 - precision_18: 0.2113 - recall_18: 0.1702\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0813 - binary_accuracy: 0.9746 - auc_18: 0.9164 - precision_18: 0.6716 - recall_18: 0.2123\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_18: 0.9256 - precision_18: 0.6791 - recall_18: 0.2394\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0787 - binary_accuracy: 0.9746 - auc_18: 0.9273 - precision_18: 0.6406 - recall_18: 0.2498\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0767 - binary_accuracy: 0.9752 - auc_18: 0.9289 - precision_18: 0.6743 - recall_18: 0.2514\n","Score for fold 9: F1 score of 0.39776295795888633; loss of 0.0744505375623703; binary_accuracy of 97.557532787323%\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1202 - binary_accuracy: 0.9576 - auc_19: 0.8417 - precision_19: 0.2020 - recall_19: 0.1643\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0816 - binary_accuracy: 0.9745 - auc_19: 0.9155 - precision_19: 0.6730 - recall_19: 0.2088\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0782 - binary_accuracy: 0.9750 - auc_19: 0.9248 - precision_19: 0.6778 - recall_19: 0.2363\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0759 - binary_accuracy: 0.9754 - auc_19: 0.9305 - precision_19: 0.6834 - recall_19: 0.2562\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0741 - binary_accuracy: 0.9757 - auc_19: 0.9347 - precision_19: 0.6873 - recall_19: 0.2736\n","Score for fold 10: F1 score of 0.4110752264609805; loss of 0.07204817980527878; binary_accuracy of 97.61279821395874%\n","----------------------------------------------------------------------\n","The number of units in each layer is  256\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1096 - binary_accuracy: 0.9677 - auc_20: 0.8466 - precision_20: 0.3524 - recall_20: 0.1560\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0802 - binary_accuracy: 0.9748 - auc_20: 0.9189 - precision_20: 0.6755 - recall_20: 0.2227\n","Epoch 3/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_20: 0.9286 - precision_20: 0.6827 - recall_20: 0.2504\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0744 - binary_accuracy: 0.9756 - auc_20: 0.9339 - precision_20: 0.6863 - recall_20: 0.2694\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_20: 0.9381 - precision_20: 0.6923 - recall_20: 0.2860\n","Score for fold 1: F1 score of 0.4428850101804573; loss of 0.07086608558893204; binary_accuracy of 97.63509631156921%\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1097 - binary_accuracy: 0.9677 - auc_21: 0.8460 - precision_21: 0.3536 - recall_21: 0.1574\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0799 - binary_accuracy: 0.9748 - auc_21: 0.9195 - precision_21: 0.6753 - recall_21: 0.2238\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_21: 0.9289 - precision_21: 0.6814 - recall_21: 0.2516\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0743 - binary_accuracy: 0.9757 - auc_21: 0.9343 - precision_21: 0.6869 - recall_21: 0.2709\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0725 - binary_accuracy: 0.9760 - auc_21: 0.9383 - precision_21: 0.6917 - recall_21: 0.2862\n","Score for fold 2: F1 score of 0.4128190237788785; loss of 0.07036399096250534; binary_accuracy of 97.6435899734497%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 25ms/step - loss: 0.1087 - binary_accuracy: 0.9678 - auc_22: 0.8486 - precision_22: 0.3572 - recall_22: 0.1597\n","Epoch 2/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0798 - binary_accuracy: 0.9748 - auc_22: 0.9198 - precision_22: 0.6769 - recall_22: 0.2260\n","Epoch 3/5\n","244/244 [==============================] - 6s 26ms/step - loss: 0.0764 - binary_accuracy: 0.9753 - auc_22: 0.9291 - precision_22: 0.6824 - recall_22: 0.2523\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0743 - binary_accuracy: 0.9757 - auc_22: 0.9343 - precision_22: 0.6865 - recall_22: 0.2710\n","Epoch 5/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0725 - binary_accuracy: 0.9760 - auc_22: 0.9383 - precision_22: 0.6924 - recall_22: 0.2863\n","Score for fold 3: F1 score of 0.4221700587781469; loss of 0.07027929276227951; binary_accuracy of 97.64708280563354%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1099 - binary_accuracy: 0.9675 - auc_23: 0.8467 - precision_23: 0.3465 - recall_23: 0.1575\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0801 - binary_accuracy: 0.9748 - auc_23: 0.9191 - precision_23: 0.6764 - recall_23: 0.2224\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_23: 0.9288 - precision_23: 0.6812 - recall_23: 0.2510\n","Epoch 4/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0744 - binary_accuracy: 0.9757 - auc_23: 0.9342 - precision_23: 0.6872 - recall_23: 0.2699\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_23: 0.9381 - precision_23: 0.6923 - recall_23: 0.2870\n","Score for fold 4: F1 score of 0.39039596289343353; loss of 0.07047753781080246; binary_accuracy of 97.63420820236206%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1110 - binary_accuracy: 0.9672 - auc_24: 0.8454 - precision_24: 0.3390 - recall_24: 0.1590\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0799 - binary_accuracy: 0.9748 - auc_24: 0.9195 - precision_24: 0.6752 - recall_24: 0.2239\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_24: 0.9290 - precision_24: 0.6811 - recall_24: 0.2516\n","Epoch 4/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0742 - binary_accuracy: 0.9757 - auc_24: 0.9345 - precision_24: 0.6860 - recall_24: 0.2711\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_24: 0.9383 - precision_24: 0.6906 - recall_24: 0.2859\n","Score for fold 5: F1 score of 0.41892454759880976; loss of 0.0703359916806221; binary_accuracy of 97.64078855514526%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 22ms/step - loss: 0.1096 - binary_accuracy: 0.9677 - auc_25: 0.8466 - precision_25: 0.3548 - recall_25: 0.1592\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0800 - binary_accuracy: 0.9748 - auc_25: 0.9192 - precision_25: 0.6765 - recall_25: 0.2233\n","Epoch 3/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_25: 0.9286 - precision_25: 0.6816 - recall_25: 0.2509\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0744 - binary_accuracy: 0.9757 - auc_25: 0.9340 - precision_25: 0.6872 - recall_25: 0.2700\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_25: 0.9380 - precision_25: 0.6918 - recall_25: 0.2863\n","Score for fold 6: F1 score of 0.4089341178331972; loss of 0.07052319496870041; binary_accuracy of 97.6355791091919%\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 22ms/step - loss: 0.1094 - binary_accuracy: 0.9679 - auc_26: 0.8465 - precision_26: 0.3580 - recall_26: 0.1592\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0798 - binary_accuracy: 0.9748 - auc_26: 0.9198 - precision_26: 0.6772 - recall_26: 0.2253\n","Epoch 3/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0764 - binary_accuracy: 0.9753 - auc_26: 0.9291 - precision_26: 0.6832 - recall_26: 0.2519\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0743 - binary_accuracy: 0.9757 - auc_26: 0.9343 - precision_26: 0.6867 - recall_26: 0.2710\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0725 - binary_accuracy: 0.9760 - auc_26: 0.9382 - precision_26: 0.6928 - recall_26: 0.2876\n","Score for fold 7: F1 score of 0.42854655022855953; loss of 0.0702330693602562; binary_accuracy of 97.64991998672485%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1093 - binary_accuracy: 0.9677 - auc_27: 0.8459 - precision_27: 0.3521 - recall_27: 0.1559\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0801 - binary_accuracy: 0.9748 - auc_27: 0.9190 - precision_27: 0.6753 - recall_27: 0.2241\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_27: 0.9287 - precision_27: 0.6816 - recall_27: 0.2509\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0744 - binary_accuracy: 0.9756 - auc_27: 0.9341 - precision_27: 0.6867 - recall_27: 0.2695\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_27: 0.9378 - precision_27: 0.6910 - recall_27: 0.2857\n","Score for fold 8: F1 score of 0.419681795314644; loss of 0.07048716396093369; binary_accuracy of 97.63962626457214%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 23ms/step - loss: 0.1089 - binary_accuracy: 0.9679 - auc_28: 0.8484 - precision_28: 0.3606 - recall_28: 0.1610\n","Epoch 2/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0800 - binary_accuracy: 0.9748 - auc_28: 0.9193 - precision_28: 0.6766 - recall_28: 0.2229\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_28: 0.9287 - precision_28: 0.6814 - recall_28: 0.2501\n","Epoch 4/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0744 - binary_accuracy: 0.9756 - auc_28: 0.9340 - precision_28: 0.6870 - recall_28: 0.2693\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_28: 0.9381 - precision_28: 0.6914 - recall_28: 0.2857\n","Score for fold 9: F1 score of 0.41201261786456245; loss of 0.0706421509385109; binary_accuracy of 97.63525724411011%\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1092 - binary_accuracy: 0.9677 - auc_29: 0.8469 - precision_29: 0.3531 - recall_29: 0.1589\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0799 - binary_accuracy: 0.9748 - auc_29: 0.9195 - precision_29: 0.6756 - recall_29: 0.2243\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0764 - binary_accuracy: 0.9753 - auc_29: 0.9291 - precision_29: 0.6829 - recall_29: 0.2515\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0743 - binary_accuracy: 0.9757 - auc_29: 0.9342 - precision_29: 0.6871 - recall_29: 0.2706\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0725 - binary_accuracy: 0.9760 - auc_29: 0.9383 - precision_29: 0.6924 - recall_29: 0.2860\n","Score for fold 10: F1 score of 0.4198547918256249; loss of 0.07054904848337173; binary_accuracy of 97.63627648353577%\n","----------------------------------------------------------------------\n","The number of units in each layer is  256\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1317 - binary_accuracy: 0.9538 - auc_30: 0.8073 - precision_30: 0.1489 - recall_30: 0.1316\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0868 - binary_accuracy: 0.9740 - auc_30: 0.8985 - precision_30: 0.6725 - recall_30: 0.1730\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0824 - binary_accuracy: 0.9745 - auc_30: 0.9134 - precision_30: 0.6797 - recall_30: 0.2006\n","Epoch 4/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0797 - binary_accuracy: 0.9748 - auc_30: 0.9213 - precision_30: 0.6832 - recall_30: 0.2202\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0777 - binary_accuracy: 0.9751 - auc_30: 0.9264 - precision_30: 0.6860 - recall_30: 0.2362\n","Score for fold 1: F1 score of 0.3709173971209762; loss of 0.07621569186449051; binary_accuracy of 97.54146933555603%\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 22ms/step - loss: 0.1327 - binary_accuracy: 0.9536 - auc_31: 0.8046 - precision_31: 0.1483 - recall_31: 0.1322\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0875 - binary_accuracy: 0.9739 - auc_31: 0.8953 - precision_31: 0.6718 - recall_31: 0.1692\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0828 - binary_accuracy: 0.9744 - auc_31: 0.9122 - precision_31: 0.6789 - recall_31: 0.1965\n","Epoch 4/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0800 - binary_accuracy: 0.9748 - auc_31: 0.9206 - precision_31: 0.6821 - recall_31: 0.2176\n","Epoch 5/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_31: 0.9259 - precision_31: 0.6861 - recall_31: 0.2347\n","Score for fold 2: F1 score of 0.35137761892914193; loss of 0.07631044089794159; binary_accuracy of 97.53486514091492%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 22ms/step - loss: 0.1322 - binary_accuracy: 0.9536 - auc_32: 0.8063 - precision_32: 0.1467 - recall_32: 0.1300\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0871 - binary_accuracy: 0.9739 - auc_32: 0.8972 - precision_32: 0.6732 - recall_32: 0.1690\n","Epoch 3/5\n","244/244 [==============================] - 5s 23ms/step - loss: 0.0826 - binary_accuracy: 0.9745 - auc_32: 0.9126 - precision_32: 0.6792 - recall_32: 0.1986\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0799 - binary_accuracy: 0.9748 - auc_32: 0.9207 - precision_32: 0.6817 - recall_32: 0.2195\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_32: 0.9260 - precision_32: 0.6859 - recall_32: 0.2357\n","Score for fold 3: F1 score of 0.3689219243896704; loss of 0.07632234692573547; binary_accuracy of 97.53953814506531%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 24ms/step - loss: 0.1319 - binary_accuracy: 0.9537 - auc_33: 0.8087 - precision_33: 0.1505 - recall_33: 0.1340\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0866 - binary_accuracy: 0.9740 - auc_33: 0.8989 - precision_33: 0.6741 - recall_33: 0.1743\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0822 - binary_accuracy: 0.9745 - auc_33: 0.9138 - precision_33: 0.6798 - recall_33: 0.2012\n","Epoch 4/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0794 - binary_accuracy: 0.9749 - auc_33: 0.9219 - precision_33: 0.6834 - recall_33: 0.2221\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0775 - binary_accuracy: 0.9752 - auc_33: 0.9270 - precision_33: 0.6865 - recall_33: 0.2392\n","Score for fold 4: F1 score of 0.3564849447561477; loss of 0.07566732913255692; binary_accuracy of 97.54878282546997%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1326 - binary_accuracy: 0.9535 - auc_34: 0.8016 - precision_34: 0.1478 - recall_34: 0.1321\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0878 - binary_accuracy: 0.9739 - auc_34: 0.8937 - precision_34: 0.6699 - recall_34: 0.1683\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0832 - binary_accuracy: 0.9744 - auc_34: 0.9108 - precision_34: 0.6774 - recall_34: 0.1951\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0804 - binary_accuracy: 0.9748 - auc_34: 0.9193 - precision_34: 0.6812 - recall_34: 0.2168\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0783 - binary_accuracy: 0.9751 - auc_34: 0.9248 - precision_34: 0.6849 - recall_34: 0.2329\n","Score for fold 5: F1 score of 0.34667248978115633; loss of 0.07675915211439133; binary_accuracy of 97.52663969993591%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1325 - binary_accuracy: 0.9531 - auc_35: 0.8092 - precision_35: 0.1503 - recall_35: 0.1380\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0866 - binary_accuracy: 0.9740 - auc_35: 0.8989 - precision_35: 0.6712 - recall_35: 0.1740\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0824 - binary_accuracy: 0.9745 - auc_35: 0.9134 - precision_35: 0.6775 - recall_35: 0.2006\n","Epoch 4/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0795 - binary_accuracy: 0.9748 - auc_35: 0.9216 - precision_35: 0.6821 - recall_35: 0.2218\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0776 - binary_accuracy: 0.9752 - auc_35: 0.9267 - precision_35: 0.6861 - recall_35: 0.2383\n","Score for fold 6: F1 score of 0.3555045386614133; loss of 0.07590846717357635; binary_accuracy of 97.54500985145569%\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1315 - binary_accuracy: 0.9537 - auc_36: 0.8093 - precision_36: 0.1513 - recall_36: 0.1351\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0867 - binary_accuracy: 0.9740 - auc_36: 0.8987 - precision_36: 0.6749 - recall_36: 0.1726\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0826 - binary_accuracy: 0.9745 - auc_36: 0.9129 - precision_36: 0.6784 - recall_36: 0.1995\n","Epoch 4/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0799 - binary_accuracy: 0.9748 - auc_36: 0.9206 - precision_36: 0.6816 - recall_36: 0.2177\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0780 - binary_accuracy: 0.9751 - auc_36: 0.9257 - precision_36: 0.6861 - recall_36: 0.2340\n","Score for fold 7: F1 score of 0.36369541635364544; loss of 0.0761888176202774; binary_accuracy of 97.54295349121094%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 22ms/step - loss: 0.1329 - binary_accuracy: 0.9535 - auc_37: 0.8033 - precision_37: 0.1437 - recall_37: 0.1268\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0874 - binary_accuracy: 0.9740 - auc_37: 0.8954 - precision_37: 0.6738 - recall_37: 0.1695\n","Epoch 3/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0826 - binary_accuracy: 0.9745 - auc_37: 0.9128 - precision_37: 0.6776 - recall_37: 0.2006\n","Epoch 4/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0798 - binary_accuracy: 0.9748 - auc_37: 0.9208 - precision_37: 0.6809 - recall_37: 0.2200\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0778 - binary_accuracy: 0.9751 - auc_37: 0.9261 - precision_37: 0.6855 - recall_37: 0.2364\n","Score for fold 8: F1 score of 0.3539392907132864; loss of 0.07614578306674957; binary_accuracy of 97.54177331924438%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 22ms/step - loss: 0.1331 - binary_accuracy: 0.9533 - auc_38: 0.8035 - precision_38: 0.1433 - recall_38: 0.1280\n","Epoch 2/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0871 - binary_accuracy: 0.9740 - auc_38: 0.8967 - precision_38: 0.6724 - recall_38: 0.1710\n","Epoch 3/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0825 - binary_accuracy: 0.9745 - auc_38: 0.9130 - precision_38: 0.6779 - recall_38: 0.2002\n","Epoch 4/5\n","244/244 [==============================] - 6s 24ms/step - loss: 0.0798 - binary_accuracy: 0.9748 - auc_38: 0.9210 - precision_38: 0.6826 - recall_38: 0.2202\n","Epoch 5/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0778 - binary_accuracy: 0.9751 - auc_38: 0.9260 - precision_38: 0.6852 - recall_38: 0.2361\n","Score for fold 9: F1 score of 0.3635750214047488; loss of 0.07633481174707413; binary_accuracy of 97.53746390342712%\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 7s 23ms/step - loss: 0.1342 - binary_accuracy: 0.9525 - auc_39: 0.7992 - precision_39: 0.1384 - recall_39: 0.1269\n","Epoch 2/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0877 - binary_accuracy: 0.9739 - auc_39: 0.8943 - precision_39: 0.6700 - recall_39: 0.1675\n","Epoch 3/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0829 - binary_accuracy: 0.9744 - auc_39: 0.9119 - precision_39: 0.6784 - recall_39: 0.1970\n","Epoch 4/5\n","244/244 [==============================] - 6s 23ms/step - loss: 0.0800 - binary_accuracy: 0.9748 - auc_39: 0.9204 - precision_39: 0.6812 - recall_39: 0.2181\n","Epoch 5/5\n","244/244 [==============================] - 5s 22ms/step - loss: 0.0779 - binary_accuracy: 0.9751 - auc_39: 0.9259 - precision_39: 0.6857 - recall_39: 0.2350\n","Score for fold 10: F1 score of 0.3527563866387077; loss of 0.076165571808815; binary_accuracy of 97.53639698028564%\n","----------------------------------------------------------------------\n","The number of units in each layer is  128\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1188 - binary_accuracy: 0.9650 - auc_40: 0.8288 - precision_40: 0.2792 - recall_40: 0.1438\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0821 - binary_accuracy: 0.9745 - auc_40: 0.9132 - precision_40: 0.6726 - recall_40: 0.2074\n","Epoch 3/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0786 - binary_accuracy: 0.9749 - auc_40: 0.9236 - precision_40: 0.6789 - recall_40: 0.2311\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0767 - binary_accuracy: 0.9752 - auc_40: 0.9286 - precision_40: 0.6810 - recall_40: 0.2477\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc_40: 0.9321 - precision_40: 0.6853 - recall_40: 0.2602\n","Score for fold 1: F1 score of 0.38054344474043994; loss of 0.0736338421702385; binary_accuracy of 97.57571816444397%\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 8s 19ms/step - loss: 0.1178 - binary_accuracy: 0.9654 - auc_41: 0.8294 - precision_41: 0.2907 - recall_41: 0.1479\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0821 - binary_accuracy: 0.9745 - auc_41: 0.9131 - precision_41: 0.6738 - recall_41: 0.2065\n","Epoch 3/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0786 - binary_accuracy: 0.9750 - auc_41: 0.9234 - precision_41: 0.6796 - recall_41: 0.2315\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0766 - binary_accuracy: 0.9752 - auc_41: 0.9287 - precision_41: 0.6836 - recall_41: 0.2470\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0753 - binary_accuracy: 0.9755 - auc_41: 0.9321 - precision_41: 0.6861 - recall_41: 0.2596\n","Score for fold 2: F1 score of 0.36037894536225695; loss of 0.07371031492948532; binary_accuracy of 97.56871461868286%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1201 - binary_accuracy: 0.9649 - auc_42: 0.8254 - precision_42: 0.2812 - recall_42: 0.1471\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0820 - binary_accuracy: 0.9745 - auc_42: 0.9132 - precision_42: 0.6748 - recall_42: 0.2067\n","Epoch 3/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_42: 0.9240 - precision_42: 0.6804 - recall_42: 0.2336\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_42: 0.9291 - precision_42: 0.6838 - recall_42: 0.2489\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0750 - binary_accuracy: 0.9755 - auc_42: 0.9326 - precision_42: 0.6870 - recall_42: 0.2617\n","Score for fold 3: F1 score of 0.3913096592448431; loss of 0.07344084233045578; binary_accuracy of 97.58270978927612%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1191 - binary_accuracy: 0.9647 - auc_43: 0.8306 - precision_43: 0.2804 - recall_43: 0.1513\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0817 - binary_accuracy: 0.9745 - auc_43: 0.9144 - precision_43: 0.6742 - recall_43: 0.2088\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_43: 0.9241 - precision_43: 0.6810 - recall_43: 0.2344\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_43: 0.9290 - precision_43: 0.6835 - recall_43: 0.2496\n","Epoch 5/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_43: 0.9326 - precision_43: 0.6863 - recall_43: 0.2614\n","Score for fold 4: F1 score of 0.39107947318868025; loss of 0.07337237894535065; binary_accuracy of 97.58222103118896%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1190 - binary_accuracy: 0.9650 - auc_44: 0.8289 - precision_44: 0.2816 - recall_44: 0.1457\n","Epoch 2/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0819 - binary_accuracy: 0.9745 - auc_44: 0.9136 - precision_44: 0.6725 - recall_44: 0.2079\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_44: 0.9237 - precision_44: 0.6793 - recall_44: 0.2329\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_44: 0.9290 - precision_44: 0.6839 - recall_44: 0.2492\n","Epoch 5/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_44: 0.9325 - precision_44: 0.6873 - recall_44: 0.2610\n","Score for fold 5: F1 score of 0.37952695455322966; loss of 0.07338354736566544; binary_accuracy of 97.579824924469%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 20ms/step - loss: 0.1195 - binary_accuracy: 0.9649 - auc_45: 0.8303 - precision_45: 0.2849 - recall_45: 0.1514\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0818 - binary_accuracy: 0.9745 - auc_45: 0.9139 - precision_45: 0.6746 - recall_45: 0.2075\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_45: 0.9237 - precision_45: 0.6806 - recall_45: 0.2327\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0766 - binary_accuracy: 0.9753 - auc_45: 0.9288 - precision_45: 0.6838 - recall_45: 0.2487\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc_45: 0.9322 - precision_45: 0.6870 - recall_45: 0.2606\n","Score for fold 6: F1 score of 0.4054708578292552; loss of 0.07354975491762161; binary_accuracy of 97.5820779800415%\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 20ms/step - loss: 0.1196 - binary_accuracy: 0.9648 - auc_46: 0.8277 - precision_46: 0.2780 - recall_46: 0.1469\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0820 - binary_accuracy: 0.9745 - auc_46: 0.9135 - precision_46: 0.6747 - recall_46: 0.2066\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_46: 0.9237 - precision_46: 0.6802 - recall_46: 0.2326\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_46: 0.9289 - precision_46: 0.6834 - recall_46: 0.2493\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_46: 0.9324 - precision_46: 0.6882 - recall_46: 0.2611\n","Score for fold 7: F1 score of 0.39419851831771485; loss of 0.07342341542243958; binary_accuracy of 97.58163690567017%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 20ms/step - loss: 0.1187 - binary_accuracy: 0.9650 - auc_47: 0.8293 - precision_47: 0.2838 - recall_47: 0.1478\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0817 - binary_accuracy: 0.9745 - auc_47: 0.9141 - precision_47: 0.6734 - recall_47: 0.2092\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0785 - binary_accuracy: 0.9750 - auc_47: 0.9236 - precision_47: 0.6795 - recall_47: 0.2336\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_47: 0.9290 - precision_47: 0.6833 - recall_47: 0.2490\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - auc_47: 0.9325 - precision_47: 0.6865 - recall_47: 0.2608\n","Score for fold 8: F1 score of 0.387572902254685; loss of 0.07363002002239227; binary_accuracy of 97.57722616195679%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 20ms/step - loss: 0.1184 - binary_accuracy: 0.9653 - auc_48: 0.8290 - precision_48: 0.2895 - recall_48: 0.1479\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0818 - binary_accuracy: 0.9745 - auc_48: 0.9140 - precision_48: 0.6718 - recall_48: 0.2087\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_48: 0.9241 - precision_48: 0.6784 - recall_48: 0.2344\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_48: 0.9291 - precision_48: 0.6822 - recall_48: 0.2492\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0750 - binary_accuracy: 0.9755 - auc_48: 0.9326 - precision_48: 0.6862 - recall_48: 0.2620\n","Score for fold 9: F1 score of 0.3924527960110048; loss of 0.0734410509467125; binary_accuracy of 97.58118391036987%\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1175 - binary_accuracy: 0.9658 - auc_49: 0.8308 - precision_49: 0.3009 - recall_49: 0.1488\n","Epoch 2/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0818 - binary_accuracy: 0.9745 - auc_49: 0.9140 - precision_49: 0.6729 - recall_49: 0.2089\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0784 - binary_accuracy: 0.9750 - auc_49: 0.9240 - precision_49: 0.6791 - recall_49: 0.2337\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0765 - binary_accuracy: 0.9753 - auc_49: 0.9289 - precision_49: 0.6831 - recall_49: 0.2488\n","Epoch 5/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0752 - binary_accuracy: 0.9755 - auc_49: 0.9323 - precision_49: 0.6858 - recall_49: 0.2607\n","Score for fold 10: F1 score of 0.39031143859310824; loss of 0.073433518409729; binary_accuracy of 97.58161306381226%\n","----------------------------------------------------------------------\n","The number of units in each layer is  128\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1485 - binary_accuracy: 0.9474 - auc_50: 0.7716 - precision_50: 0.0991 - recall_50: 0.1043\n","Epoch 2/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0963 - binary_accuracy: 0.9731 - auc_50: 0.8513 - precision_50: 0.6686 - recall_50: 0.1124\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0893 - binary_accuracy: 0.9738 - auc_50: 0.8858 - precision_50: 0.6715 - recall_50: 0.1605\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0854 - binary_accuracy: 0.9742 - auc_50: 0.9026 - precision_50: 0.6788 - recall_50: 0.1828\n","Epoch 5/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0827 - binary_accuracy: 0.9745 - auc_50: 0.9124 - precision_50: 0.6814 - recall_50: 0.2000\n","Score for fold 1: F1 score of 0.32510202986041764; loss of 0.08093152940273285; binary_accuracy of 97.47182130813599%\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 20ms/step - loss: 0.1481 - binary_accuracy: 0.9474 - auc_51: 0.7706 - precision_51: 0.0998 - recall_51: 0.1052\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0974 - binary_accuracy: 0.9730 - auc_51: 0.8454 - precision_51: 0.6663 - recall_51: 0.1050\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0911 - binary_accuracy: 0.9736 - auc_51: 0.8784 - precision_51: 0.6615 - recall_51: 0.1500\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0867 - binary_accuracy: 0.9740 - auc_51: 0.8978 - precision_51: 0.6746 - recall_51: 0.1731\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0838 - binary_accuracy: 0.9744 - auc_51: 0.9085 - precision_51: 0.6805 - recall_51: 0.1917\n","Score for fold 2: F1 score of 0.29523796791753554; loss of 0.08211778104305267; binary_accuracy of 97.4544882774353%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1486 - binary_accuracy: 0.9471 - auc_52: 0.7728 - precision_52: 0.0999 - recall_52: 0.1066\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0967 - binary_accuracy: 0.9731 - auc_52: 0.8491 - precision_52: 0.6707 - recall_52: 0.1094\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0901 - binary_accuracy: 0.9738 - auc_52: 0.8819 - precision_52: 0.6711 - recall_52: 0.1576\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0857 - binary_accuracy: 0.9742 - auc_52: 0.9017 - precision_52: 0.6762 - recall_52: 0.1839\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0829 - binary_accuracy: 0.9745 - auc_52: 0.9116 - precision_52: 0.6806 - recall_52: 0.1996\n","Score for fold 3: F1 score of 0.3253952391006639; loss of 0.08123067766427994; binary_accuracy of 97.46924042701721%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1472 - binary_accuracy: 0.9486 - auc_53: 0.7729 - precision_53: 0.1056 - recall_53: 0.1074\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0964 - binary_accuracy: 0.9730 - auc_53: 0.8520 - precision_53: 0.6653 - recall_53: 0.1109\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0911 - binary_accuracy: 0.9736 - auc_53: 0.8779 - precision_53: 0.6670 - recall_53: 0.1479\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0867 - binary_accuracy: 0.9741 - auc_53: 0.8978 - precision_53: 0.6754 - recall_53: 0.1752\n","Epoch 5/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0837 - binary_accuracy: 0.9744 - auc_53: 0.9090 - precision_53: 0.6803 - recall_53: 0.1940\n","Score for fold 4: F1 score of 0.32006456558207086; loss of 0.08191560953855515; binary_accuracy of 97.46500849723816%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1472 - binary_accuracy: 0.9483 - auc_54: 0.7717 - precision_54: 0.1019 - recall_54: 0.1040\n","Epoch 2/5\n","244/244 [==============================] - 5s 18ms/step - loss: 0.0970 - binary_accuracy: 0.9730 - auc_54: 0.8477 - precision_54: 0.6693 - recall_54: 0.1068\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0915 - binary_accuracy: 0.9736 - auc_54: 0.8761 - precision_54: 0.6713 - recall_54: 0.1438\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0870 - binary_accuracy: 0.9740 - auc_54: 0.8963 - precision_54: 0.6754 - recall_54: 0.1733\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0841 - binary_accuracy: 0.9744 - auc_54: 0.9075 - precision_54: 0.6821 - recall_54: 0.1897\n","Score for fold 5: F1 score of 0.3052566371749808; loss of 0.0822356715798378; binary_accuracy of 97.45727777481079%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 8s 19ms/step - loss: 0.1478 - binary_accuracy: 0.9479 - auc_55: 0.7724 - precision_55: 0.1016 - recall_55: 0.1051\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0959 - binary_accuracy: 0.9731 - auc_55: 0.8530 - precision_55: 0.6684 - recall_55: 0.1160\n","Epoch 3/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0895 - binary_accuracy: 0.9738 - auc_55: 0.8849 - precision_55: 0.6711 - recall_55: 0.1589\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0856 - binary_accuracy: 0.9742 - auc_55: 0.9017 - precision_55: 0.6793 - recall_55: 0.1813\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0829 - binary_accuracy: 0.9745 - auc_55: 0.9110 - precision_55: 0.6825 - recall_55: 0.1986\n","Score for fold 6: F1 score of 0.3137612604082201; loss of 0.08129817247390747; binary_accuracy of 97.47181534767151%\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1464 - binary_accuracy: 0.9491 - auc_56: 0.7725 - precision_56: 0.1043 - recall_56: 0.1030\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0981 - binary_accuracy: 0.9729 - auc_56: 0.8403 - precision_56: 0.6678 - recall_56: 0.1007\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0926 - binary_accuracy: 0.9734 - auc_56: 0.8703 - precision_56: 0.6594 - recall_56: 0.1420\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0878 - binary_accuracy: 0.9739 - auc_56: 0.8934 - precision_56: 0.6729 - recall_56: 0.1686\n","Epoch 5/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0845 - binary_accuracy: 0.9743 - auc_56: 0.9062 - precision_56: 0.6806 - recall_56: 0.1883\n","Score for fold 7: F1 score of 0.30452313572952827; loss of 0.08270829916000366; binary_accuracy of 97.45393991470337%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1465 - binary_accuracy: 0.9487 - auc_57: 0.7725 - precision_57: 0.1033 - recall_57: 0.1040\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0973 - binary_accuracy: 0.9730 - auc_57: 0.8459 - precision_57: 0.6698 - recall_57: 0.1047\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0907 - binary_accuracy: 0.9737 - auc_57: 0.8800 - precision_57: 0.6720 - recall_57: 0.1502\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0864 - binary_accuracy: 0.9741 - auc_57: 0.8989 - precision_57: 0.6781 - recall_57: 0.1744\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0836 - binary_accuracy: 0.9744 - auc_57: 0.9093 - precision_57: 0.6811 - recall_57: 0.1928\n","Score for fold 8: F1 score of 0.32888853821843883; loss of 0.08193891495466232; binary_accuracy of 97.46257662773132%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1479 - binary_accuracy: 0.9473 - auc_58: 0.7720 - precision_58: 0.1003 - recall_58: 0.1061\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0967 - binary_accuracy: 0.9730 - auc_58: 0.8481 - precision_58: 0.6680 - recall_58: 0.1097\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0913 - binary_accuracy: 0.9736 - auc_58: 0.8764 - precision_58: 0.6664 - recall_58: 0.1484\n","Epoch 4/5\n","244/244 [==============================] - 5s 20ms/step - loss: 0.0869 - binary_accuracy: 0.9740 - auc_58: 0.8969 - precision_58: 0.6766 - recall_58: 0.1730\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0837 - binary_accuracy: 0.9744 - auc_58: 0.9087 - precision_58: 0.6823 - recall_58: 0.1941\n","Score for fold 9: F1 score of 0.32231590646114633; loss of 0.0817512795329094; binary_accuracy of 97.46600389480591%\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 6s 19ms/step - loss: 0.1481 - binary_accuracy: 0.9471 - auc_59: 0.7713 - precision_59: 0.0989 - recall_59: 0.1053\n","Epoch 2/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0972 - binary_accuracy: 0.9730 - auc_59: 0.8464 - precision_59: 0.6743 - recall_59: 0.1043\n","Epoch 3/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0915 - binary_accuracy: 0.9736 - auc_59: 0.8758 - precision_59: 0.6730 - recall_59: 0.1436\n","Epoch 4/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0869 - binary_accuracy: 0.9741 - auc_59: 0.8967 - precision_59: 0.6756 - recall_59: 0.1753\n","Epoch 5/5\n","244/244 [==============================] - 5s 19ms/step - loss: 0.0839 - binary_accuracy: 0.9744 - auc_59: 0.9079 - precision_59: 0.6820 - recall_59: 0.1925\n","Score for fold 10: F1 score of 0.3076418979080445; loss of 0.08207830041646957; binary_accuracy of 97.46289849281311%\n","=======================================================================\n","Training for Cellular Component\n","----------------------------------------------------------------------\n","The number of units in each layer is  512\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0836 - binary_accuracy: 0.9759 - auc_60: 0.8853 - precision_60: 0.5278 - recall_60: 0.2273\n","Epoch 2/5\n","331/331 [==============================] - 10s 31ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_60: 0.9333 - precision_60: 0.7392 - recall_60: 0.2846\n","Epoch 3/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0622 - binary_accuracy: 0.9802 - auc_60: 0.9412 - precision_60: 0.7389 - recall_60: 0.3098\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_60: 0.9462 - precision_60: 0.7396 - recall_60: 0.3302\n","Epoch 5/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0584 - binary_accuracy: 0.9809 - auc_60: 0.9503 - precision_60: 0.7420 - recall_60: 0.3484\n","Score for fold 1: F1 score of 0.48919323738848886; loss of 0.05572647973895073; binary_accuracy of 98.13711047172546%\n","Current best model for Cellular Component has 512 units in each layer, uses relu activation function and has an F1 score of 0.48919323738848886\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0838 - binary_accuracy: 0.9759 - auc_61: 0.8849 - precision_61: 0.5277 - recall_61: 0.2256\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0652 - binary_accuracy: 0.9798 - auc_61: 0.9332 - precision_61: 0.7397 - recall_61: 0.2834\n","Epoch 3/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_61: 0.9409 - precision_61: 0.7380 - recall_61: 0.3090\n","Epoch 4/5\n","331/331 [==============================] - 10s 32ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - auc_61: 0.9458 - precision_61: 0.7393 - recall_61: 0.3289\n","Epoch 5/5\n","331/331 [==============================] - 10s 32ms/step - loss: 0.0585 - binary_accuracy: 0.9809 - auc_61: 0.9501 - precision_61: 0.7428 - recall_61: 0.3465\n","Score for fold 2: F1 score of 0.5048323864661755; loss of 0.05620260536670685; binary_accuracy of 98.1296718120575%\n","Current best model for Cellular Component has 512 units in each layer, uses relu activation function and has an F1 score of 0.5048323864661755\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0831 - binary_accuracy: 0.9760 - auc_62: 0.8866 - precision_62: 0.5355 - recall_62: 0.2273\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_62: 0.9334 - precision_62: 0.7397 - recall_62: 0.2840\n","Epoch 3/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_62: 0.9409 - precision_62: 0.7388 - recall_62: 0.3092\n","Epoch 4/5\n","331/331 [==============================] - 10s 31ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_62: 0.9461 - precision_62: 0.7406 - recall_62: 0.3290\n","Epoch 5/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0584 - binary_accuracy: 0.9809 - auc_62: 0.9503 - precision_62: 0.7428 - recall_62: 0.3469\n","Score for fold 3: F1 score of 0.5015097959374714; loss of 0.05589530989527702; binary_accuracy of 98.14351797103882%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0840 - binary_accuracy: 0.9758 - auc_63: 0.8842 - precision_63: 0.5259 - recall_63: 0.2259\n","Epoch 2/5\n","331/331 [==============================] - 10s 32ms/step - loss: 0.0652 - binary_accuracy: 0.9798 - auc_63: 0.9333 - precision_63: 0.7388 - recall_63: 0.2843\n","Epoch 3/5\n","331/331 [==============================] - 10s 31ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_63: 0.9410 - precision_63: 0.7378 - recall_63: 0.3089\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - auc_63: 0.9460 - precision_63: 0.7402 - recall_63: 0.3287\n","Epoch 5/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0585 - binary_accuracy: 0.9809 - auc_63: 0.9501 - precision_63: 0.7430 - recall_63: 0.3469\n","Score for fold 4: F1 score of 0.4898259461061893; loss of 0.05593466758728027; binary_accuracy of 98.13457131385803%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0843 - binary_accuracy: 0.9756 - auc_64: 0.8842 - precision_64: 0.5149 - recall_64: 0.2258\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_64: 0.9336 - precision_64: 0.7406 - recall_64: 0.2841\n","Epoch 3/5\n","331/331 [==============================] - 11s 35ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_64: 0.9409 - precision_64: 0.7391 - recall_64: 0.3084\n","Epoch 4/5\n","331/331 [==============================] - 12s 35ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - auc_64: 0.9460 - precision_64: 0.7403 - recall_64: 0.3282\n","Epoch 5/5\n","331/331 [==============================] - 12s 38ms/step - loss: 0.0584 - binary_accuracy: 0.9809 - auc_64: 0.9500 - precision_64: 0.7438 - recall_64: 0.3470\n","Score for fold 5: F1 score of 0.5018624809663149; loss of 0.05577106773853302; binary_accuracy of 98.1468141078949%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0843 - binary_accuracy: 0.9756 - auc_65: 0.8831 - precision_65: 0.5170 - recall_65: 0.2225\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0652 - binary_accuracy: 0.9798 - auc_65: 0.9331 - precision_65: 0.7399 - recall_65: 0.2826\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_65: 0.9408 - precision_65: 0.7379 - recall_65: 0.3094\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - auc_65: 0.9458 - precision_65: 0.7405 - recall_65: 0.3285\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0585 - binary_accuracy: 0.9809 - auc_65: 0.9500 - precision_65: 0.7428 - recall_65: 0.3472\n","Score for fold 6: F1 score of 0.4919725478175596; loss of 0.05582105740904808; binary_accuracy of 98.14633131027222%\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0837 - binary_accuracy: 0.9757 - auc_66: 0.8854 - precision_66: 0.5215 - recall_66: 0.2284\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_66: 0.9335 - precision_66: 0.7393 - recall_66: 0.2852\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_66: 0.9409 - precision_66: 0.7382 - recall_66: 0.3096\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_66: 0.9460 - precision_66: 0.7385 - recall_66: 0.3300\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0584 - binary_accuracy: 0.9809 - auc_66: 0.9503 - precision_66: 0.7423 - recall_66: 0.3481\n","Score for fold 7: F1 score of 0.5047671182949978; loss of 0.05574224889278412; binary_accuracy of 98.13842177391052%\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0837 - binary_accuracy: 0.9757 - auc_67: 0.8854 - precision_67: 0.5204 - recall_67: 0.2267\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_67: 0.9339 - precision_67: 0.7404 - recall_67: 0.2847\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_67: 0.9411 - precision_67: 0.7389 - recall_67: 0.3098\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_67: 0.9463 - precision_67: 0.7401 - recall_67: 0.3295\n","Epoch 5/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0583 - binary_accuracy: 0.9809 - auc_67: 0.9504 - precision_67: 0.7433 - recall_67: 0.3483\n","Score for fold 8: F1 score of 0.5008522394571406; loss of 0.055805668234825134; binary_accuracy of 98.1442928314209%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0839 - binary_accuracy: 0.9758 - auc_68: 0.8850 - precision_68: 0.5248 - recall_68: 0.2260\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0652 - binary_accuracy: 0.9798 - auc_68: 0.9333 - precision_68: 0.7400 - recall_68: 0.2832\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_68: 0.9409 - precision_68: 0.7385 - recall_68: 0.3085\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_68: 0.9461 - precision_68: 0.7399 - recall_68: 0.3289\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0585 - binary_accuracy: 0.9809 - auc_68: 0.9502 - precision_68: 0.7424 - recall_68: 0.3460\n","Score for fold 9: F1 score of 0.47065208522681595; loss of 0.05598292872309685; binary_accuracy of 98.12840819358826%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0841 - binary_accuracy: 0.9758 - auc_69: 0.8835 - precision_69: 0.5242 - recall_69: 0.2242\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0652 - binary_accuracy: 0.9798 - auc_69: 0.9331 - precision_69: 0.7403 - recall_69: 0.2825\n","Epoch 3/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_69: 0.9409 - precision_69: 0.7384 - recall_69: 0.3081\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - auc_69: 0.9459 - precision_69: 0.7408 - recall_69: 0.3280\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0585 - binary_accuracy: 0.9808 - auc_69: 0.9501 - precision_69: 0.7413 - recall_69: 0.3461\n","Score for fold 10: F1 score of 0.47824533016730225; loss of 0.056061454117298126; binary_accuracy of 98.12809228897095%\n","----------------------------------------------------------------------\n","The number of units in each layer is  512\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 15s 33ms/step - loss: 0.0970 - binary_accuracy: 0.9675 - auc_70: 0.8697 - precision_70: 0.2920 - recall_70: 0.2217\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0674 - binary_accuracy: 0.9795 - auc_70: 0.9275 - precision_70: 0.7433 - recall_70: 0.2616\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_70: 0.9357 - precision_70: 0.7408 - recall_70: 0.2859\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0626 - binary_accuracy: 0.9801 - auc_70: 0.9405 - precision_70: 0.7386 - recall_70: 0.3050\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0609 - binary_accuracy: 0.9804 - auc_70: 0.9446 - precision_70: 0.7401 - recall_70: 0.3209\n","Score for fold 1: F1 score of 0.45794638749462524; loss of 0.058877430856227875; binary_accuracy of 98.07997345924377%\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0976 - binary_accuracy: 0.9669 - auc_71: 0.8694 - precision_71: 0.2861 - recall_71: 0.2252\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0673 - binary_accuracy: 0.9795 - auc_71: 0.9277 - precision_71: 0.7449 - recall_71: 0.2622\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_71: 0.9355 - precision_71: 0.7397 - recall_71: 0.2874\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0626 - binary_accuracy: 0.9802 - auc_71: 0.9405 - precision_71: 0.7403 - recall_71: 0.3048\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0611 - binary_accuracy: 0.9804 - auc_71: 0.9442 - precision_71: 0.7402 - recall_71: 0.3200\n","Score for fold 2: F1 score of 0.45272373750929856; loss of 0.05902582406997681; binary_accuracy of 98.07610511779785%\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0975 - binary_accuracy: 0.9668 - auc_72: 0.8711 - precision_72: 0.2833 - recall_72: 0.2238\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0674 - binary_accuracy: 0.9795 - auc_72: 0.9276 - precision_72: 0.7424 - recall_72: 0.2622\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0647 - binary_accuracy: 0.9798 - auc_72: 0.9352 - precision_72: 0.7390 - recall_72: 0.2855\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0627 - binary_accuracy: 0.9801 - auc_72: 0.9402 - precision_72: 0.7398 - recall_72: 0.3039\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0611 - binary_accuracy: 0.9804 - auc_72: 0.9441 - precision_72: 0.7399 - recall_72: 0.3192\n","Score for fold 3: F1 score of 0.472110260709224; loss of 0.059213731437921524; binary_accuracy of 98.07618260383606%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0984 - binary_accuracy: 0.9669 - auc_73: 0.8655 - precision_73: 0.2829 - recall_73: 0.2194\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0678 - binary_accuracy: 0.9795 - auc_73: 0.9264 - precision_73: 0.7453 - recall_73: 0.2572\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0649 - binary_accuracy: 0.9798 - auc_73: 0.9345 - precision_73: 0.7408 - recall_73: 0.2830\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0629 - binary_accuracy: 0.9801 - auc_73: 0.9396 - precision_73: 0.7402 - recall_73: 0.3011\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0614 - binary_accuracy: 0.9803 - auc_73: 0.9434 - precision_73: 0.7399 - recall_73: 0.3164\n","Score for fold 4: F1 score of 0.4555203642663041; loss of 0.05950763076543808; binary_accuracy of 98.0681300163269%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0979 - binary_accuracy: 0.9668 - auc_74: 0.8684 - precision_74: 0.2831 - recall_74: 0.2227\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0674 - binary_accuracy: 0.9795 - auc_74: 0.9276 - precision_74: 0.7444 - recall_74: 0.2615\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_74: 0.9354 - precision_74: 0.7405 - recall_74: 0.2852\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0628 - binary_accuracy: 0.9801 - auc_74: 0.9401 - precision_74: 0.7399 - recall_74: 0.3030\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0611 - binary_accuracy: 0.9804 - auc_74: 0.9441 - precision_74: 0.7411 - recall_74: 0.3191\n","Score for fold 5: F1 score of 0.46129118567751126; loss of 0.05935352295637131; binary_accuracy of 98.07347655296326%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0974 - binary_accuracy: 0.9672 - auc_75: 0.8685 - precision_75: 0.2889 - recall_75: 0.2224\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0676 - binary_accuracy: 0.9795 - auc_75: 0.9268 - precision_75: 0.7442 - recall_75: 0.2598\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0647 - binary_accuracy: 0.9798 - auc_75: 0.9350 - precision_75: 0.7409 - recall_75: 0.2843\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0627 - binary_accuracy: 0.9801 - auc_75: 0.9401 - precision_75: 0.7402 - recall_75: 0.3032\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0611 - binary_accuracy: 0.9804 - auc_75: 0.9440 - precision_75: 0.7393 - recall_75: 0.3194\n","Score for fold 6: F1 score of 0.46060822891695785; loss of 0.05935791879892349; binary_accuracy of 98.06761741638184%\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0980 - binary_accuracy: 0.9666 - auc_76: 0.8698 - precision_76: 0.2806 - recall_76: 0.2251\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0672 - binary_accuracy: 0.9795 - auc_76: 0.9280 - precision_76: 0.7445 - recall_76: 0.2624\n","Epoch 3/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_76: 0.9357 - precision_76: 0.7411 - recall_76: 0.2863\n","Epoch 4/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0625 - binary_accuracy: 0.9802 - auc_76: 0.9407 - precision_76: 0.7402 - recall_76: 0.3045\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0610 - binary_accuracy: 0.9804 - auc_76: 0.9444 - precision_76: 0.7393 - recall_76: 0.3205\n","Score for fold 7: F1 score of 0.4483965151731449; loss of 0.059261638671159744; binary_accuracy of 98.07135462760925%\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0980 - binary_accuracy: 0.9667 - auc_77: 0.8692 - precision_77: 0.2803 - recall_77: 0.2223\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0673 - binary_accuracy: 0.9795 - auc_77: 0.9277 - precision_77: 0.7449 - recall_77: 0.2621\n","Epoch 3/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_77: 0.9355 - precision_77: 0.7414 - recall_77: 0.2863\n","Epoch 4/5\n","331/331 [==============================] - 12s 37ms/step - loss: 0.0625 - binary_accuracy: 0.9802 - auc_77: 0.9406 - precision_77: 0.7402 - recall_77: 0.3050\n","Epoch 5/5\n","331/331 [==============================] - 12s 37ms/step - loss: 0.0610 - binary_accuracy: 0.9804 - auc_77: 0.9444 - precision_77: 0.7401 - recall_77: 0.3205\n","Score for fold 8: F1 score of 0.44347319651096984; loss of 0.06097929924726486; binary_accuracy of 98.01029562950134%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0978 - binary_accuracy: 0.9671 - auc_78: 0.8670 - precision_78: 0.2854 - recall_78: 0.2198\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0679 - binary_accuracy: 0.9794 - auc_78: 0.9261 - precision_78: 0.7426 - recall_78: 0.2581\n","Epoch 3/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0649 - binary_accuracy: 0.9798 - auc_78: 0.9344 - precision_78: 0.7412 - recall_78: 0.2825\n","Epoch 4/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0630 - binary_accuracy: 0.9801 - auc_78: 0.9396 - precision_78: 0.7398 - recall_78: 0.3011\n","Epoch 5/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0614 - binary_accuracy: 0.9803 - auc_78: 0.9435 - precision_78: 0.7391 - recall_78: 0.3165\n","Score for fold 9: F1 score of 0.4536743160456749; loss of 0.05936254560947418; binary_accuracy of 98.07251691818237%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0983 - binary_accuracy: 0.9668 - auc_79: 0.8671 - precision_79: 0.2809 - recall_79: 0.2201\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0676 - binary_accuracy: 0.9795 - auc_79: 0.9269 - precision_79: 0.7444 - recall_79: 0.2595\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0647 - binary_accuracy: 0.9799 - auc_79: 0.9352 - precision_79: 0.7417 - recall_79: 0.2851\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0627 - binary_accuracy: 0.9801 - auc_79: 0.9403 - precision_79: 0.7393 - recall_79: 0.3036\n","Epoch 5/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0612 - binary_accuracy: 0.9804 - auc_79: 0.9440 - precision_79: 0.7392 - recall_79: 0.3188\n","Score for fold 10: F1 score of 0.4734698572735756; loss of 0.059211257845163345; binary_accuracy of 98.07460308074951%\n","----------------------------------------------------------------------\n","The number of units in each layer is  256\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.0886 - binary_accuracy: 0.9744 - auc_80: 0.8756 - precision_80: 0.4634 - recall_80: 0.2189\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0660 - binary_accuracy: 0.9797 - auc_80: 0.9311 - precision_80: 0.7405 - recall_80: 0.2742\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0633 - binary_accuracy: 0.9800 - auc_80: 0.9388 - precision_80: 0.7405 - recall_80: 0.2974\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0615 - binary_accuracy: 0.9803 - auc_80: 0.9433 - precision_80: 0.7406 - recall_80: 0.3141\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0601 - binary_accuracy: 0.9806 - auc_80: 0.9468 - precision_80: 0.7415 - recall_80: 0.3286\n","Score for fold 1: F1 score of 0.47733989519496955; loss of 0.05805060639977455; binary_accuracy of 98.0944573879242%\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 23ms/step - loss: 0.0889 - binary_accuracy: 0.9744 - auc_81: 0.8743 - precision_81: 0.4609 - recall_81: 0.2167\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_81: 0.9307 - precision_81: 0.7425 - recall_81: 0.2734\n","Epoch 3/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_81: 0.9385 - precision_81: 0.7414 - recall_81: 0.2962\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0616 - binary_accuracy: 0.9803 - auc_81: 0.9431 - precision_81: 0.7408 - recall_81: 0.3128\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0601 - binary_accuracy: 0.9806 - auc_81: 0.9465 - precision_81: 0.7419 - recall_81: 0.3273\n","Score for fold 2: F1 score of 0.466804944592968; loss of 0.058023836463689804; binary_accuracy of 98.09093475341797%\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 23ms/step - loss: 0.0888 - binary_accuracy: 0.9743 - auc_82: 0.8759 - precision_82: 0.4598 - recall_82: 0.2200\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0659 - binary_accuracy: 0.9797 - auc_82: 0.9314 - precision_82: 0.7421 - recall_82: 0.2750\n","Epoch 3/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0632 - binary_accuracy: 0.9801 - auc_82: 0.9389 - precision_82: 0.7403 - recall_82: 0.2984\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0615 - binary_accuracy: 0.9803 - auc_82: 0.9433 - precision_82: 0.7403 - recall_82: 0.3149\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0600 - binary_accuracy: 0.9806 - auc_82: 0.9468 - precision_82: 0.7413 - recall_82: 0.3290\n","Score for fold 3: F1 score of 0.4739171390004861; loss of 0.05802573636174202; binary_accuracy of 98.09662699699402%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.0894 - binary_accuracy: 0.9743 - auc_83: 0.8735 - precision_83: 0.4568 - recall_83: 0.2175\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_83: 0.9307 - precision_83: 0.7424 - recall_83: 0.2727\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_83: 0.9384 - precision_83: 0.7405 - recall_83: 0.2970\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0617 - binary_accuracy: 0.9803 - auc_83: 0.9428 - precision_83: 0.7405 - recall_83: 0.3129\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_83: 0.9465 - precision_83: 0.7412 - recall_83: 0.3270\n","Score for fold 4: F1 score of 0.4380718544948698; loss of 0.05858950316905975; binary_accuracy of 98.07912707328796%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.0890 - binary_accuracy: 0.9744 - auc_84: 0.8735 - precision_84: 0.4639 - recall_84: 0.2157\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_84: 0.9305 - precision_84: 0.7428 - recall_84: 0.2718\n","Epoch 3/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_84: 0.9385 - precision_84: 0.7416 - recall_84: 0.2960\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0617 - binary_accuracy: 0.9803 - auc_84: 0.9429 - precision_84: 0.7406 - recall_84: 0.3125\n","Epoch 5/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_84: 0.9465 - precision_84: 0.7419 - recall_84: 0.3261\n","Score for fold 5: F1 score of 0.4684355875574161; loss of 0.05805306136608124; binary_accuracy of 98.0972945690155%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.0893 - binary_accuracy: 0.9743 - auc_85: 0.8727 - precision_85: 0.4601 - recall_85: 0.2173\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_85: 0.9308 - precision_85: 0.7417 - recall_85: 0.2740\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_85: 0.9384 - precision_85: 0.7395 - recall_85: 0.2963\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0616 - binary_accuracy: 0.9803 - auc_85: 0.9431 - precision_85: 0.7409 - recall_85: 0.3132\n","Epoch 5/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_85: 0.9465 - precision_85: 0.7415 - recall_85: 0.3272\n","Score for fold 6: F1 score of 0.48463163540902393; loss of 0.058613669127225876; binary_accuracy of 98.08669686317444%\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 23ms/step - loss: 0.0882 - binary_accuracy: 0.9746 - auc_86: 0.8757 - precision_86: 0.4727 - recall_86: 0.2193\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_86: 0.9308 - precision_86: 0.7411 - recall_86: 0.2734\n","Epoch 3/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_86: 0.9385 - precision_86: 0.7405 - recall_86: 0.2967\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0616 - binary_accuracy: 0.9803 - auc_86: 0.9430 - precision_86: 0.7406 - recall_86: 0.3127\n","Epoch 5/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_86: 0.9464 - precision_86: 0.7412 - recall_86: 0.3273\n","Score for fold 7: F1 score of 0.46523796642337584; loss of 0.05810727924108505; binary_accuracy of 98.09243679046631%\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 23ms/step - loss: 0.0895 - binary_accuracy: 0.9743 - auc_87: 0.8730 - precision_87: 0.4586 - recall_87: 0.2172\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_87: 0.9306 - precision_87: 0.7419 - recall_87: 0.2729\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_87: 0.9383 - precision_87: 0.7400 - recall_87: 0.2960\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0616 - binary_accuracy: 0.9803 - auc_87: 0.9429 - precision_87: 0.7412 - recall_87: 0.3128\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_87: 0.9464 - precision_87: 0.7417 - recall_87: 0.3270\n","Score for fold 8: F1 score of 0.45438892198609804; loss of 0.0583343543112278; binary_accuracy of 98.08291792869568%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.0886 - binary_accuracy: 0.9744 - auc_88: 0.8759 - precision_88: 0.4620 - recall_88: 0.2195\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_88: 0.9310 - precision_88: 0.7425 - recall_88: 0.2739\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_88: 0.9384 - precision_88: 0.7405 - recall_88: 0.2964\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0617 - binary_accuracy: 0.9803 - auc_88: 0.9430 - precision_88: 0.7405 - recall_88: 0.3131\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_88: 0.9463 - precision_88: 0.7417 - recall_88: 0.3274\n","Score for fold 9: F1 score of 0.4655829822651695; loss of 0.058162346482276917; binary_accuracy of 98.08799028396606%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 23ms/step - loss: 0.0893 - binary_accuracy: 0.9743 - auc_89: 0.8739 - precision_89: 0.4603 - recall_89: 0.2176\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0660 - binary_accuracy: 0.9797 - auc_89: 0.9311 - precision_89: 0.7417 - recall_89: 0.2744\n","Epoch 3/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_89: 0.9387 - precision_89: 0.7396 - recall_89: 0.2968\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0616 - binary_accuracy: 0.9803 - auc_89: 0.9430 - precision_89: 0.7415 - recall_89: 0.3124\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_89: 0.9465 - precision_89: 0.7426 - recall_89: 0.3266\n","Score for fold 10: F1 score of 0.4721775846646227; loss of 0.05837935954332352; binary_accuracy of 98.0886459350586%\n","----------------------------------------------------------------------\n","The number of units in each layer is  256\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1088 - binary_accuracy: 0.9638 - auc_90: 0.8318 - precision_90: 0.2274 - recall_90: 0.1943\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0729 - binary_accuracy: 0.9789 - auc_90: 0.9092 - precision_90: 0.7523 - recall_90: 0.2200\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0685 - binary_accuracy: 0.9794 - auc_90: 0.9249 - precision_90: 0.7508 - recall_90: 0.2483\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_90: 0.9316 - precision_90: 0.7485 - recall_90: 0.2671\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_90: 0.9361 - precision_90: 0.7489 - recall_90: 0.2826\n","Score for fold 1: F1 score of 0.4333406379623745; loss of 0.06285965442657471; binary_accuracy of 98.0203926563263%\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 10s 24ms/step - loss: 0.1094 - binary_accuracy: 0.9633 - auc_91: 0.8303 - precision_91: 0.2234 - recall_91: 0.1963\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0730 - binary_accuracy: 0.9789 - auc_91: 0.9088 - precision_91: 0.7495 - recall_91: 0.2199\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0687 - binary_accuracy: 0.9794 - auc_91: 0.9242 - precision_91: 0.7496 - recall_91: 0.2488\n","Epoch 4/5\n","331/331 [==============================] - 8s 25ms/step - loss: 0.0662 - binary_accuracy: 0.9797 - auc_91: 0.9315 - precision_91: 0.7473 - recall_91: 0.2681\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0644 - binary_accuracy: 0.9799 - auc_91: 0.9364 - precision_91: 0.7473 - recall_91: 0.2833\n","Score for fold 2: F1 score of 0.42277958553303396; loss of 0.06269882619380951; binary_accuracy of 98.01638722419739%\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1094 - binary_accuracy: 0.9629 - auc_92: 0.8333 - precision_92: 0.2208 - recall_92: 0.1974\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0723 - binary_accuracy: 0.9790 - auc_92: 0.9116 - precision_92: 0.7491 - recall_92: 0.2238\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0682 - binary_accuracy: 0.9794 - auc_92: 0.9254 - precision_92: 0.7512 - recall_92: 0.2510\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0658 - binary_accuracy: 0.9797 - auc_92: 0.9324 - precision_92: 0.7497 - recall_92: 0.2712\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0641 - binary_accuracy: 0.9800 - auc_92: 0.9370 - precision_92: 0.7469 - recall_92: 0.2868\n","Score for fold 3: F1 score of 0.4431168910858398; loss of 0.06267812103033066; binary_accuracy of 98.01754951477051%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1079 - binary_accuracy: 0.9639 - auc_93: 0.8340 - precision_93: 0.2311 - recall_93: 0.1978\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0725 - binary_accuracy: 0.9789 - auc_93: 0.9108 - precision_93: 0.7517 - recall_93: 0.2218\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0685 - binary_accuracy: 0.9794 - auc_93: 0.9248 - precision_93: 0.7507 - recall_93: 0.2483\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0661 - binary_accuracy: 0.9797 - auc_93: 0.9318 - precision_93: 0.7487 - recall_93: 0.2688\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0643 - binary_accuracy: 0.9799 - auc_93: 0.9363 - precision_93: 0.7479 - recall_93: 0.2843\n","Score for fold 4: F1 score of 0.42503171324541306; loss of 0.06252296268939972; binary_accuracy of 98.02374243736267%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1083 - binary_accuracy: 0.9635 - auc_94: 0.8347 - precision_94: 0.2267 - recall_94: 0.1969\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0730 - binary_accuracy: 0.9789 - auc_94: 0.9095 - precision_94: 0.7481 - recall_94: 0.2192\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0688 - binary_accuracy: 0.9793 - auc_94: 0.9240 - precision_94: 0.7515 - recall_94: 0.2455\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0663 - binary_accuracy: 0.9796 - auc_94: 0.9312 - precision_94: 0.7492 - recall_94: 0.2652\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0646 - binary_accuracy: 0.9799 - auc_94: 0.9358 - precision_94: 0.7464 - recall_94: 0.2811\n","Score for fold 5: F1 score of 0.41217350365832367; loss of 0.06303433328866959; binary_accuracy of 98.0105459690094%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 23ms/step - loss: 0.1087 - binary_accuracy: 0.9634 - auc_95: 0.8344 - precision_95: 0.2257 - recall_95: 0.1968\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0730 - binary_accuracy: 0.9789 - auc_95: 0.9090 - precision_95: 0.7479 - recall_95: 0.2199\n","Epoch 3/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0688 - binary_accuracy: 0.9794 - auc_95: 0.9239 - precision_95: 0.7500 - recall_95: 0.2475\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0664 - binary_accuracy: 0.9796 - auc_95: 0.9310 - precision_95: 0.7474 - recall_95: 0.2665\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0645 - binary_accuracy: 0.9799 - auc_95: 0.9363 - precision_95: 0.7460 - recall_95: 0.2831\n","Score for fold 6: F1 score of 0.4197289414624524; loss of 0.06291572749614716; binary_accuracy of 98.01359176635742%\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 23ms/step - loss: 0.1088 - binary_accuracy: 0.9632 - auc_96: 0.8352 - precision_96: 0.2236 - recall_96: 0.1980\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0721 - binary_accuracy: 0.9790 - auc_96: 0.9124 - precision_96: 0.7495 - recall_96: 0.2250\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0683 - binary_accuracy: 0.9794 - auc_96: 0.9256 - precision_96: 0.7494 - recall_96: 0.2511\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0659 - binary_accuracy: 0.9797 - auc_96: 0.9323 - precision_96: 0.7475 - recall_96: 0.2698\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0642 - binary_accuracy: 0.9799 - auc_96: 0.9370 - precision_96: 0.7464 - recall_96: 0.2853\n","Score for fold 7: F1 score of 0.42158251951757447; loss of 0.06266786903142929; binary_accuracy of 98.01697731018066%\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1083 - binary_accuracy: 0.9635 - auc_97: 0.8349 - precision_97: 0.2271 - recall_97: 0.1979\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0723 - binary_accuracy: 0.9790 - auc_97: 0.9118 - precision_97: 0.7477 - recall_97: 0.2257\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0682 - binary_accuracy: 0.9794 - auc_97: 0.9259 - precision_97: 0.7484 - recall_97: 0.2522\n","Epoch 4/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0658 - binary_accuracy: 0.9797 - auc_97: 0.9327 - precision_97: 0.7471 - recall_97: 0.2714\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0641 - binary_accuracy: 0.9799 - auc_97: 0.9371 - precision_97: 0.7459 - recall_97: 0.2861\n","Score for fold 8: F1 score of 0.4183346838511062; loss of 0.06258835643529892; binary_accuracy of 98.01524877548218%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1078 - binary_accuracy: 0.9640 - auc_98: 0.8349 - precision_98: 0.2298 - recall_98: 0.1941\n","Epoch 2/5\n","331/331 [==============================] - 8s 23ms/step - loss: 0.0728 - binary_accuracy: 0.9789 - auc_98: 0.9103 - precision_98: 0.7513 - recall_98: 0.2195\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0688 - binary_accuracy: 0.9794 - auc_98: 0.9239 - precision_98: 0.7527 - recall_98: 0.2457\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0663 - binary_accuracy: 0.9796 - auc_98: 0.9312 - precision_98: 0.7502 - recall_98: 0.2653\n","Epoch 5/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0644 - binary_accuracy: 0.9799 - auc_98: 0.9362 - precision_98: 0.7486 - recall_98: 0.2818\n","Score for fold 9: F1 score of 0.414229890527099; loss of 0.06267344951629639; binary_accuracy of 98.01506400108337%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 9s 24ms/step - loss: 0.1083 - binary_accuracy: 0.9636 - auc_99: 0.8336 - precision_99: 0.2271 - recall_99: 0.1958\n","Epoch 2/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0722 - binary_accuracy: 0.9790 - auc_99: 0.9126 - precision_99: 0.7492 - recall_99: 0.2237\n","Epoch 3/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0682 - binary_accuracy: 0.9794 - auc_99: 0.9258 - precision_99: 0.7490 - recall_99: 0.2505\n","Epoch 4/5\n","331/331 [==============================] - 8s 24ms/step - loss: 0.0658 - binary_accuracy: 0.9797 - auc_99: 0.9325 - precision_99: 0.7477 - recall_99: 0.2705\n","Epoch 5/5\n","331/331 [==============================] - 8s 26ms/step - loss: 0.0641 - binary_accuracy: 0.9800 - auc_99: 0.9371 - precision_99: 0.7474 - recall_99: 0.2867\n","Score for fold 10: F1 score of 0.42126371129580314; loss of 0.062366366386413574; binary_accuracy of 98.02353382110596%\n","----------------------------------------------------------------------\n","The number of units in each layer is  128\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0967 - binary_accuracy: 0.9721 - auc_100: 0.8615 - precision_100: 0.3837 - recall_100: 0.2102\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0676 - binary_accuracy: 0.9795 - auc_100: 0.9266 - precision_100: 0.7457 - recall_100: 0.2586\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_100: 0.9340 - precision_100: 0.7425 - recall_100: 0.2802\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_100: 0.9385 - precision_100: 0.7416 - recall_100: 0.2931\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_100: 0.9414 - precision_100: 0.7418 - recall_100: 0.3039\n","Score for fold 1: F1 score of 0.43923772563166724; loss of 0.06082543358206749; binary_accuracy of 98.04134368896484%\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0952 - binary_accuracy: 0.9728 - auc_101: 0.8633 - precision_101: 0.4049 - recall_101: 0.2110\n","Epoch 2/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0677 - binary_accuracy: 0.9795 - auc_101: 0.9264 - precision_101: 0.7452 - recall_101: 0.2579\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_101: 0.9342 - precision_101: 0.7435 - recall_101: 0.2788\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_101: 0.9383 - precision_101: 0.7422 - recall_101: 0.2923\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_101: 0.9414 - precision_101: 0.7422 - recall_101: 0.3024\n","Score for fold 2: F1 score of 0.43941806962684266; loss of 0.06099000945687294; binary_accuracy of 98.038649559021%\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0963 - binary_accuracy: 0.9726 - auc_102: 0.8603 - precision_102: 0.3957 - recall_102: 0.2082\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0676 - binary_accuracy: 0.9795 - auc_102: 0.9268 - precision_102: 0.7474 - recall_102: 0.2569\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_102: 0.9345 - precision_102: 0.7446 - recall_102: 0.2787\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_102: 0.9387 - precision_102: 0.7423 - recall_102: 0.2916\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_102: 0.9416 - precision_102: 0.7429 - recall_102: 0.3026\n","Score for fold 3: F1 score of 0.4355506727809541; loss of 0.06082317978143692; binary_accuracy of 98.04084897041321%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0966 - binary_accuracy: 0.9721 - auc_103: 0.8615 - precision_103: 0.3841 - recall_103: 0.2106\n","Epoch 2/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0675 - binary_accuracy: 0.9795 - auc_103: 0.9269 - precision_103: 0.7453 - recall_103: 0.2581\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0649 - binary_accuracy: 0.9798 - auc_103: 0.9347 - precision_103: 0.7425 - recall_103: 0.2806\n","Epoch 4/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_103: 0.9387 - precision_103: 0.7416 - recall_103: 0.2942\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_103: 0.9416 - precision_103: 0.7418 - recall_103: 0.3048\n","Score for fold 4: F1 score of 0.41953481630400236; loss of 0.060969140380620956; binary_accuracy of 98.03442358970642%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0951 - binary_accuracy: 0.9729 - auc_104: 0.8605 - precision_104: 0.4055 - recall_104: 0.2062\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0677 - binary_accuracy: 0.9795 - auc_104: 0.9259 - precision_104: 0.7455 - recall_104: 0.2574\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_104: 0.9342 - precision_104: 0.7433 - recall_104: 0.2800\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_104: 0.9386 - precision_104: 0.7428 - recall_104: 0.2931\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0624 - binary_accuracy: 0.9802 - auc_104: 0.9413 - precision_104: 0.7417 - recall_104: 0.3039\n","Score for fold 5: F1 score of 0.4496529553838492; loss of 0.060839809477329254; binary_accuracy of 98.04167747497559%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0977 - binary_accuracy: 0.9721 - auc_105: 0.8584 - precision_105: 0.3821 - recall_105: 0.2072\n","Epoch 2/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0677 - binary_accuracy: 0.9795 - auc_105: 0.9262 - precision_105: 0.7460 - recall_105: 0.2585\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_105: 0.9344 - precision_105: 0.7425 - recall_105: 0.2805\n","Epoch 4/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0634 - binary_accuracy: 0.9800 - auc_105: 0.9387 - precision_105: 0.7413 - recall_105: 0.2952\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0622 - binary_accuracy: 0.9802 - auc_105: 0.9417 - precision_105: 0.7419 - recall_105: 0.3059\n","Score for fold 6: F1 score of 0.45219611320096353; loss of 0.060890186578035355; binary_accuracy of 98.04534912109375%\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 19ms/step - loss: 0.0957 - binary_accuracy: 0.9726 - auc_106: 0.8626 - precision_106: 0.3963 - recall_106: 0.2095\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0676 - binary_accuracy: 0.9795 - auc_106: 0.9267 - precision_106: 0.7474 - recall_106: 0.2575\n","Epoch 3/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0649 - binary_accuracy: 0.9798 - auc_106: 0.9346 - precision_106: 0.7439 - recall_106: 0.2797\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0633 - binary_accuracy: 0.9800 - auc_106: 0.9390 - precision_106: 0.7427 - recall_106: 0.2938\n","Epoch 5/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0622 - binary_accuracy: 0.9802 - auc_106: 0.9418 - precision_106: 0.7416 - recall_106: 0.3056\n","Score for fold 7: F1 score of 0.4521444604442206; loss of 0.06084524467587471; binary_accuracy of 98.04230332374573%\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0963 - binary_accuracy: 0.9725 - auc_107: 0.8600 - precision_107: 0.3927 - recall_107: 0.2085\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0678 - binary_accuracy: 0.9795 - auc_107: 0.9260 - precision_107: 0.7461 - recall_107: 0.2564\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0651 - binary_accuracy: 0.9798 - auc_107: 0.9341 - precision_107: 0.7427 - recall_107: 0.2798\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_107: 0.9384 - precision_107: 0.7432 - recall_107: 0.2932\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_107: 0.9413 - precision_107: 0.7429 - recall_107: 0.3039\n","Score for fold 8: F1 score of 0.4450475583926157; loss of 0.0609462670981884; binary_accuracy of 98.04283380508423%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0955 - binary_accuracy: 0.9727 - auc_108: 0.8621 - precision_108: 0.3985 - recall_108: 0.2074\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0676 - binary_accuracy: 0.9795 - auc_108: 0.9265 - precision_108: 0.7463 - recall_108: 0.2570\n","Epoch 3/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_108: 0.9341 - precision_108: 0.7439 - recall_108: 0.2795\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_108: 0.9384 - precision_108: 0.7432 - recall_108: 0.2927\n","Epoch 5/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_108: 0.9414 - precision_108: 0.7433 - recall_108: 0.3046\n","Score for fold 9: F1 score of 0.4442142271383254; loss of 0.06082314997911453; binary_accuracy of 98.04091453552246%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.0973 - binary_accuracy: 0.9724 - auc_109: 0.8586 - precision_109: 0.3903 - recall_109: 0.2066\n","Epoch 2/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0677 - binary_accuracy: 0.9795 - auc_109: 0.9262 - precision_109: 0.7478 - recall_109: 0.2562\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0650 - binary_accuracy: 0.9798 - auc_109: 0.9343 - precision_109: 0.7432 - recall_109: 0.2799\n","Epoch 4/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0635 - binary_accuracy: 0.9800 - auc_109: 0.9384 - precision_109: 0.7428 - recall_109: 0.2928\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0623 - binary_accuracy: 0.9802 - auc_109: 0.9414 - precision_109: 0.7423 - recall_109: 0.3035\n","Score for fold 10: F1 score of 0.4527956041335249; loss of 0.060993440449237823; binary_accuracy of 98.04074764251709%\n","----------------------------------------------------------------------\n","The number of units in each layer is  128\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1206 - binary_accuracy: 0.9599 - auc_110: 0.8030 - precision_110: 0.1890 - recall_110: 0.1894\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0810 - binary_accuracy: 0.9782 - auc_110: 0.8698 - precision_110: 0.7251 - recall_110: 0.1898\n","Epoch 3/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0750 - binary_accuracy: 0.9787 - auc_110: 0.9003 - precision_110: 0.7475 - recall_110: 0.2070\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0711 - binary_accuracy: 0.9790 - auc_110: 0.9163 - precision_110: 0.7488 - recall_110: 0.2292\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0685 - binary_accuracy: 0.9794 - auc_110: 0.9251 - precision_110: 0.7507 - recall_110: 0.2491\n","Score for fold 1: F1 score of 0.39249042053790006; loss of 0.06679873913526535; binary_accuracy of 97.95711636543274%\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1210 - binary_accuracy: 0.9599 - auc_111: 0.8010 - precision_111: 0.1889 - recall_111: 0.1888\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0839 - binary_accuracy: 0.9780 - auc_111: 0.8521 - precision_111: 0.7215 - recall_111: 0.1808\n","Epoch 3/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0771 - binary_accuracy: 0.9785 - auc_111: 0.8899 - precision_111: 0.7467 - recall_111: 0.1980\n","Epoch 4/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0721 - binary_accuracy: 0.9790 - auc_111: 0.9124 - precision_111: 0.7501 - recall_111: 0.2247\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0693 - binary_accuracy: 0.9793 - auc_111: 0.9223 - precision_111: 0.7501 - recall_111: 0.2439\n","Score for fold 2: F1 score of 0.39671315012247194; loss of 0.06780631095170975; binary_accuracy of 97.95144200325012%\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1212 - binary_accuracy: 0.9597 - auc_112: 0.8012 - precision_112: 0.1881 - recall_112: 0.1893\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0827 - binary_accuracy: 0.9781 - auc_112: 0.8610 - precision_112: 0.7214 - recall_112: 0.1831\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0760 - binary_accuracy: 0.9786 - auc_112: 0.8954 - precision_112: 0.7513 - recall_112: 0.2023\n","Epoch 4/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0718 - binary_accuracy: 0.9790 - auc_112: 0.9136 - precision_112: 0.7528 - recall_112: 0.2272\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0691 - binary_accuracy: 0.9794 - auc_112: 0.9229 - precision_112: 0.7544 - recall_112: 0.2450\n","Score for fold 3: F1 score of 0.37111565560999255; loss of 0.06747188419103622; binary_accuracy of 97.95418381690979%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1217 - binary_accuracy: 0.9595 - auc_113: 0.8003 - precision_113: 0.1862 - recall_113: 0.1888\n","Epoch 2/5\n","331/331 [==============================] - 6s 19ms/step - loss: 0.0830 - binary_accuracy: 0.9781 - auc_113: 0.8577 - precision_113: 0.7243 - recall_113: 0.1826\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0768 - binary_accuracy: 0.9785 - auc_113: 0.8919 - precision_113: 0.7436 - recall_113: 0.2009\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0717 - binary_accuracy: 0.9790 - auc_113: 0.9137 - precision_113: 0.7527 - recall_113: 0.2269\n","Epoch 5/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0687 - binary_accuracy: 0.9794 - auc_113: 0.9242 - precision_113: 0.7531 - recall_113: 0.2466\n","Score for fold 4: F1 score of 0.37480236740401884; loss of 0.0669688805937767; binary_accuracy of 97.95863032341003%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1202 - binary_accuracy: 0.9602 - auc_114: 0.8036 - precision_114: 0.1912 - recall_114: 0.1888\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0797 - binary_accuracy: 0.9783 - auc_114: 0.8764 - precision_114: 0.7364 - recall_114: 0.1899\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0741 - binary_accuracy: 0.9788 - auc_114: 0.9038 - precision_114: 0.7475 - recall_114: 0.2126\n","Epoch 4/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0705 - binary_accuracy: 0.9791 - auc_114: 0.9181 - precision_114: 0.7503 - recall_114: 0.2345\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0680 - binary_accuracy: 0.9795 - auc_114: 0.9264 - precision_114: 0.7513 - recall_114: 0.2526\n","Score for fold 5: F1 score of 0.38486885315677766; loss of 0.06635105609893799; binary_accuracy of 97.96285629272461%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1214 - binary_accuracy: 0.9594 - auc_115: 0.8009 - precision_115: 0.1850 - recall_115: 0.1887\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0833 - binary_accuracy: 0.9780 - auc_115: 0.8559 - precision_115: 0.7243 - recall_115: 0.1812\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0762 - binary_accuracy: 0.9786 - auc_115: 0.8942 - precision_115: 0.7522 - recall_115: 0.1996\n","Epoch 4/5\n","331/331 [==============================] - 6s 20ms/step - loss: 0.0719 - binary_accuracy: 0.9790 - auc_115: 0.9132 - precision_115: 0.7511 - recall_115: 0.2250\n","Epoch 5/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0690 - binary_accuracy: 0.9793 - auc_115: 0.9233 - precision_115: 0.7526 - recall_115: 0.2439\n","Score for fold 6: F1 score of 0.375382631175928; loss of 0.06726813316345215; binary_accuracy of 97.9518473148346%\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1206 - binary_accuracy: 0.9597 - auc_116: 0.8033 - precision_116: 0.1881 - recall_116: 0.1894\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0796 - binary_accuracy: 0.9783 - auc_116: 0.8758 - precision_116: 0.7334 - recall_116: 0.1931\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0739 - binary_accuracy: 0.9788 - auc_116: 0.9044 - precision_116: 0.7511 - recall_116: 0.2135\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0704 - binary_accuracy: 0.9792 - auc_116: 0.9186 - precision_116: 0.7506 - recall_116: 0.2376\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0679 - binary_accuracy: 0.9795 - auc_116: 0.9265 - precision_116: 0.7516 - recall_116: 0.2538\n","Score for fold 7: F1 score of 0.40311569320801777; loss of 0.06636523455381393; binary_accuracy of 97.9699969291687%\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1206 - binary_accuracy: 0.9603 - auc_117: 0.8014 - precision_117: 0.1918 - recall_117: 0.1881\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0820 - binary_accuracy: 0.9781 - auc_117: 0.8629 - precision_117: 0.7265 - recall_117: 0.1855\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0750 - binary_accuracy: 0.9787 - auc_117: 0.8996 - precision_117: 0.7525 - recall_117: 0.2076\n","Epoch 4/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0712 - binary_accuracy: 0.9791 - auc_117: 0.9158 - precision_117: 0.7496 - recall_117: 0.2302\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0686 - binary_accuracy: 0.9794 - auc_117: 0.9245 - precision_117: 0.7521 - recall_117: 0.2476\n","Score for fold 8: F1 score of 0.3868934999182013; loss of 0.06696692109107971; binary_accuracy of 97.96034097671509%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 21ms/step - loss: 0.1211 - binary_accuracy: 0.9596 - auc_118: 0.8030 - precision_118: 0.1875 - recall_118: 0.1897\n","Epoch 2/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0820 - binary_accuracy: 0.9781 - auc_118: 0.8649 - precision_118: 0.7242 - recall_118: 0.1839\n","Epoch 3/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0773 - binary_accuracy: 0.9785 - auc_118: 0.8892 - precision_118: 0.7490 - recall_118: 0.1944\n","Epoch 4/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0733 - binary_accuracy: 0.9788 - auc_118: 0.9077 - precision_118: 0.7484 - recall_118: 0.2162\n","Epoch 5/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0703 - binary_accuracy: 0.9792 - auc_118: 0.9195 - precision_118: 0.7516 - recall_118: 0.2354\n","Score for fold 9: F1 score of 0.36485054475745515; loss of 0.06846683472394943; binary_accuracy of 97.94018268585205%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 8s 20ms/step - loss: 0.1212 - binary_accuracy: 0.9592 - auc_119: 0.8039 - precision_119: 0.1850 - recall_119: 0.1905\n","Epoch 2/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0800 - binary_accuracy: 0.9782 - auc_119: 0.8753 - precision_119: 0.7294 - recall_119: 0.1909\n","Epoch 3/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0747 - binary_accuracy: 0.9787 - auc_119: 0.9014 - precision_119: 0.7506 - recall_119: 0.2080\n","Epoch 4/5\n","331/331 [==============================] - 7s 21ms/step - loss: 0.0710 - binary_accuracy: 0.9791 - auc_119: 0.9165 - precision_119: 0.7498 - recall_119: 0.2323\n","Epoch 5/5\n","331/331 [==============================] - 7s 20ms/step - loss: 0.0685 - binary_accuracy: 0.9794 - auc_119: 0.9251 - precision_119: 0.7529 - recall_119: 0.2492\n","Score for fold 10: F1 score of 0.39701970319776375; loss of 0.0669730007648468; binary_accuracy of 97.96096682548523%\n","=======================================================================\n","Training for Molecular Function\n","----------------------------------------------------------------------\n","The number of units in each layer is  512\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 10s 39ms/step - loss: 0.1059 - binary_accuracy: 0.9684 - auc_120: 0.8679 - precision_120: 0.4655 - recall_120: 0.2104\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_120: 0.9308 - precision_120: 0.7142 - recall_120: 0.2938\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0747 - binary_accuracy: 0.9754 - auc_120: 0.9397 - precision_120: 0.7188 - recall_120: 0.3280\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_120: 0.9452 - precision_120: 0.7250 - recall_120: 0.3528\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0696 - binary_accuracy: 0.9766 - auc_120: 0.9495 - precision_120: 0.7319 - recall_120: 0.3735\n","Score for fold 1: F1 score of 0.5197358098283856; loss of 0.0667094737291336; binary_accuracy of 97.73042798042297%\n","Current best model for Molecular Function has 512 units in each layer, uses relu activation function and has an F1 score of 0.5197358098283856\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1057 - binary_accuracy: 0.9684 - auc_121: 0.8685 - precision_121: 0.4676 - recall_121: 0.2118\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0784 - binary_accuracy: 0.9748 - auc_121: 0.9313 - precision_121: 0.7152 - recall_121: 0.2958\n","Epoch 3/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0745 - binary_accuracy: 0.9755 - auc_121: 0.9399 - precision_121: 0.7204 - recall_121: 0.3295\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0717 - binary_accuracy: 0.9760 - auc_121: 0.9455 - precision_121: 0.7250 - recall_121: 0.3533\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0695 - binary_accuracy: 0.9766 - auc_121: 0.9496 - precision_121: 0.7318 - recall_121: 0.3734\n","Score for fold 2: F1 score of 0.5239871438568484; loss of 0.0669151172041893; binary_accuracy of 97.72679209709167%\n","Current best model for Molecular Function has 512 units in each layer, uses relu activation function and has an F1 score of 0.5239871438568484\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1054 - binary_accuracy: 0.9683 - auc_122: 0.8692 - precision_122: 0.4652 - recall_122: 0.2132\n","Epoch 2/5\n","218/218 [==============================] - 8s 38ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_122: 0.9308 - precision_122: 0.7135 - recall_122: 0.2944\n","Epoch 3/5\n","218/218 [==============================] - 9s 41ms/step - loss: 0.0746 - binary_accuracy: 0.9755 - auc_122: 0.9398 - precision_122: 0.7195 - recall_122: 0.3281\n","Epoch 4/5\n","218/218 [==============================] - 9s 43ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_122: 0.9453 - precision_122: 0.7253 - recall_122: 0.3526\n","Epoch 5/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0696 - binary_accuracy: 0.9765 - auc_122: 0.9493 - precision_122: 0.7307 - recall_122: 0.3734\n","Score for fold 3: F1 score of 0.5020790160986116; loss of 0.06661906838417053; binary_accuracy of 97.71642088890076%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1064 - binary_accuracy: 0.9683 - auc_123: 0.8663 - precision_123: 0.4639 - recall_123: 0.2085\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_123: 0.9307 - precision_123: 0.7141 - recall_123: 0.2942\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0747 - binary_accuracy: 0.9755 - auc_123: 0.9395 - precision_123: 0.7204 - recall_123: 0.3277\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_123: 0.9451 - precision_123: 0.7253 - recall_123: 0.3521\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0697 - binary_accuracy: 0.9766 - auc_123: 0.9493 - precision_123: 0.7306 - recall_123: 0.3736\n","Score for fold 4: F1 score of 0.5173186775907451; loss of 0.06728313863277435; binary_accuracy of 97.71397113800049%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1058 - binary_accuracy: 0.9683 - auc_124: 0.8682 - precision_124: 0.4650 - recall_124: 0.2107\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_124: 0.9309 - precision_124: 0.7133 - recall_124: 0.2941\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0746 - binary_accuracy: 0.9755 - auc_124: 0.9398 - precision_124: 0.7196 - recall_124: 0.3284\n","Epoch 4/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_124: 0.9453 - precision_124: 0.7250 - recall_124: 0.3518\n","Epoch 5/5\n","218/218 [==============================] - 8s 34ms/step - loss: 0.0696 - binary_accuracy: 0.9765 - auc_124: 0.9494 - precision_124: 0.7317 - recall_124: 0.3722\n","Score for fold 5: F1 score of 0.510455444278559; loss of 0.06680326163768768; binary_accuracy of 97.7143943309784%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1062 - binary_accuracy: 0.9683 - auc_125: 0.8666 - precision_125: 0.4625 - recall_125: 0.2074\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0790 - binary_accuracy: 0.9747 - auc_125: 0.9302 - precision_125: 0.7141 - recall_125: 0.2915\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0748 - binary_accuracy: 0.9754 - auc_125: 0.9394 - precision_125: 0.7195 - recall_125: 0.3271\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0721 - binary_accuracy: 0.9760 - auc_125: 0.9447 - precision_125: 0.7232 - recall_125: 0.3509\n","Epoch 5/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0697 - binary_accuracy: 0.9765 - auc_125: 0.9493 - precision_125: 0.7303 - recall_125: 0.3716\n","Score for fold 6: F1 score of 0.5180118349939443; loss of 0.06670457869768143; binary_accuracy of 97.72995114326477%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1056 - binary_accuracy: 0.9685 - auc_126: 0.8681 - precision_126: 0.4692 - recall_126: 0.2111\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0788 - binary_accuracy: 0.9747 - auc_126: 0.9306 - precision_126: 0.7138 - recall_126: 0.2937\n","Epoch 3/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0746 - binary_accuracy: 0.9755 - auc_126: 0.9398 - precision_126: 0.7199 - recall_126: 0.3283\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_126: 0.9452 - precision_126: 0.7253 - recall_126: 0.3529\n","Epoch 5/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0696 - binary_accuracy: 0.9766 - auc_126: 0.9495 - precision_126: 0.7308 - recall_126: 0.3735\n","Score for fold 7: F1 score of 0.5065742311949893; loss of 0.06656230986118317; binary_accuracy of 97.71862626075745%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1063 - binary_accuracy: 0.9683 - auc_127: 0.8671 - precision_127: 0.4635 - recall_127: 0.2092\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0788 - binary_accuracy: 0.9747 - auc_127: 0.9306 - precision_127: 0.7143 - recall_127: 0.2920\n","Epoch 3/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0748 - binary_accuracy: 0.9754 - auc_127: 0.9396 - precision_127: 0.7191 - recall_127: 0.3262\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_127: 0.9449 - precision_127: 0.7256 - recall_127: 0.3512\n","Epoch 5/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0696 - binary_accuracy: 0.9765 - auc_127: 0.9494 - precision_127: 0.7312 - recall_127: 0.3725\n","Score for fold 8: F1 score of 0.5203128805541896; loss of 0.06679019331932068; binary_accuracy of 97.71279096603394%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1067 - binary_accuracy: 0.9682 - auc_128: 0.8664 - precision_128: 0.4607 - recall_128: 0.2101\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0788 - binary_accuracy: 0.9747 - auc_128: 0.9306 - precision_128: 0.7136 - recall_128: 0.2929\n","Epoch 3/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0746 - binary_accuracy: 0.9755 - auc_128: 0.9397 - precision_128: 0.7204 - recall_128: 0.3282\n","Epoch 4/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_128: 0.9449 - precision_128: 0.7247 - recall_128: 0.3524\n","Epoch 5/5\n","218/218 [==============================] - 8s 34ms/step - loss: 0.0696 - binary_accuracy: 0.9766 - auc_128: 0.9493 - precision_128: 0.7315 - recall_128: 0.3733\n","Score for fold 9: F1 score of 0.5048409579662416; loss of 0.0666474923491478; binary_accuracy of 97.72165417671204%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1062 - binary_accuracy: 0.9683 - auc_129: 0.8668 - precision_129: 0.4622 - recall_129: 0.2073\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_129: 0.9308 - precision_129: 0.7127 - recall_129: 0.2938\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0747 - binary_accuracy: 0.9755 - auc_129: 0.9396 - precision_129: 0.7195 - recall_129: 0.3285\n","Epoch 4/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_129: 0.9449 - precision_129: 0.7243 - recall_129: 0.3516\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0696 - binary_accuracy: 0.9765 - auc_129: 0.9494 - precision_129: 0.7312 - recall_129: 0.3728\n","Score for fold 10: F1 score of 0.5106642715545021; loss of 0.06654771417379379; binary_accuracy of 97.7192759513855%\n","----------------------------------------------------------------------\n","The number of units in each layer is  512\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1254 - binary_accuracy: 0.9553 - auc_130: 0.8446 - precision_130: 0.2395 - recall_130: 0.2095\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0823 - binary_accuracy: 0.9741 - auc_130: 0.9230 - precision_130: 0.7128 - recall_130: 0.2616\n","Epoch 3/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0783 - binary_accuracy: 0.9748 - auc_130: 0.9324 - precision_130: 0.7154 - recall_130: 0.2944\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0756 - binary_accuracy: 0.9753 - auc_130: 0.9381 - precision_130: 0.7195 - recall_130: 0.3178\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0735 - binary_accuracy: 0.9757 - auc_130: 0.9423 - precision_130: 0.7226 - recall_130: 0.3371\n","Score for fold 1: F1 score of 0.4745032357434925; loss of 0.0712532252073288; binary_accuracy of 97.61385917663574%\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 35ms/step - loss: 0.1245 - binary_accuracy: 0.9557 - auc_131: 0.8487 - precision_131: 0.2460 - recall_131: 0.2152\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0818 - binary_accuracy: 0.9742 - auc_131: 0.9242 - precision_131: 0.7102 - recall_131: 0.2669\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0780 - binary_accuracy: 0.9748 - auc_131: 0.9330 - precision_131: 0.7144 - recall_131: 0.2977\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0753 - binary_accuracy: 0.9753 - auc_131: 0.9386 - precision_131: 0.7190 - recall_131: 0.3204\n","Epoch 5/5\n","218/218 [==============================] - 8s 34ms/step - loss: 0.0733 - binary_accuracy: 0.9757 - auc_131: 0.9426 - precision_131: 0.7232 - recall_131: 0.3387\n","Score for fold 2: F1 score of 0.4841038807929022; loss of 0.07099927216768265; binary_accuracy of 97.62150645256042%\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1262 - binary_accuracy: 0.9549 - auc_132: 0.8465 - precision_132: 0.2383 - recall_132: 0.2145\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0824 - binary_accuracy: 0.9741 - auc_132: 0.9226 - precision_132: 0.7099 - recall_132: 0.2621\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0785 - binary_accuracy: 0.9747 - auc_132: 0.9318 - precision_132: 0.7149 - recall_132: 0.2922\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0760 - binary_accuracy: 0.9752 - auc_132: 0.9373 - precision_132: 0.7182 - recall_132: 0.3136\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0739 - binary_accuracy: 0.9756 - auc_132: 0.9415 - precision_132: 0.7213 - recall_132: 0.3328\n","Score for fold 3: F1 score of 0.4774764263116796; loss of 0.07169587910175323; binary_accuracy of 97.60404825210571%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1254 - binary_accuracy: 0.9552 - auc_133: 0.8457 - precision_133: 0.2391 - recall_133: 0.2108\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0824 - binary_accuracy: 0.9741 - auc_133: 0.9228 - precision_133: 0.7110 - recall_133: 0.2618\n","Epoch 3/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0784 - binary_accuracy: 0.9747 - auc_133: 0.9322 - precision_133: 0.7150 - recall_133: 0.2927\n","Epoch 4/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0758 - binary_accuracy: 0.9752 - auc_133: 0.9377 - precision_133: 0.7175 - recall_133: 0.3166\n","Epoch 5/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0736 - binary_accuracy: 0.9757 - auc_133: 0.9420 - precision_133: 0.7228 - recall_133: 0.3361\n","Score for fold 4: F1 score of 0.45262094284358084; loss of 0.07141774892807007; binary_accuracy of 97.60376214981079%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 14s 36ms/step - loss: 0.1258 - binary_accuracy: 0.9553 - auc_134: 0.8450 - precision_134: 0.2419 - recall_134: 0.2134\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0824 - binary_accuracy: 0.9741 - auc_134: 0.9228 - precision_134: 0.7117 - recall_134: 0.2619\n","Epoch 3/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0784 - binary_accuracy: 0.9747 - auc_134: 0.9322 - precision_134: 0.7158 - recall_134: 0.2929\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0758 - binary_accuracy: 0.9752 - auc_134: 0.9376 - precision_134: 0.7195 - recall_134: 0.3153\n","Epoch 5/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0736 - binary_accuracy: 0.9757 - auc_134: 0.9420 - precision_134: 0.7229 - recall_134: 0.3353\n","Score for fold 5: F1 score of 0.48015685646945777; loss of 0.07168648391962051; binary_accuracy of 97.60645627975464%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 10s 36ms/step - loss: 0.1247 - binary_accuracy: 0.9559 - auc_135: 0.8470 - precision_135: 0.2466 - recall_135: 0.2126\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0823 - binary_accuracy: 0.9741 - auc_135: 0.9229 - precision_135: 0.7102 - recall_135: 0.2622\n","Epoch 3/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0783 - binary_accuracy: 0.9748 - auc_135: 0.9322 - precision_135: 0.7158 - recall_135: 0.2941\n","Epoch 4/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0756 - binary_accuracy: 0.9753 - auc_135: 0.9379 - precision_135: 0.7207 - recall_135: 0.3164\n","Epoch 5/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0735 - binary_accuracy: 0.9757 - auc_135: 0.9421 - precision_135: 0.7238 - recall_135: 0.3369\n","Score for fold 6: F1 score of 0.4836655434195016; loss of 0.07119869440793991; binary_accuracy of 97.61927127838135%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 36ms/step - loss: 0.1254 - binary_accuracy: 0.9550 - auc_136: 0.8490 - precision_136: 0.2412 - recall_136: 0.2174\n","Epoch 2/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0814 - binary_accuracy: 0.9742 - auc_136: 0.9251 - precision_136: 0.7103 - recall_136: 0.2704\n","Epoch 3/5\n","218/218 [==============================] - 8s 37ms/step - loss: 0.0775 - binary_accuracy: 0.9749 - auc_136: 0.9341 - precision_136: 0.7159 - recall_136: 0.3016\n","Epoch 4/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0764 - binary_accuracy: 0.9750 - auc_136: 0.9373 - precision_136: 0.7065 - recall_136: 0.3174\n","Epoch 5/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0736 - binary_accuracy: 0.9756 - auc_136: 0.9420 - precision_136: 0.7206 - recall_136: 0.3363\n","Score for fold 7: F1 score of 0.4868658317727555; loss of 0.07143033295869827; binary_accuracy of 97.61311411857605%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 10s 37ms/step - loss: 0.1264 - binary_accuracy: 0.9549 - auc_137: 0.8448 - precision_137: 0.2371 - recall_137: 0.2124\n","Epoch 2/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0822 - binary_accuracy: 0.9741 - auc_137: 0.9232 - precision_137: 0.7128 - recall_137: 0.2616\n","Epoch 3/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0783 - binary_accuracy: 0.9747 - auc_137: 0.9323 - precision_137: 0.7153 - recall_137: 0.2942\n","Epoch 4/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0756 - binary_accuracy: 0.9753 - auc_137: 0.9380 - precision_137: 0.7194 - recall_137: 0.3177\n","Epoch 5/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0735 - binary_accuracy: 0.9757 - auc_137: 0.9424 - precision_137: 0.7229 - recall_137: 0.3370\n","Score for fold 8: F1 score of 0.4761590585468448; loss of 0.07135927677154541; binary_accuracy of 97.61342406272888%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 10s 37ms/step - loss: 0.1266 - binary_accuracy: 0.9547 - auc_138: 0.8438 - precision_138: 0.2343 - recall_138: 0.2106\n","Epoch 2/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0824 - binary_accuracy: 0.9741 - auc_138: 0.9226 - precision_138: 0.7109 - recall_138: 0.2625\n","Epoch 3/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0783 - binary_accuracy: 0.9748 - auc_138: 0.9323 - precision_138: 0.7159 - recall_138: 0.2944\n","Epoch 4/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0757 - binary_accuracy: 0.9752 - auc_138: 0.9378 - precision_138: 0.7192 - recall_138: 0.3172\n","Epoch 5/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0737 - binary_accuracy: 0.9756 - auc_138: 0.9419 - precision_138: 0.7200 - recall_138: 0.3361\n","Score for fold 9: F1 score of 0.4594869178615536; loss of 0.0736941546201706; binary_accuracy of 97.53777384757996%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 36ms/step - loss: 0.1257 - binary_accuracy: 0.9552 - auc_139: 0.8468 - precision_139: 0.2405 - recall_139: 0.2130\n","Epoch 2/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0823 - binary_accuracy: 0.9741 - auc_139: 0.9230 - precision_139: 0.7104 - recall_139: 0.2643\n","Epoch 3/5\n","218/218 [==============================] - 8s 35ms/step - loss: 0.0782 - binary_accuracy: 0.9748 - auc_139: 0.9324 - precision_139: 0.7157 - recall_139: 0.2956\n","Epoch 4/5\n","218/218 [==============================] - 8s 37ms/step - loss: 0.0755 - binary_accuracy: 0.9753 - auc_139: 0.9381 - precision_139: 0.7197 - recall_139: 0.3193\n","Epoch 5/5\n","218/218 [==============================] - 8s 36ms/step - loss: 0.0734 - binary_accuracy: 0.9757 - auc_139: 0.9424 - precision_139: 0.7214 - recall_139: 0.3391\n","Score for fold 10: F1 score of 0.46998238084124555; loss of 0.07176689803600311; binary_accuracy of 97.60750532150269%\n","----------------------------------------------------------------------\n","The number of units in each layer is  256\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 25ms/step - loss: 0.1140 - binary_accuracy: 0.9660 - auc_140: 0.8528 - precision_140: 0.3937 - recall_140: 0.1983\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0802 - binary_accuracy: 0.9744 - auc_140: 0.9273 - precision_140: 0.7128 - recall_140: 0.2793\n","Epoch 3/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_140: 0.9365 - precision_140: 0.7180 - recall_140: 0.3103\n","Epoch 4/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0738 - binary_accuracy: 0.9756 - auc_140: 0.9416 - precision_140: 0.7218 - recall_140: 0.3334\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_140: 0.9454 - precision_140: 0.7254 - recall_140: 0.3507\n","Score for fold 1: F1 score of 0.47186498514222097; loss of 0.06954342126846313; binary_accuracy of 97.64431118965149%\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 25ms/step - loss: 0.1136 - binary_accuracy: 0.9661 - auc_141: 0.8541 - precision_141: 0.3964 - recall_141: 0.1987\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0804 - binary_accuracy: 0.9744 - auc_141: 0.9269 - precision_141: 0.7125 - recall_141: 0.2781\n","Epoch 3/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0764 - binary_accuracy: 0.9751 - auc_141: 0.9365 - precision_141: 0.7171 - recall_141: 0.3108\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0739 - binary_accuracy: 0.9756 - auc_141: 0.9415 - precision_141: 0.7228 - recall_141: 0.3322\n","Epoch 5/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_141: 0.9452 - precision_141: 0.7262 - recall_141: 0.3495\n","Score for fold 2: F1 score of 0.4792177175943525; loss of 0.06965861469507217; binary_accuracy of 97.64578342437744%\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1143 - binary_accuracy: 0.9660 - auc_142: 0.8530 - precision_142: 0.3919 - recall_142: 0.1978\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0804 - binary_accuracy: 0.9744 - auc_142: 0.9270 - precision_142: 0.7118 - recall_142: 0.2782\n","Epoch 3/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0764 - binary_accuracy: 0.9751 - auc_142: 0.9363 - precision_142: 0.7170 - recall_142: 0.3098\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0739 - binary_accuracy: 0.9756 - auc_142: 0.9416 - precision_142: 0.7219 - recall_142: 0.3316\n","Epoch 5/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_142: 0.9454 - precision_142: 0.7254 - recall_142: 0.3494\n","Score for fold 3: F1 score of 0.48973680740920383; loss of 0.06957840174436569; binary_accuracy of 97.6533591747284%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1139 - binary_accuracy: 0.9661 - auc_143: 0.8536 - precision_143: 0.3972 - recall_143: 0.2006\n","Epoch 2/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0801 - binary_accuracy: 0.9744 - auc_143: 0.9277 - precision_143: 0.7120 - recall_143: 0.2807\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0762 - binary_accuracy: 0.9751 - auc_143: 0.9367 - precision_143: 0.7174 - recall_143: 0.3111\n","Epoch 4/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0738 - binary_accuracy: 0.9756 - auc_143: 0.9418 - precision_143: 0.7217 - recall_143: 0.3332\n","Epoch 5/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_143: 0.9455 - precision_143: 0.7257 - recall_143: 0.3501\n","Score for fold 4: F1 score of 0.4717558056359172; loss of 0.0699697807431221; binary_accuracy of 97.63293266296387%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 25ms/step - loss: 0.1129 - binary_accuracy: 0.9664 - auc_144: 0.8541 - precision_144: 0.4033 - recall_144: 0.1958\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0805 - binary_accuracy: 0.9744 - auc_144: 0.9266 - precision_144: 0.7120 - recall_144: 0.2784\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0764 - binary_accuracy: 0.9751 - auc_144: 0.9363 - precision_144: 0.7173 - recall_144: 0.3109\n","Epoch 4/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0740 - binary_accuracy: 0.9756 - auc_144: 0.9414 - precision_144: 0.7212 - recall_144: 0.3319\n","Epoch 5/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_144: 0.9451 - precision_144: 0.7255 - recall_144: 0.3497\n","Score for fold 5: F1 score of 0.5005492351245242; loss of 0.06968759000301361; binary_accuracy of 97.6517915725708%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 25ms/step - loss: 0.1139 - binary_accuracy: 0.9662 - auc_145: 0.8528 - precision_145: 0.3994 - recall_145: 0.1990\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0802 - binary_accuracy: 0.9744 - auc_145: 0.9276 - precision_145: 0.7125 - recall_145: 0.2804\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0762 - binary_accuracy: 0.9751 - auc_145: 0.9366 - precision_145: 0.7177 - recall_145: 0.3124\n","Epoch 4/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0736 - binary_accuracy: 0.9757 - auc_145: 0.9420 - precision_145: 0.7237 - recall_145: 0.3354\n","Epoch 5/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0717 - binary_accuracy: 0.9761 - auc_145: 0.9457 - precision_145: 0.7270 - recall_145: 0.3519\n","Score for fold 6: F1 score of 0.4901478462896938; loss of 0.06954921782016754; binary_accuracy of 97.6522445678711%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 10s 36ms/step - loss: 0.1133 - binary_accuracy: 0.9661 - auc_146: 0.8545 - precision_146: 0.3969 - recall_146: 0.1994\n","Epoch 2/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0803 - binary_accuracy: 0.9744 - auc_146: 0.9273 - precision_146: 0.7129 - recall_146: 0.2793\n","Epoch 3/5\n","218/218 [==============================] - 6s 29ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_146: 0.9365 - precision_146: 0.7169 - recall_146: 0.3104\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0739 - binary_accuracy: 0.9756 - auc_146: 0.9414 - precision_146: 0.7209 - recall_146: 0.3317\n","Epoch 5/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_146: 0.9454 - precision_146: 0.7265 - recall_146: 0.3492\n","Score for fold 7: F1 score of 0.4915512444705333; loss of 0.06975797563791275; binary_accuracy of 97.64660000801086%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 25ms/step - loss: 0.1138 - binary_accuracy: 0.9661 - auc_147: 0.8533 - precision_147: 0.3961 - recall_147: 0.2000\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0802 - binary_accuracy: 0.9745 - auc_147: 0.9275 - precision_147: 0.7127 - recall_147: 0.2806\n","Epoch 3/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0762 - binary_accuracy: 0.9751 - auc_147: 0.9366 - precision_147: 0.7179 - recall_147: 0.3123\n","Epoch 4/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0737 - binary_accuracy: 0.9757 - auc_147: 0.9420 - precision_147: 0.7226 - recall_147: 0.3352\n","Epoch 5/5\n","218/218 [==============================] - 5s 25ms/step - loss: 0.0718 - binary_accuracy: 0.9760 - auc_147: 0.9455 - precision_147: 0.7267 - recall_147: 0.3512\n","Score for fold 8: F1 score of 0.4874581068963081; loss of 0.0693216398358345; binary_accuracy of 97.657310962677%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1132 - binary_accuracy: 0.9664 - auc_148: 0.8538 - precision_148: 0.4026 - recall_148: 0.1966\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0802 - binary_accuracy: 0.9744 - auc_148: 0.9275 - precision_148: 0.7127 - recall_148: 0.2789\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_148: 0.9366 - precision_148: 0.7171 - recall_148: 0.3114\n","Epoch 4/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0739 - binary_accuracy: 0.9756 - auc_148: 0.9415 - precision_148: 0.7214 - recall_148: 0.3326\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_148: 0.9453 - precision_148: 0.7255 - recall_148: 0.3497\n","Score for fold 9: F1 score of 0.4675310865380881; loss of 0.0697697326540947; binary_accuracy of 97.6411759853363%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 27ms/step - loss: 0.1129 - binary_accuracy: 0.9661 - auc_149: 0.8554 - precision_149: 0.3974 - recall_149: 0.2002\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0802 - binary_accuracy: 0.9744 - auc_149: 0.9276 - precision_149: 0.7133 - recall_149: 0.2790\n","Epoch 3/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_149: 0.9364 - precision_149: 0.7164 - recall_149: 0.3118\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0738 - binary_accuracy: 0.9756 - auc_149: 0.9417 - precision_149: 0.7223 - recall_149: 0.3329\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_149: 0.9453 - precision_149: 0.7260 - recall_149: 0.3510\n","Score for fold 10: F1 score of 0.4733571297927457; loss of 0.06953196227550507; binary_accuracy of 97.64827489852905%\n","----------------------------------------------------------------------\n","The number of units in each layer is  256\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1393 - binary_accuracy: 0.9506 - auc_150: 0.8085 - precision_150: 0.1768 - recall_150: 0.1669\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0895 - binary_accuracy: 0.9732 - auc_150: 0.9015 - precision_150: 0.7115 - recall_150: 0.2108\n","Epoch 3/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0840 - binary_accuracy: 0.9739 - auc_150: 0.9190 - precision_150: 0.7135 - recall_150: 0.2488\n","Epoch 4/5\n","218/218 [==============================] - 6s 28ms/step - loss: 0.0808 - binary_accuracy: 0.9743 - auc_150: 0.9271 - precision_150: 0.7159 - recall_150: 0.2711\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0784 - binary_accuracy: 0.9747 - auc_150: 0.9327 - precision_150: 0.7204 - recall_150: 0.2886\n","Score for fold 1: F1 score of 0.42123525051995303; loss of 0.07642455399036407; binary_accuracy of 97.50993847846985%\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1397 - binary_accuracy: 0.9497 - auc_151: 0.8132 - precision_151: 0.1782 - recall_151: 0.1770\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0879 - binary_accuracy: 0.9734 - auc_151: 0.9069 - precision_151: 0.7128 - recall_151: 0.2205\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0830 - binary_accuracy: 0.9740 - auc_151: 0.9216 - precision_151: 0.7151 - recall_151: 0.2555\n","Epoch 4/5\n","218/218 [==============================] - 6s 28ms/step - loss: 0.0799 - binary_accuracy: 0.9745 - auc_151: 0.9292 - precision_151: 0.7176 - recall_151: 0.2778\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0776 - binary_accuracy: 0.9748 - auc_151: 0.9343 - precision_151: 0.7187 - recall_151: 0.2958\n","Score for fold 2: F1 score of 0.42935088497470714; loss of 0.07607413083314896; binary_accuracy of 97.51395583152771%\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 27ms/step - loss: 0.1404 - binary_accuracy: 0.9491 - auc_152: 0.8099 - precision_152: 0.1738 - recall_152: 0.1754\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0883 - binary_accuracy: 0.9733 - auc_152: 0.9053 - precision_152: 0.7124 - recall_152: 0.2196\n","Epoch 3/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0834 - binary_accuracy: 0.9740 - auc_152: 0.9204 - precision_152: 0.7147 - recall_152: 0.2530\n","Epoch 4/5\n","218/218 [==============================] - 6s 28ms/step - loss: 0.0804 - binary_accuracy: 0.9744 - auc_152: 0.9280 - precision_152: 0.7166 - recall_152: 0.2751\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0781 - binary_accuracy: 0.9748 - auc_152: 0.9332 - precision_152: 0.7197 - recall_152: 0.2920\n","Score for fold 3: F1 score of 0.4360850224552854; loss of 0.07616955786943436; binary_accuracy of 97.51787781715393%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 27ms/step - loss: 0.1388 - binary_accuracy: 0.9507 - auc_153: 0.8103 - precision_153: 0.1815 - recall_153: 0.1730\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0890 - binary_accuracy: 0.9732 - auc_153: 0.9038 - precision_153: 0.7092 - recall_153: 0.2147\n","Epoch 3/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0837 - binary_accuracy: 0.9739 - auc_153: 0.9197 - precision_153: 0.7152 - recall_153: 0.2496\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0806 - binary_accuracy: 0.9744 - auc_153: 0.9277 - precision_153: 0.7165 - recall_153: 0.2725\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0783 - binary_accuracy: 0.9747 - auc_153: 0.9330 - precision_153: 0.7195 - recall_153: 0.2901\n","Score for fold 4: F1 score of 0.4318699277881966; loss of 0.07632063329219818; binary_accuracy of 97.50807881355286%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 27ms/step - loss: 0.1403 - binary_accuracy: 0.9497 - auc_154: 0.8080 - precision_154: 0.1779 - recall_154: 0.1762\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0885 - binary_accuracy: 0.9733 - auc_154: 0.9049 - precision_154: 0.7113 - recall_154: 0.2200\n","Epoch 3/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0832 - binary_accuracy: 0.9740 - auc_154: 0.9211 - precision_154: 0.7144 - recall_154: 0.2539\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0801 - binary_accuracy: 0.9744 - auc_154: 0.9290 - precision_154: 0.7176 - recall_154: 0.2759\n","Epoch 5/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0778 - binary_accuracy: 0.9748 - auc_154: 0.9340 - precision_154: 0.7206 - recall_154: 0.2924\n","Score for fold 5: F1 score of 0.42657213733862187; loss of 0.07628617435693741; binary_accuracy of 97.51495122909546%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 27ms/step - loss: 0.1399 - binary_accuracy: 0.9504 - auc_155: 0.8048 - precision_155: 0.1761 - recall_155: 0.1679\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0895 - binary_accuracy: 0.9732 - auc_155: 0.9014 - precision_155: 0.7132 - recall_155: 0.2121\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0839 - binary_accuracy: 0.9739 - auc_155: 0.9190 - precision_155: 0.7156 - recall_155: 0.2500\n","Epoch 4/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0806 - binary_accuracy: 0.9744 - auc_155: 0.9275 - precision_155: 0.7175 - recall_155: 0.2722\n","Epoch 5/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0783 - binary_accuracy: 0.9748 - auc_155: 0.9328 - precision_155: 0.7204 - recall_155: 0.2897\n","Score for fold 6: F1 score of 0.4322195821585161; loss of 0.07645700126886368; binary_accuracy of 97.51175045967102%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1401 - binary_accuracy: 0.9500 - auc_156: 0.8074 - precision_156: 0.1757 - recall_156: 0.1707\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0896 - binary_accuracy: 0.9732 - auc_156: 0.9008 - precision_156: 0.7116 - recall_156: 0.2123\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0843 - binary_accuracy: 0.9739 - auc_156: 0.9179 - precision_156: 0.7152 - recall_156: 0.2467\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0810 - binary_accuracy: 0.9743 - auc_156: 0.9266 - precision_156: 0.7169 - recall_156: 0.2685\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_156: 0.9320 - precision_156: 0.7208 - recall_156: 0.2864\n","Score for fold 7: F1 score of 0.42444255267816905; loss of 0.0767572671175003; binary_accuracy of 97.50341773033142%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1399 - binary_accuracy: 0.9504 - auc_157: 0.8046 - precision_157: 0.1747 - recall_157: 0.1651\n","Epoch 2/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0897 - binary_accuracy: 0.9731 - auc_157: 0.9006 - precision_157: 0.7113 - recall_157: 0.2097\n","Epoch 3/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0840 - binary_accuracy: 0.9739 - auc_157: 0.9186 - precision_157: 0.7167 - recall_157: 0.2480\n","Epoch 4/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0806 - binary_accuracy: 0.9744 - auc_157: 0.9276 - precision_157: 0.7182 - recall_157: 0.2727\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0782 - binary_accuracy: 0.9748 - auc_157: 0.9330 - precision_157: 0.7195 - recall_157: 0.2912\n","Score for fold 8: F1 score of 0.41191978246583855; loss of 0.07652688771486282; binary_accuracy of 97.50503897666931%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 26ms/step - loss: 0.1398 - binary_accuracy: 0.9499 - auc_158: 0.8080 - precision_158: 0.1786 - recall_158: 0.1760\n","Epoch 2/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0899 - binary_accuracy: 0.9731 - auc_158: 0.9005 - precision_158: 0.7097 - recall_158: 0.2102\n","Epoch 3/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0847 - binary_accuracy: 0.9738 - auc_158: 0.9173 - precision_158: 0.7156 - recall_158: 0.2417\n","Epoch 4/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0812 - binary_accuracy: 0.9743 - auc_158: 0.9262 - precision_158: 0.7173 - recall_158: 0.2674\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0787 - binary_accuracy: 0.9747 - auc_158: 0.9320 - precision_158: 0.7206 - recall_158: 0.2854\n","Score for fold 9: F1 score of 0.4236417621637063; loss of 0.07674332708120346; binary_accuracy of 97.50714898109436%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 7s 27ms/step - loss: 0.1400 - binary_accuracy: 0.9503 - auc_159: 0.8042 - precision_159: 0.1744 - recall_159: 0.1658\n","Epoch 2/5\n","218/218 [==============================] - 6s 25ms/step - loss: 0.0906 - binary_accuracy: 0.9730 - auc_159: 0.8979 - precision_159: 0.7113 - recall_159: 0.2041\n","Epoch 3/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0848 - binary_accuracy: 0.9738 - auc_159: 0.9171 - precision_159: 0.7146 - recall_159: 0.2415\n","Epoch 4/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0814 - binary_accuracy: 0.9743 - auc_159: 0.9258 - precision_159: 0.7176 - recall_159: 0.2654\n","Epoch 5/5\n","218/218 [==============================] - 6s 26ms/step - loss: 0.0790 - binary_accuracy: 0.9746 - auc_159: 0.9314 - precision_159: 0.7192 - recall_159: 0.2839\n","Score for fold 10: F1 score of 0.42599341742014213; loss of 0.07714507728815079; binary_accuracy of 97.49671220779419%\n","----------------------------------------------------------------------\n","The number of units in each layer is  128\n","The activation function in each layer is  relu\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 22ms/step - loss: 0.1235 - binary_accuracy: 0.9637 - auc_160: 0.8357 - precision_160: 0.3351 - recall_160: 0.1867\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0828 - binary_accuracy: 0.9740 - auc_160: 0.9213 - precision_160: 0.7100 - recall_160: 0.2588\n","Epoch 3/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0787 - binary_accuracy: 0.9746 - auc_160: 0.9313 - precision_160: 0.7153 - recall_160: 0.2884\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0764 - binary_accuracy: 0.9751 - auc_160: 0.9365 - precision_160: 0.7189 - recall_160: 0.3074\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0748 - binary_accuracy: 0.9754 - auc_160: 0.9399 - precision_160: 0.7208 - recall_160: 0.3215\n","Score for fold 1: F1 score of 0.45875177510891574; loss of 0.07292643189430237; binary_accuracy of 97.57052063941956%\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 22ms/step - loss: 0.1235 - binary_accuracy: 0.9637 - auc_161: 0.8365 - precision_161: 0.3385 - recall_161: 0.1900\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0824 - binary_accuracy: 0.9741 - auc_161: 0.9221 - precision_161: 0.7095 - recall_161: 0.2618\n","Epoch 3/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0787 - binary_accuracy: 0.9746 - auc_161: 0.9313 - precision_161: 0.7145 - recall_161: 0.2897\n","Epoch 4/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0764 - binary_accuracy: 0.9751 - auc_161: 0.9364 - precision_161: 0.7187 - recall_161: 0.3082\n","Epoch 5/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0749 - binary_accuracy: 0.9754 - auc_161: 0.9396 - precision_161: 0.7214 - recall_161: 0.3213\n","Score for fold 2: F1 score of 0.4552756167789875; loss of 0.07305615395307541; binary_accuracy of 97.57032990455627%\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1257 - binary_accuracy: 0.9629 - auc_162: 0.8317 - precision_162: 0.3172 - recall_162: 0.1817\n","Epoch 2/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0829 - binary_accuracy: 0.9740 - auc_162: 0.9209 - precision_162: 0.7102 - recall_162: 0.2584\n","Epoch 3/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0787 - binary_accuracy: 0.9746 - auc_162: 0.9314 - precision_162: 0.7147 - recall_162: 0.2892\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0764 - binary_accuracy: 0.9750 - auc_162: 0.9364 - precision_162: 0.7178 - recall_162: 0.3079\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0748 - binary_accuracy: 0.9754 - auc_162: 0.9398 - precision_162: 0.7205 - recall_162: 0.3217\n","Score for fold 3: F1 score of 0.4550185007745123; loss of 0.07310689985752106; binary_accuracy of 97.57022261619568%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 11s 21ms/step - loss: 0.1238 - binary_accuracy: 0.9634 - auc_163: 0.8337 - precision_163: 0.3291 - recall_163: 0.1859\n","Epoch 2/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0827 - binary_accuracy: 0.9741 - auc_163: 0.9213 - precision_163: 0.7111 - recall_163: 0.2600\n","Epoch 3/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0788 - binary_accuracy: 0.9746 - auc_163: 0.9311 - precision_163: 0.7152 - recall_163: 0.2886\n","Epoch 4/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0765 - binary_accuracy: 0.9750 - auc_163: 0.9362 - precision_163: 0.7181 - recall_163: 0.3068\n","Epoch 5/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0749 - binary_accuracy: 0.9753 - auc_163: 0.9396 - precision_163: 0.7207 - recall_163: 0.3205\n","Score for fold 4: F1 score of 0.4582376437863284; loss of 0.0734880119562149; binary_accuracy of 97.56854176521301%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1236 - binary_accuracy: 0.9633 - auc_164: 0.8357 - precision_164: 0.3290 - recall_164: 0.1880\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0826 - binary_accuracy: 0.9740 - auc_164: 0.9216 - precision_164: 0.7102 - recall_164: 0.2596\n","Epoch 3/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0786 - binary_accuracy: 0.9747 - auc_164: 0.9315 - precision_164: 0.7153 - recall_164: 0.2893\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_164: 0.9366 - precision_164: 0.7191 - recall_164: 0.3083\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0747 - binary_accuracy: 0.9754 - auc_164: 0.9399 - precision_164: 0.7202 - recall_164: 0.3237\n","Score for fold 5: F1 score of 0.43810093374824016; loss of 0.07316220551729202; binary_accuracy of 97.56215214729309%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1248 - binary_accuracy: 0.9632 - auc_165: 0.8346 - precision_165: 0.3272 - recall_165: 0.1892\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0826 - binary_accuracy: 0.9740 - auc_165: 0.9216 - precision_165: 0.7114 - recall_165: 0.2584\n","Epoch 3/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0786 - binary_accuracy: 0.9747 - auc_165: 0.9317 - precision_165: 0.7158 - recall_165: 0.2897\n","Epoch 4/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_165: 0.9367 - precision_165: 0.7192 - recall_165: 0.3082\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0746 - binary_accuracy: 0.9754 - auc_165: 0.9401 - precision_165: 0.7221 - recall_165: 0.3228\n","Score for fold 6: F1 score of 0.4552741198189856; loss of 0.07294714450836182; binary_accuracy of 97.57426977157593%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1247 - binary_accuracy: 0.9631 - auc_166: 0.8339 - precision_166: 0.3238 - recall_166: 0.1853\n","Epoch 2/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0826 - binary_accuracy: 0.9741 - auc_166: 0.9216 - precision_166: 0.7131 - recall_166: 0.2586\n","Epoch 3/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0785 - binary_accuracy: 0.9747 - auc_166: 0.9316 - precision_166: 0.7165 - recall_166: 0.2899\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_166: 0.9366 - precision_166: 0.7191 - recall_166: 0.3087\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0747 - binary_accuracy: 0.9754 - auc_166: 0.9400 - precision_166: 0.7219 - recall_166: 0.3219\n","Score for fold 7: F1 score of 0.4653676263169698; loss of 0.07288704812526703; binary_accuracy of 97.57279753684998%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1245 - binary_accuracy: 0.9631 - auc_167: 0.8361 - precision_167: 0.3255 - recall_167: 0.1889\n","Epoch 2/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0826 - binary_accuracy: 0.9740 - auc_167: 0.9219 - precision_167: 0.7109 - recall_167: 0.2572\n","Epoch 3/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0786 - binary_accuracy: 0.9746 - auc_167: 0.9317 - precision_167: 0.7143 - recall_167: 0.2878\n","Epoch 4/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0764 - binary_accuracy: 0.9750 - auc_167: 0.9366 - precision_167: 0.7178 - recall_167: 0.3073\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0747 - binary_accuracy: 0.9754 - auc_167: 0.9400 - precision_167: 0.7209 - recall_167: 0.3216\n","Score for fold 8: F1 score of 0.4621942996178033; loss of 0.07302772998809814; binary_accuracy of 97.5728690624237%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1250 - binary_accuracy: 0.9627 - auc_168: 0.8353 - precision_168: 0.3202 - recall_168: 0.1912\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0826 - binary_accuracy: 0.9740 - auc_168: 0.9217 - precision_168: 0.7102 - recall_168: 0.2593\n","Epoch 3/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0787 - binary_accuracy: 0.9746 - auc_168: 0.9313 - precision_168: 0.7142 - recall_168: 0.2886\n","Epoch 4/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0764 - binary_accuracy: 0.9750 - auc_168: 0.9365 - precision_168: 0.7174 - recall_168: 0.3079\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0748 - binary_accuracy: 0.9753 - auc_168: 0.9398 - precision_168: 0.7205 - recall_168: 0.3214\n","Score for fold 9: F1 score of 0.46521426924503845; loss of 0.07319550961256027; binary_accuracy of 97.56811857223511%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 22ms/step - loss: 0.1230 - binary_accuracy: 0.9635 - auc_169: 0.8361 - precision_169: 0.3330 - recall_169: 0.1879\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0826 - binary_accuracy: 0.9741 - auc_169: 0.9217 - precision_169: 0.7098 - recall_169: 0.2614\n","Epoch 3/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0785 - binary_accuracy: 0.9747 - auc_169: 0.9318 - precision_169: 0.7139 - recall_169: 0.2907\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0763 - binary_accuracy: 0.9751 - auc_169: 0.9367 - precision_169: 0.7180 - recall_169: 0.3086\n","Epoch 5/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0747 - binary_accuracy: 0.9754 - auc_169: 0.9400 - precision_169: 0.7212 - recall_169: 0.3222\n","Score for fold 10: F1 score of 0.4502592125576124; loss of 0.07316484302282333; binary_accuracy of 97.56437540054321%\n","----------------------------------------------------------------------\n","The number of units in each layer is  128\n","The activation function in each layer is  tanh\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 20ms/step - loss: 0.1561 - binary_accuracy: 0.9443 - auc_170: 0.7738 - precision_170: 0.1305 - recall_170: 0.1437\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0987 - binary_accuracy: 0.9721 - auc_170: 0.8625 - precision_170: 0.6963 - recall_170: 0.1593\n","Epoch 3/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0931 - binary_accuracy: 0.9727 - auc_170: 0.8879 - precision_170: 0.7047 - recall_170: 0.1915\n","Epoch 4/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0883 - binary_accuracy: 0.9733 - auc_170: 0.9055 - precision_170: 0.7138 - recall_170: 0.2180\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0849 - binary_accuracy: 0.9738 - auc_170: 0.9159 - precision_170: 0.7179 - recall_170: 0.2412\n","Score for fold 1: F1 score of 0.3691501088289264; loss of 0.08294257521629333; binary_accuracy of 97.40598797798157%\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 20ms/step - loss: 0.1561 - binary_accuracy: 0.9452 - auc_171: 0.7736 - precision_171: 0.1310 - recall_171: 0.1395\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0993 - binary_accuracy: 0.9720 - auc_171: 0.8595 - precision_171: 0.6957 - recall_171: 0.1552\n","Epoch 3/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0935 - binary_accuracy: 0.9727 - auc_171: 0.8859 - precision_171: 0.7046 - recall_171: 0.1879\n","Epoch 4/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0882 - binary_accuracy: 0.9734 - auc_171: 0.9054 - precision_171: 0.7118 - recall_171: 0.2217\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0846 - binary_accuracy: 0.9739 - auc_171: 0.9166 - precision_171: 0.7172 - recall_171: 0.2455\n","Score for fold 2: F1 score of 0.37428671975984956; loss of 0.08261273056268692; binary_accuracy of 97.41758704185486%\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 22ms/step - loss: 0.1568 - binary_accuracy: 0.9444 - auc_172: 0.7730 - precision_172: 0.1290 - recall_172: 0.1414\n","Epoch 2/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0989 - binary_accuracy: 0.9720 - auc_172: 0.8627 - precision_172: 0.6996 - recall_172: 0.1529\n","Epoch 3/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0927 - binary_accuracy: 0.9728 - auc_172: 0.8892 - precision_172: 0.7097 - recall_172: 0.1918\n","Epoch 4/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0878 - binary_accuracy: 0.9734 - auc_172: 0.9072 - precision_172: 0.7138 - recall_172: 0.2226\n","Epoch 5/5\n","218/218 [==============================] - 4s 20ms/step - loss: 0.0844 - binary_accuracy: 0.9739 - auc_172: 0.9176 - precision_172: 0.7160 - recall_172: 0.2468\n","Score for fold 3: F1 score of 0.3806122485977993; loss of 0.08243837207555771; binary_accuracy of 97.41540551185608%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1573 - binary_accuracy: 0.9438 - auc_173: 0.7731 - precision_173: 0.1293 - recall_173: 0.1452\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0991 - binary_accuracy: 0.9720 - auc_173: 0.8611 - precision_173: 0.6938 - recall_173: 0.1555\n","Epoch 3/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0937 - binary_accuracy: 0.9727 - auc_173: 0.8852 - precision_173: 0.7090 - recall_173: 0.1872\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0882 - binary_accuracy: 0.9734 - auc_173: 0.9054 - precision_173: 0.7141 - recall_173: 0.2205\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0846 - binary_accuracy: 0.9738 - auc_173: 0.9170 - precision_173: 0.7181 - recall_173: 0.2428\n","Score for fold 4: F1 score of 0.3869368750795462; loss of 0.0826735869050026; binary_accuracy of 97.41517305374146%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1549 - binary_accuracy: 0.9450 - auc_174: 0.7764 - precision_174: 0.1318 - recall_174: 0.1417\n","Epoch 2/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0986 - binary_accuracy: 0.9720 - auc_174: 0.8646 - precision_174: 0.6918 - recall_174: 0.1564\n","Epoch 3/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0923 - binary_accuracy: 0.9728 - auc_174: 0.8911 - precision_174: 0.7069 - recall_174: 0.1937\n","Epoch 4/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0878 - binary_accuracy: 0.9734 - auc_174: 0.9071 - precision_174: 0.7121 - recall_174: 0.2243\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0845 - binary_accuracy: 0.9739 - auc_174: 0.9174 - precision_174: 0.7187 - recall_174: 0.2456\n","Score for fold 5: F1 score of 0.38513305329102787; loss of 0.08270008862018585; binary_accuracy of 97.41377234458923%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1558 - binary_accuracy: 0.9446 - auc_175: 0.7720 - precision_175: 0.1272 - recall_175: 0.1376\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0993 - binary_accuracy: 0.9719 - auc_175: 0.8599 - precision_175: 0.6985 - recall_175: 0.1501\n","Epoch 3/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0918 - binary_accuracy: 0.9729 - auc_175: 0.8924 - precision_175: 0.7124 - recall_175: 0.1967\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0870 - binary_accuracy: 0.9735 - auc_175: 0.9092 - precision_175: 0.7162 - recall_175: 0.2285\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0840 - binary_accuracy: 0.9740 - auc_175: 0.9186 - precision_175: 0.7178 - recall_175: 0.2491\n","Score for fold 6: F1 score of 0.3736619386198695; loss of 0.0822012796998024; binary_accuracy of 97.42394089698792%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1566 - binary_accuracy: 0.9442 - auc_176: 0.7737 - precision_176: 0.1288 - recall_176: 0.1420\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0987 - binary_accuracy: 0.9721 - auc_176: 0.8622 - precision_176: 0.6987 - recall_176: 0.1585\n","Epoch 3/5\n","218/218 [==============================] - 4s 21ms/step - loss: 0.0931 - binary_accuracy: 0.9728 - auc_176: 0.8866 - precision_176: 0.7084 - recall_176: 0.1917\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0886 - binary_accuracy: 0.9733 - auc_176: 0.9040 - precision_176: 0.7167 - recall_176: 0.2168\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0854 - binary_accuracy: 0.9738 - auc_176: 0.9144 - precision_176: 0.7190 - recall_176: 0.2388\n","Score for fold 7: F1 score of 0.36938324839230585; loss of 0.08347582817077637; binary_accuracy of 97.40415811538696%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1564 - binary_accuracy: 0.9442 - auc_177: 0.7720 - precision_177: 0.1271 - recall_177: 0.1397\n","Epoch 2/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0996 - binary_accuracy: 0.9719 - auc_177: 0.8577 - precision_177: 0.6926 - recall_177: 0.1539\n","Epoch 3/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0945 - binary_accuracy: 0.9726 - auc_177: 0.8821 - precision_177: 0.7059 - recall_177: 0.1827\n","Epoch 4/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0890 - binary_accuracy: 0.9733 - auc_177: 0.9029 - precision_177: 0.7139 - recall_177: 0.2148\n","Epoch 5/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0852 - binary_accuracy: 0.9738 - auc_177: 0.9150 - precision_177: 0.7170 - recall_177: 0.2407\n","Score for fold 8: F1 score of 0.3771237211423437; loss of 0.08315437287092209; binary_accuracy of 97.4065899848938%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1549 - binary_accuracy: 0.9448 - auc_178: 0.7782 - precision_178: 0.1354 - recall_178: 0.1485\n","Epoch 2/5\n","218/218 [==============================] - 9s 43ms/step - loss: 0.0985 - binary_accuracy: 0.9721 - auc_178: 0.8643 - precision_178: 0.6952 - recall_178: 0.1599\n","Epoch 3/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0925 - binary_accuracy: 0.9728 - auc_178: 0.8902 - precision_178: 0.7101 - recall_178: 0.1936\n","Epoch 4/5\n","218/218 [==============================] - 6s 27ms/step - loss: 0.0874 - binary_accuracy: 0.9735 - auc_178: 0.9082 - precision_178: 0.7166 - recall_178: 0.2248\n","Epoch 5/5\n","218/218 [==============================] - 7s 31ms/step - loss: 0.0841 - binary_accuracy: 0.9739 - auc_178: 0.9186 - precision_178: 0.7177 - recall_178: 0.2476\n","Score for fold 9: F1 score of 0.38628218971851297; loss of 0.08213802427053452; binary_accuracy of 97.42016792297363%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 6s 21ms/step - loss: 0.1559 - binary_accuracy: 0.9441 - auc_179: 0.7777 - precision_179: 0.1338 - recall_179: 0.1503\n","Epoch 2/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0980 - binary_accuracy: 0.9721 - auc_179: 0.8662 - precision_179: 0.6956 - recall_179: 0.1619\n","Epoch 3/5\n","218/218 [==============================] - 5s 21ms/step - loss: 0.0917 - binary_accuracy: 0.9729 - auc_179: 0.8928 - precision_179: 0.7088 - recall_179: 0.2003\n","Epoch 4/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0871 - binary_accuracy: 0.9735 - auc_179: 0.9091 - precision_179: 0.7124 - recall_179: 0.2306\n","Epoch 5/5\n","218/218 [==============================] - 5s 22ms/step - loss: 0.0839 - binary_accuracy: 0.9740 - auc_179: 0.9188 - precision_179: 0.7173 - recall_179: 0.2510\n","Score for fold 10: F1 score of 0.3757679173127114; loss of 0.081966333091259; binary_accuracy of 97.42300510406494%\n"]}]},{"cell_type":"markdown","source":["## Model 2 Architecture: Decreasing then increasing layer size"],"metadata":{"id":"ivDJswKpFM9A"}},{"cell_type":"code","source":["BATCH_SIZE = 256"],"metadata":{"executionInfo":{"status":"ok","timestamp":1708302755492,"user_tz":-60,"elapsed":15,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}},"id":"mF57mwHIQ9BA"},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def model2_training(dataset_name, data):\n","  train = data[0]\n","  label = data[1]\n","\n","  INPUT_SHAPE = [train.shape[1]]\n","\n","  best_f1 = 0\n","  print('=======================================================================')\n","  print(f'Training for {dataset_name}')\n","\n","  act_param = 'relu'\n","\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","  fold_no = 1\n","\n","  for train_fold, test_fold in kfold.split(train, label):\n","\n","    model2 = tf.keras.Sequential([\n","        tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),\n","        tf.keras.layers.Dense(units = 512, activation = act_param),\n","        tf.keras.layers.Dense(units = 256, activation = act_param),\n","        tf.keras.layers.Dense(units = 128, activation = act_param),\n","        tf.keras.layers.Dense(units = 256, activation = act_param),\n","        tf.keras.layers.Dense(units = 512, activation = act_param),\n","        tf.keras.layers.Dense(units = num_labels, activation = 'sigmoid')\n","        ])\n","\n","    # Compile model\n","    model2.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","        loss='binary_crossentropy',\n","        metrics=['binary_accuracy',\n","                tf.keras.metrics.AUC(),\n","                tf.keras.metrics.Precision(),\n","                tf.keras.metrics.Recall(),\n","                ] # tf.keras.metrics.F1Score() not appropriate as it is calculated batchwise\n","        )\n","\n","    print(f'Training for fold {fold_no} ...')\n","\n","    # Fit the data to the model\n","    history = model2.fit(\n","        train, label,\n","        batch_size=BATCH_SIZE,\n","        epochs=5\n","        )\n","\n","    # Generate metrics\n","    scores = model2.evaluate(train, label, verbose=0)\n","    precision = scores[3]\n","    recall = scores[4]\n","    F1_score = 2*precision*recall / (precision + recall)\n","    print(f'Score for fold {fold_no}: F1 score of {F1_score}; {model2.metrics_names[0]} of {scores[0]}; {model2.metrics_names[1]} of {scores[1]*100}%')\n","\n","    if F1_score > best_f1:\n","      best_f1 = F1_score\n","      if dataset_name == 'Biological Processes':\n","        tf.keras.models.save_model(\n","            model2,\n","            '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data/FFNNMod2/best_BP_model',\n","        )\n","        print(f'Current best model for Biological Processes has an F1 score of {F1_score}')\n","\n","      elif dataset_name == 'Molecular Function':\n","        tf.keras.models.save_model(\n","            model2,\n","            '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data/FFNNMod2/best_MF_model',\n","        )\n","        print(f'Current best model for Molecular Function has an F1 score of {F1_score}')\n","\n","      else:\n","        tf.keras.models.save_model(\n","            model2,\n","            '/content/drive/MyDrive/ColabNotebooks/BiologicalData/Final_Project/bio_data/FFNNMod2/best_CC_model',\n","        )\n","        print(f'Current best model for Cellular Component has an F1 score of {F1_score}')\n","\n","    fold_no += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1708302755492,"user_tz":-60,"elapsed":13,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}},"id":"f4tA3YlCQ9BC"},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["for dataset in train_data_dict:\n","  dataset_name = dataset\n","  data = train_data_dict[dataset]\n","  model2_training(dataset_name, data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohngJm9WPbfu","executionInfo":{"status":"ok","timestamp":1708304760636,"user_tz":-60,"elapsed":2005155,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}},"outputId":"a5b2af87-f0d2-4d9f-fd34-f58b98951707"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================================================================\n","Training for Biological Processes\n","Training for fold 1 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 35ms/step - loss: 0.1079 - binary_accuracy: 0.9687 - auc_180: 0.8447 - precision_180: 0.3743 - recall_180: 0.1420\n","Epoch 2/5\n","244/244 [==============================] - 8s 34ms/step - loss: 0.0812 - binary_accuracy: 0.9747 - auc_180: 0.9156 - precision_180: 0.6764 - recall_180: 0.2149\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0773 - binary_accuracy: 0.9752 - auc_180: 0.9269 - precision_180: 0.6830 - recall_180: 0.2447\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0747 - binary_accuracy: 0.9756 - auc_180: 0.9332 - precision_180: 0.6880 - recall_180: 0.2668\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0728 - binary_accuracy: 0.9760 - auc_180: 0.9376 - precision_180: 0.6933 - recall_180: 0.2845\n","Score for fold 1: F1 score of 0.42692201973979943; loss of 0.07086903601884842; binary_accuracy of 97.64177203178406%\n","Current best model for Biological Processes has an F1 score of 0.42692201973979943\n","Training for fold 2 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 34ms/step - loss: 0.1084 - binary_accuracy: 0.9687 - auc_181: 0.8453 - precision_181: 0.3759 - recall_181: 0.1450\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0810 - binary_accuracy: 0.9747 - auc_181: 0.9164 - precision_181: 0.6769 - recall_181: 0.2157\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0771 - binary_accuracy: 0.9752 - auc_181: 0.9274 - precision_181: 0.6818 - recall_181: 0.2458\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0746 - binary_accuracy: 0.9756 - auc_181: 0.9336 - precision_181: 0.6874 - recall_181: 0.2673\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_181: 0.9378 - precision_181: 0.6921 - recall_181: 0.2860\n","Score for fold 2: F1 score of 0.4209447373143758; loss of 0.0704914927482605; binary_accuracy of 97.64474630355835%\n","Training for fold 3 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 34ms/step - loss: 0.1071 - binary_accuracy: 0.9689 - auc_182: 0.8482 - precision_182: 0.3839 - recall_182: 0.1477\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0807 - binary_accuracy: 0.9747 - auc_182: 0.9170 - precision_182: 0.6773 - recall_182: 0.2170\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0769 - binary_accuracy: 0.9752 - auc_182: 0.9277 - precision_182: 0.6831 - recall_182: 0.2470\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0744 - binary_accuracy: 0.9757 - auc_182: 0.9339 - precision_182: 0.6884 - recall_182: 0.2700\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0724 - binary_accuracy: 0.9761 - auc_182: 0.9385 - precision_182: 0.6943 - recall_182: 0.2884\n","Score for fold 3: F1 score of 0.4241805675883048; loss of 0.07001075893640518; binary_accuracy of 97.65877723693848%\n","Training for fold 4 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 33ms/step - loss: 0.1075 - binary_accuracy: 0.9689 - auc_183: 0.8473 - precision_183: 0.3821 - recall_183: 0.1464\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0808 - binary_accuracy: 0.9747 - auc_183: 0.9170 - precision_183: 0.6761 - recall_183: 0.2172\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0770 - binary_accuracy: 0.9752 - auc_183: 0.9275 - precision_183: 0.6823 - recall_183: 0.2470\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0747 - binary_accuracy: 0.9756 - auc_183: 0.9333 - precision_183: 0.6876 - recall_183: 0.2681\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_183: 0.9378 - precision_183: 0.6942 - recall_183: 0.2864\n","Score for fold 4: F1 score of 0.41473337135076077; loss of 0.07036077231168747; binary_accuracy of 97.64835238456726%\n","Training for fold 5 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 33ms/step - loss: 0.1068 - binary_accuracy: 0.9691 - auc_184: 0.8478 - precision_184: 0.3884 - recall_184: 0.1466\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0805 - binary_accuracy: 0.9747 - auc_184: 0.9180 - precision_184: 0.6763 - recall_184: 0.2198\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0768 - binary_accuracy: 0.9753 - auc_184: 0.9281 - precision_184: 0.6829 - recall_184: 0.2482\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0744 - binary_accuracy: 0.9757 - auc_184: 0.9340 - precision_184: 0.6900 - recall_184: 0.2686\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_184: 0.9381 - precision_184: 0.6934 - recall_184: 0.2859\n","Score for fold 5: F1 score of 0.42537089766847047; loss of 0.0699285939335823; binary_accuracy of 97.65717387199402%\n","Training for fold 6 ...\n","Epoch 1/5\n","244/244 [==============================] - 11s 38ms/step - loss: 0.1076 - binary_accuracy: 0.9689 - auc_185: 0.8469 - precision_185: 0.3822 - recall_185: 0.1455\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0807 - binary_accuracy: 0.9747 - auc_185: 0.9170 - precision_185: 0.6777 - recall_185: 0.2173\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0770 - binary_accuracy: 0.9752 - auc_185: 0.9275 - precision_185: 0.6830 - recall_185: 0.2470\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0746 - binary_accuracy: 0.9756 - auc_185: 0.9334 - precision_185: 0.6875 - recall_185: 0.2671\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0728 - binary_accuracy: 0.9760 - auc_185: 0.9375 - precision_185: 0.6923 - recall_185: 0.2860\n","Score for fold 6: F1 score of 0.42876681174631504; loss of 0.07040610164403915; binary_accuracy of 97.6474404335022%\n","Current best model for Biological Processes has an F1 score of 0.42876681174631504\n","Training for fold 7 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1078 - binary_accuracy: 0.9689 - auc_186: 0.8464 - precision_186: 0.3813 - recall_186: 0.1456\n","Epoch 2/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0811 - binary_accuracy: 0.9747 - auc_186: 0.9161 - precision_186: 0.6764 - recall_186: 0.2161\n","Epoch 3/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0771 - binary_accuracy: 0.9752 - auc_186: 0.9273 - precision_186: 0.6827 - recall_186: 0.2453\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0747 - binary_accuracy: 0.9756 - auc_186: 0.9332 - precision_186: 0.6887 - recall_186: 0.2661\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0727 - binary_accuracy: 0.9760 - auc_186: 0.9378 - precision_186: 0.6936 - recall_186: 0.2857\n","Score for fold 7: F1 score of 0.4062868476375486; loss of 0.07024923712015152; binary_accuracy of 97.65088558197021%\n","Training for fold 8 ...\n","Epoch 1/5\n","244/244 [==============================] - 9s 32ms/step - loss: 0.1080 - binary_accuracy: 0.9688 - auc_187: 0.8444 - precision_187: 0.3782 - recall_187: 0.1437\n","Epoch 2/5\n","244/244 [==============================] - 8s 34ms/step - loss: 0.0806 - binary_accuracy: 0.9747 - auc_187: 0.9174 - precision_187: 0.6781 - recall_187: 0.2175\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0768 - binary_accuracy: 0.9753 - auc_187: 0.9282 - precision_187: 0.6832 - recall_187: 0.2490\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0745 - binary_accuracy: 0.9757 - auc_187: 0.9338 - precision_187: 0.6881 - recall_187: 0.2688\n","Epoch 5/5\n","244/244 [==============================] - 8s 34ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_187: 0.9379 - precision_187: 0.6923 - recall_187: 0.2873\n","Score for fold 8: F1 score of 0.41814782692527597; loss of 0.07003128528594971; binary_accuracy of 97.65745997428894%\n","Training for fold 9 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 33ms/step - loss: 0.1071 - binary_accuracy: 0.9690 - auc_188: 0.8452 - precision_188: 0.3849 - recall_188: 0.1437\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0806 - binary_accuracy: 0.9747 - auc_188: 0.9175 - precision_188: 0.6759 - recall_188: 0.2186\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0769 - binary_accuracy: 0.9752 - auc_188: 0.9277 - precision_188: 0.6811 - recall_188: 0.2480\n","Epoch 4/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0745 - binary_accuracy: 0.9756 - auc_188: 0.9337 - precision_188: 0.6865 - recall_188: 0.2690\n","Epoch 5/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_188: 0.9380 - precision_188: 0.6917 - recall_188: 0.2873\n","Score for fold 9: F1 score of 0.4464521257442694; loss of 0.07075577229261398; binary_accuracy of 97.63376116752625%\n","Current best model for Biological Processes has an F1 score of 0.4464521257442694\n","Training for fold 10 ...\n","Epoch 1/5\n","244/244 [==============================] - 10s 33ms/step - loss: 0.1077 - binary_accuracy: 0.9687 - auc_189: 0.8476 - precision_189: 0.3782 - recall_189: 0.1483\n","Epoch 2/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0806 - binary_accuracy: 0.9747 - auc_189: 0.9175 - precision_189: 0.6777 - recall_189: 0.2182\n","Epoch 3/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0769 - binary_accuracy: 0.9753 - auc_189: 0.9279 - precision_189: 0.6833 - recall_189: 0.2475\n","Epoch 4/5\n","244/244 [==============================] - 8s 33ms/step - loss: 0.0745 - binary_accuracy: 0.9757 - auc_189: 0.9338 - precision_189: 0.6882 - recall_189: 0.2685\n","Epoch 5/5\n","244/244 [==============================] - 8s 32ms/step - loss: 0.0726 - binary_accuracy: 0.9760 - auc_189: 0.9381 - precision_189: 0.6929 - recall_189: 0.2863\n","Score for fold 10: F1 score of 0.4454032001820211; loss of 0.07064007967710495; binary_accuracy of 97.64649868011475%\n","=======================================================================\n","Training for Cellular Component\n","Training for fold 1 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 33ms/step - loss: 0.0877 - binary_accuracy: 0.9752 - auc_190: 0.8739 - precision_190: 0.4965 - recall_190: 0.2077\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0668 - binary_accuracy: 0.9796 - auc_190: 0.9289 - precision_190: 0.7446 - recall_190: 0.2666\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0637 - binary_accuracy: 0.9800 - auc_190: 0.9376 - precision_190: 0.7420 - recall_190: 0.2937\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0618 - binary_accuracy: 0.9803 - auc_190: 0.9426 - precision_190: 0.7416 - recall_190: 0.3125\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_190: 0.9462 - precision_190: 0.7416 - recall_190: 0.3284\n","Score for fold 1: F1 score of 0.47064571472392774; loss of 0.05874857306480408; binary_accuracy of 98.0752944946289%\n","Current best model for Cellular Component has an F1 score of 0.47064571472392774\n","Training for fold 2 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0879 - binary_accuracy: 0.9751 - auc_191: 0.8723 - precision_191: 0.4911 - recall_191: 0.2038\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0670 - binary_accuracy: 0.9796 - auc_191: 0.9284 - precision_191: 0.7444 - recall_191: 0.2651\n","Epoch 3/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0640 - binary_accuracy: 0.9800 - auc_191: 0.9368 - precision_191: 0.7414 - recall_191: 0.2911\n","Epoch 4/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0621 - binary_accuracy: 0.9802 - auc_191: 0.9417 - precision_191: 0.7402 - recall_191: 0.3093\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0605 - binary_accuracy: 0.9805 - auc_191: 0.9456 - precision_191: 0.7415 - recall_191: 0.3260\n","Score for fold 2: F1 score of 0.45144111162068246; loss of 0.058353323489427567; binary_accuracy of 98.0878472328186%\n","Training for fold 3 ...\n","Epoch 1/5\n","331/331 [==============================] - 12s 32ms/step - loss: 0.0870 - binary_accuracy: 0.9753 - auc_192: 0.8762 - precision_192: 0.5024 - recall_192: 0.2108\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0666 - binary_accuracy: 0.9796 - auc_192: 0.9294 - precision_192: 0.7432 - recall_192: 0.2686\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0636 - binary_accuracy: 0.9800 - auc_192: 0.9379 - precision_192: 0.7404 - recall_192: 0.2951\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0616 - binary_accuracy: 0.9803 - auc_192: 0.9429 - precision_192: 0.7424 - recall_192: 0.3134\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0601 - binary_accuracy: 0.9806 - auc_192: 0.9466 - precision_192: 0.7413 - recall_192: 0.3282\n","Score for fold 3: F1 score of 0.4402219382622123; loss of 0.05849170684814453; binary_accuracy of 98.08353781700134%\n","Training for fold 4 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0877 - binary_accuracy: 0.9752 - auc_193: 0.8734 - precision_193: 0.4989 - recall_193: 0.2038\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0671 - binary_accuracy: 0.9796 - auc_193: 0.9280 - precision_193: 0.7446 - recall_193: 0.2640\n","Epoch 3/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0638 - binary_accuracy: 0.9800 - auc_193: 0.9373 - precision_193: 0.7424 - recall_193: 0.2917\n","Epoch 4/5\n","331/331 [==============================] - 12s 36ms/step - loss: 0.0619 - binary_accuracy: 0.9803 - auc_193: 0.9424 - precision_193: 0.7407 - recall_193: 0.3115\n","Epoch 5/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_193: 0.9464 - precision_193: 0.7418 - recall_193: 0.3282\n","Score for fold 4: F1 score of 0.45539613847930216; loss of 0.05835934355854988; binary_accuracy of 98.08811545372009%\n","Training for fold 5 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0876 - binary_accuracy: 0.9752 - auc_194: 0.8741 - precision_194: 0.4955 - recall_194: 0.2064\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0668 - binary_accuracy: 0.9796 - auc_194: 0.9288 - precision_194: 0.7434 - recall_194: 0.2670\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0638 - binary_accuracy: 0.9800 - auc_194: 0.9374 - precision_194: 0.7409 - recall_194: 0.2926\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0618 - binary_accuracy: 0.9803 - auc_194: 0.9425 - precision_194: 0.7412 - recall_194: 0.3114\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0602 - binary_accuracy: 0.9806 - auc_194: 0.9462 - precision_194: 0.7426 - recall_194: 0.3272\n","Score for fold 5: F1 score of 0.46466109080741297; loss of 0.058323897421360016; binary_accuracy of 98.08964729309082%\n","Training for fold 6 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0872 - binary_accuracy: 0.9753 - auc_195: 0.8755 - precision_195: 0.5031 - recall_195: 0.2072\n","Epoch 2/5\n","331/331 [==============================] - 11s 32ms/step - loss: 0.0667 - binary_accuracy: 0.9796 - auc_195: 0.9292 - precision_195: 0.7428 - recall_195: 0.2679\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0637 - binary_accuracy: 0.9800 - auc_195: 0.9377 - precision_195: 0.7410 - recall_195: 0.2942\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0618 - binary_accuracy: 0.9803 - auc_195: 0.9427 - precision_195: 0.7396 - recall_195: 0.3127\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_195: 0.9465 - precision_195: 0.7408 - recall_195: 0.3282\n","Score for fold 6: F1 score of 0.4763360380682097; loss of 0.05783646181225777; binary_accuracy of 98.09655547142029%\n","Current best model for Cellular Component has an F1 score of 0.4763360380682097\n","Training for fold 7 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0870 - binary_accuracy: 0.9753 - auc_196: 0.8759 - precision_196: 0.5036 - recall_196: 0.2113\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0667 - binary_accuracy: 0.9796 - auc_196: 0.9290 - precision_196: 0.7449 - recall_196: 0.2666\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0638 - binary_accuracy: 0.9800 - auc_196: 0.9376 - precision_196: 0.7423 - recall_196: 0.2917\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0618 - binary_accuracy: 0.9803 - auc_196: 0.9425 - precision_196: 0.7414 - recall_196: 0.3110\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0601 - binary_accuracy: 0.9806 - auc_196: 0.9466 - precision_196: 0.7421 - recall_196: 0.3275\n","Score for fold 7: F1 score of 0.4813647189947089; loss of 0.05833065137267113; binary_accuracy of 98.09063673019409%\n","Current best model for Cellular Component has an F1 score of 0.4813647189947089\n","Training for fold 8 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0875 - binary_accuracy: 0.9754 - auc_197: 0.8730 - precision_197: 0.5063 - recall_197: 0.2057\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0669 - binary_accuracy: 0.9796 - auc_197: 0.9283 - precision_197: 0.7436 - recall_197: 0.2657\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0639 - binary_accuracy: 0.9800 - auc_197: 0.9371 - precision_197: 0.7409 - recall_197: 0.2924\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0620 - binary_accuracy: 0.9803 - auc_197: 0.9421 - precision_197: 0.7410 - recall_197: 0.3103\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - auc_197: 0.9460 - precision_197: 0.7412 - recall_197: 0.3253\n","Score for fold 8: F1 score of 0.4645313821758292; loss of 0.05837486684322357; binary_accuracy of 98.08792471885681%\n","Training for fold 9 ...\n","Epoch 1/5\n","331/331 [==============================] - 25s 58ms/step - loss: 0.0877 - binary_accuracy: 0.9753 - auc_198: 0.8730 - precision_198: 0.5015 - recall_198: 0.2056\n","Epoch 2/5\n","331/331 [==============================] - 15s 44ms/step - loss: 0.0667 - binary_accuracy: 0.9796 - auc_198: 0.9290 - precision_198: 0.7438 - recall_198: 0.2673\n","Epoch 3/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0638 - binary_accuracy: 0.9800 - auc_198: 0.9373 - precision_198: 0.7412 - recall_198: 0.2938\n","Epoch 4/5\n","331/331 [==============================] - 11s 34ms/step - loss: 0.0618 - binary_accuracy: 0.9803 - auc_198: 0.9426 - precision_198: 0.7421 - recall_198: 0.3120\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0601 - binary_accuracy: 0.9806 - auc_198: 0.9465 - precision_198: 0.7428 - recall_198: 0.3276\n","Score for fold 9: F1 score of 0.4571721815928237; loss of 0.058231741189956665; binary_accuracy of 98.09132218360901%\n","Training for fold 10 ...\n","Epoch 1/5\n","331/331 [==============================] - 13s 33ms/step - loss: 0.0876 - binary_accuracy: 0.9754 - auc_199: 0.8740 - precision_199: 0.5047 - recall_199: 0.2081\n","Epoch 2/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0667 - binary_accuracy: 0.9796 - auc_199: 0.9291 - precision_199: 0.7443 - recall_199: 0.2668\n","Epoch 3/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0637 - binary_accuracy: 0.9800 - auc_199: 0.9377 - precision_199: 0.7408 - recall_199: 0.2932\n","Epoch 4/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0617 - binary_accuracy: 0.9803 - auc_199: 0.9427 - precision_199: 0.7401 - recall_199: 0.3117\n","Epoch 5/5\n","331/331 [==============================] - 11s 33ms/step - loss: 0.0602 - binary_accuracy: 0.9805 - auc_199: 0.9464 - precision_199: 0.7410 - recall_199: 0.3280\n","Score for fold 10: F1 score of 0.45485911755445035; loss of 0.057953279465436935; binary_accuracy of 98.08927178382874%\n","=======================================================================\n","Training for Molecular Function\n","Training for fold 1 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1113 - binary_accuracy: 0.9673 - auc_200: 0.8549 - precision_200: 0.4262 - recall_200: 0.1858\n","Epoch 2/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0813 - binary_accuracy: 0.9743 - auc_200: 0.9247 - precision_200: 0.7130 - recall_200: 0.2698\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0770 - binary_accuracy: 0.9749 - auc_200: 0.9352 - precision_200: 0.7163 - recall_200: 0.3038\n","Epoch 4/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0741 - binary_accuracy: 0.9755 - auc_200: 0.9411 - precision_200: 0.7216 - recall_200: 0.3285\n","Epoch 5/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0721 - binary_accuracy: 0.9760 - auc_200: 0.9450 - precision_200: 0.7256 - recall_200: 0.3484\n","Score for fold 1: F1 score of 0.497661084107738; loss of 0.06950854510068893; binary_accuracy of 97.6474404335022%\n","Current best model for Molecular Function has an F1 score of 0.497661084107738\n","Training for fold 2 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 33ms/step - loss: 0.1107 - binary_accuracy: 0.9677 - auc_201: 0.8538 - precision_201: 0.4366 - recall_201: 0.1796\n","Epoch 2/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0812 - binary_accuracy: 0.9743 - auc_201: 0.9250 - precision_201: 0.7111 - recall_201: 0.2711\n","Epoch 3/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0767 - binary_accuracy: 0.9750 - auc_201: 0.9356 - precision_201: 0.7175 - recall_201: 0.3069\n","Epoch 4/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0739 - binary_accuracy: 0.9756 - auc_201: 0.9413 - precision_201: 0.7218 - recall_201: 0.3316\n","Epoch 5/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_201: 0.9453 - precision_201: 0.7266 - recall_201: 0.3508\n","Score for fold 2: F1 score of 0.5020477579150516; loss of 0.06923060864210129; binary_accuracy of 97.66473174095154%\n","Current best model for Molecular Function has an F1 score of 0.5020477579150516\n","Training for fold 3 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 33ms/step - loss: 0.1117 - binary_accuracy: 0.9674 - auc_202: 0.8518 - precision_202: 0.4258 - recall_202: 0.1796\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0815 - binary_accuracy: 0.9742 - auc_202: 0.9243 - precision_202: 0.7121 - recall_202: 0.2685\n","Epoch 3/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0769 - binary_accuracy: 0.9750 - auc_202: 0.9353 - precision_202: 0.7168 - recall_202: 0.3049\n","Epoch 4/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0741 - binary_accuracy: 0.9755 - auc_202: 0.9411 - precision_202: 0.7208 - recall_202: 0.3299\n","Epoch 5/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_202: 0.9453 - precision_202: 0.7250 - recall_202: 0.3490\n","Score for fold 3: F1 score of 0.47214068864101744; loss of 0.0695158988237381; binary_accuracy of 97.64565229415894%\n","Training for fold 4 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 32ms/step - loss: 0.1108 - binary_accuracy: 0.9674 - auc_203: 0.8562 - precision_203: 0.4272 - recall_203: 0.1837\n","Epoch 2/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0815 - binary_accuracy: 0.9742 - auc_203: 0.9243 - precision_203: 0.7105 - recall_203: 0.2692\n","Epoch 3/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0769 - binary_accuracy: 0.9750 - auc_203: 0.9352 - precision_203: 0.7158 - recall_203: 0.3051\n","Epoch 4/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0740 - binary_accuracy: 0.9755 - auc_203: 0.9413 - precision_203: 0.7223 - recall_203: 0.3299\n","Epoch 5/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_203: 0.9451 - precision_203: 0.7264 - recall_203: 0.3495\n","Score for fold 4: F1 score of 0.4898330055606086; loss of 0.06965633481740952; binary_accuracy of 97.64847159385681%\n","Training for fold 5 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 33ms/step - loss: 0.1101 - binary_accuracy: 0.9677 - auc_204: 0.8582 - precision_204: 0.4390 - recall_204: 0.1866\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0811 - binary_accuracy: 0.9743 - auc_204: 0.9253 - precision_204: 0.7131 - recall_204: 0.2717\n","Epoch 3/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0766 - binary_accuracy: 0.9751 - auc_204: 0.9358 - precision_204: 0.7171 - recall_204: 0.3090\n","Epoch 4/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0738 - binary_accuracy: 0.9756 - auc_204: 0.9417 - precision_204: 0.7222 - recall_204: 0.3329\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0717 - binary_accuracy: 0.9761 - auc_204: 0.9458 - precision_204: 0.7256 - recall_204: 0.3531\n","Score for fold 5: F1 score of 0.499771471430553; loss of 0.06918582320213318; binary_accuracy of 97.65890836715698%\n","Training for fold 6 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1118 - binary_accuracy: 0.9674 - auc_205: 0.8550 - precision_205: 0.4276 - recall_205: 0.1854\n","Epoch 2/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0811 - binary_accuracy: 0.9743 - auc_205: 0.9255 - precision_205: 0.7112 - recall_205: 0.2728\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0767 - binary_accuracy: 0.9750 - auc_205: 0.9357 - precision_205: 0.7171 - recall_205: 0.3062\n","Epoch 4/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0740 - binary_accuracy: 0.9755 - auc_205: 0.9413 - precision_205: 0.7215 - recall_205: 0.3304\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0718 - binary_accuracy: 0.9760 - auc_205: 0.9455 - precision_205: 0.7259 - recall_205: 0.3505\n","Score for fold 6: F1 score of 0.49234676271665906; loss of 0.06917078047990799; binary_accuracy of 97.66039252281189%\n","Training for fold 7 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1118 - binary_accuracy: 0.9673 - auc_206: 0.8520 - precision_206: 0.4238 - recall_206: 0.1804\n","Epoch 2/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0815 - binary_accuracy: 0.9742 - auc_206: 0.9244 - precision_206: 0.7102 - recall_206: 0.2699\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0768 - binary_accuracy: 0.9750 - auc_206: 0.9356 - precision_206: 0.7170 - recall_206: 0.3056\n","Epoch 4/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0740 - binary_accuracy: 0.9756 - auc_206: 0.9412 - precision_206: 0.7211 - recall_206: 0.3315\n","Epoch 5/5\n","218/218 [==============================] - 8s 34ms/step - loss: 0.0718 - binary_accuracy: 0.9760 - auc_206: 0.9455 - precision_206: 0.7257 - recall_206: 0.3510\n","Score for fold 7: F1 score of 0.46864292476779595; loss of 0.06938151270151138; binary_accuracy of 97.64901995658875%\n","Training for fold 8 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 34ms/step - loss: 0.1110 - binary_accuracy: 0.9675 - auc_207: 0.8548 - precision_207: 0.4312 - recall_207: 0.1834\n","Epoch 2/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0813 - binary_accuracy: 0.9743 - auc_207: 0.9249 - precision_207: 0.7125 - recall_207: 0.2702\n","Epoch 3/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0768 - binary_accuracy: 0.9750 - auc_207: 0.9356 - precision_207: 0.7171 - recall_207: 0.3055\n","Epoch 4/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0740 - binary_accuracy: 0.9755 - auc_207: 0.9413 - precision_207: 0.7215 - recall_207: 0.3284\n","Epoch 5/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0719 - binary_accuracy: 0.9760 - auc_207: 0.9456 - precision_207: 0.7258 - recall_207: 0.3494\n","Score for fold 8: F1 score of 0.4936876771627983; loss of 0.06963391602039337; binary_accuracy of 97.65689969062805%\n","Training for fold 9 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 32ms/step - loss: 0.1102 - binary_accuracy: 0.9674 - auc_208: 0.8595 - precision_208: 0.4288 - recall_208: 0.1915\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0808 - binary_accuracy: 0.9743 - auc_208: 0.9261 - precision_208: 0.7115 - recall_208: 0.2758\n","Epoch 3/5\n","218/218 [==============================] - 7s 32ms/step - loss: 0.0764 - binary_accuracy: 0.9751 - auc_208: 0.9363 - precision_208: 0.7175 - recall_208: 0.3091\n","Epoch 4/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0737 - binary_accuracy: 0.9756 - auc_208: 0.9418 - precision_208: 0.7216 - recall_208: 0.3340\n","Epoch 5/5\n","218/218 [==============================] - 7s 33ms/step - loss: 0.0716 - binary_accuracy: 0.9761 - auc_208: 0.9457 - precision_208: 0.7259 - recall_208: 0.3533\n","Score for fold 9: F1 score of 0.4943451574522805; loss of 0.06949654221534729; binary_accuracy of 97.64646887779236%\n","Training for fold 10 ...\n","Epoch 1/5\n","218/218 [==============================] - 9s 33ms/step - loss: 0.1115 - binary_accuracy: 0.9674 - auc_209: 0.8552 - precision_209: 0.4276 - recall_209: 0.1867\n","Epoch 2/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0812 - binary_accuracy: 0.9743 - auc_209: 0.9251 - precision_209: 0.7116 - recall_209: 0.2719\n","Epoch 3/5\n","218/218 [==============================] - 8s 34ms/step - loss: 0.0768 - binary_accuracy: 0.9750 - auc_209: 0.9355 - precision_209: 0.7168 - recall_209: 0.3066\n","Epoch 4/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0740 - binary_accuracy: 0.9755 - auc_209: 0.9413 - precision_209: 0.7215 - recall_209: 0.3299\n","Epoch 5/5\n","218/218 [==============================] - 7s 34ms/step - loss: 0.0720 - binary_accuracy: 0.9760 - auc_209: 0.9452 - precision_209: 0.7254 - recall_209: 0.3494\n","Score for fold 10: F1 score of 0.49278847399338815; loss of 0.06938135623931885; binary_accuracy of 97.65684604644775%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FPRk3Ferc2fr","executionInfo":{"status":"ok","timestamp":1708304760637,"user_tz":-60,"elapsed":16,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"}}},"execution_count":14,"outputs":[]}]}