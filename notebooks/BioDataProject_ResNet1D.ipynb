{"cells":[{"cell_type":"markdown","metadata":{"id":"rrM-gFkvkbOx"},"source":["# ResNet-like 1D Neural Network\n","\n","This note book will be used to test resnet inspired neural network on each of the 3 ontologies."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5107,"status":"ok","timestamp":1708292955436,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"INY5-pvaEKak"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-23 01:11:56.967040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-23 01:12:07.755743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/blast-plus-2.12.0-zt4jna4xynkry22vk62pu2bzcspytxm7/lib:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cuda-10.1.243-fgipoyn2aa7f5eqpjut35wchklelutf6/lib64:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cudnn-7.6.3.30-10.1-linux-x64-2in3eqmrnltkm2jvegqk3momjizihy5t/lib64:/gpfs/space/software/cluster_software/compilers/gcc-9.2.0/lib64:/gpfs/space/software/cluster_software/manual/any/python/conda/3.8/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/python-3.10.10-pfr7vmasg4bcyjnzs2fqbzu25nihahvn/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/zlib-1.2.9-5f6os64uxcqi6maa562tiez2sfoiev6j/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/util-linux-uuid-2.37.4-64fuxgoqjpljsejkoukv7we25ejujkv2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/sqlite-3.38.5-6om7c4enymngbfes4bs22jwcv47ifolw/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/openssl-3.1.0-ajt6p2d2dme2ukuemvpsop7u223ysc4p/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxcrypt-4.4.33-q66zm4ctluh2vhik2udglo6runo2v2lq/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gettext-0.21.1-4ijwgqvodnymnuqfcawut4kcxvoazqug/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/ncurses-6.2-jfejotbts5qgn7rnn7gvwgq7plcsv56n/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gdbm-1.23-hk4fyx5624v6tel3vemlkd6s36rxjcn2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/readline-8.1-jcxe2o7ibne6bokmmoihy774o7udnzay/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/expat-2.4.8-yon44f47ecp45vz6rz3i636cf3avconb/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/bzip2-1.0.8-gpvicjs26x2h4rox67uniqfkyjvmwgqo/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/cuda-11.7.0-hfqzohhoijx3mhqdh2w3mvycmhbrcner/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxml2-2.9.12-lwp5q5ymzzhhhv2u4zmve6x6uojbymxf/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libiconv-1.16-lgagwi6e52rlrjftg6bkfywcghlgdw3b/lib\n","2024-02-23 01:12:07.756231: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/blast-plus-2.12.0-zt4jna4xynkry22vk62pu2bzcspytxm7/lib:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cuda-10.1.243-fgipoyn2aa7f5eqpjut35wchklelutf6/lib64:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cudnn-7.6.3.30-10.1-linux-x64-2in3eqmrnltkm2jvegqk3momjizihy5t/lib64:/gpfs/space/software/cluster_software/compilers/gcc-9.2.0/lib64:/gpfs/space/software/cluster_software/manual/any/python/conda/3.8/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/python-3.10.10-pfr7vmasg4bcyjnzs2fqbzu25nihahvn/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/zlib-1.2.9-5f6os64uxcqi6maa562tiez2sfoiev6j/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/util-linux-uuid-2.37.4-64fuxgoqjpljsejkoukv7we25ejujkv2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/sqlite-3.38.5-6om7c4enymngbfes4bs22jwcv47ifolw/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/openssl-3.1.0-ajt6p2d2dme2ukuemvpsop7u223ysc4p/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxcrypt-4.4.33-q66zm4ctluh2vhik2udglo6runo2v2lq/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gettext-0.21.1-4ijwgqvodnymnuqfcawut4kcxvoazqug/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/ncurses-6.2-jfejotbts5qgn7rnn7gvwgq7plcsv56n/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gdbm-1.23-hk4fyx5624v6tel3vemlkd6s36rxjcn2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/readline-8.1-jcxe2o7ibne6bokmmoihy774o7udnzay/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/expat-2.4.8-yon44f47ecp45vz6rz3i636cf3avconb/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/bzip2-1.0.8-gpvicjs26x2h4rox67uniqfkyjvmwgqo/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/cuda-11.7.0-hfqzohhoijx3mhqdh2w3mvycmhbrcner/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxml2-2.9.12-lwp5q5ymzzhhhv2u4zmve6x6uojbymxf/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libiconv-1.16-lgagwi6e52rlrjftg6bkfywcghlgdw3b/lib\n","2024-02-23 01:12:07.756254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import KFold\n","import yaml"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708292955437,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"FQzydhXnRN-w","outputId":"b51a5ee4-2d55-4eb9-c1f2-57b390b932ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow v2.11.0\n","Numpy v1.21.5\n"]}],"source":["print(\"TensorFlow v\" + tf.__version__)\n","print(\"Numpy v\" + np.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["config_path = './config.yaml'\n","with open(config_path, 'r') as file:\n","    config = yaml.safe_load(file)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":551,"status":"ok","timestamp":1708293042698,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"EgQNBoLEFwNF"},"outputs":[],"source":["USE_75_PERCENT_DATA = config['use_75_percent_datasets']\n","partial_dataset_prefix = '75percent_' if USE_75_PERCENT_DATA else ''\n","BP_train_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_embeddings_BiologicalProcesses.pkl\")\n","CC_train_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_embeddings_CellularComponent.pkl\")\n","MF_train_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_embeddings_MolecularFunction.pkl\")\n","BP_label_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_labels_BiologicalProcesses.pkl\")\n","CC_label_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_labels_CellularComponent.pkl\")\n","MF_label_df = pd.read_pickle(f\"{config['directories']['preprocessed_data']}/{partial_dataset_prefix}train_labels_MolecularFunction.pkl\")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708293044720,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"fN_1hLZRq1JW"},"outputs":[],"source":["train_data_dict = {\n","    'Biological Processes': [BP_train_df, BP_label_df],\n","    'Cellular Component': [CC_train_df, CC_label_df],\n","    'Molecular Function': [MF_train_df, MF_label_df]\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708293044720,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"OdUudkyKj3ID"},"outputs":[],"source":["num_labels = 1500\n","num_folds = config['num_folds']"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708293044720,"user":{"displayName":"chelsie romain","userId":"15975139810273213353"},"user_tz":-60},"id":"62fohGyUlVrU"},"outputs":[],"source":["BATCH_SIZE = config['batch_size']"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from tensorflow.keras import layers, models\n","\n","class ResNet1DBlock(models.Model):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResNet1DBlock, self).__init__()\n","        self.conv1 = layers.Conv1D(out_channels, kernel_size=3, strides=stride, padding='same', use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","        self.relu = layers.ReLU()\n","        self.conv2 = layers.Conv1D(out_channels, kernel_size=3, padding='same', use_bias=False)\n","        self.bn2 = layers.BatchNormalization()\n","        self.downsample = downsample\n","\n","    def call(self, inputs, training=False):\n","        identity = inputs\n","\n","        out = self.conv1(inputs)\n","        out = self.bn1(out, training=training)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out, training=training)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(inputs)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet1D(models.Model):\n","    def __init__(self, input_channels=1, num_classes=1500):\n","        super(ResNet1D, self).__init__()\n","        \n","        self.initial_conv = layers.Conv1D(64, kernel_size=7, strides=2, padding='same', use_bias=False)\n","        self.initial_bn = layers.BatchNormalization()\n","        self.relu = layers.ReLU()\n","        self.maxpool = layers.MaxPool1D(pool_size=3, strides=2, padding='same')\n","\n","        self.layer1 = self._make_layer(64, 64, blocks=2)\n","        self.layer2 = self._make_layer(64, 128, blocks=2, stride=2)\n","        self.layer3 = self._make_layer(128, 256, blocks=2, stride=2)\n","        self.layer4 = self._make_layer(256, 512, blocks=2, stride=2)\n","\n","        self.avgpool = layers.GlobalAveragePooling1D()\n","        self.fc = layers.Dense(num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or in_channels != out_channels:\n","            downsample = models.Sequential([\n","                layers.Conv1D(out_channels, kernel_size=1, strides=stride, use_bias=False),\n","                layers.BatchNormalization(),\n","            ])\n","\n","        layers_list = []\n","        layers_list.append(ResNet1DBlock(in_channels, out_channels, stride, downsample))\n","        for _ in range(1, blocks):\n","            layers_list.append(ResNet1DBlock(out_channels, out_channels))\n","\n","        return models.Sequential(layers_list)\n","\n","    def call(self, inputs, training=False):\n","        inputs = tf.expand_dims(inputs, axis=-1)\n","        \n","        x = self.initial_conv(inputs)\n","        x = self.initial_bn(x, training=training)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x, training=training)\n","        x = self.layer2(x, training=training)\n","        x = self.layer3(x, training=training)\n","        x = self.layer4(x, training=training)\n","\n","        x = self.avgpool(x)\n","        x = self.fc(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def train_model(get_model, dataset_name, model_name, data, num_folds, BATCH_SIZE):\n","    train, label = data\n","\n","    best_f1 = 0\n","    print('=======================================================================')\n","    print(f'Training for {dataset_name}')\n","    \n","    model_root_path = f'{config[\"directories\"][\"models\"]}/{model_name}'\n","\n","    kfold = KFold(n_splits=num_folds, shuffle=True)\n","    fold_no = 1\n","\n","    for train_fold, test_fold in kfold.split(train, label):\n","        print(f'Training for fold {fold_no} ...')\n","        \n","        label_frequencies = label.iloc[train_fold].mean(axis=0)\n","\n","        weights = 1 / (label_frequencies + 1e-8)\n","        weights = weights / weights.sum() \n","        \n","        def weighted_softmax_cross_entropy_with_logits(labels, logits):\n","            raw_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n","            \n","            weights_reshaped = tf.reshape(weights, [1, -1])\n","    \n","            weighted_loss = raw_loss * weights_reshaped\n","    \n","            return tf.reduce_mean(weighted_loss)\n","\n","        model = get_model()\n","        model.compile(\n","          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","          loss=weighted_softmax_cross_entropy_with_logits,\n","          metrics=['binary_accuracy',\n","                tf.keras.metrics.AUC(),\n","                tf.keras.metrics.Precision(),\n","                tf.keras.metrics.Recall(),\n","                ]\n","          )\n","\n","        history = model.fit(\n","            train.iloc[train_fold], label.iloc[train_fold],\n","            validation_data=(train.iloc[test_fold], label.iloc[test_fold]),\n","            batch_size=BATCH_SIZE,\n","            epochs=5\n","        )\n","\n","        scores = model.evaluate(train.iloc[test_fold], label.iloc[test_fold], verbose=0)\n","        precision = scores[3]\n","        recall = scores[4]\n","        F1_score = 2 * precision * recall / (precision + recall)\n","        print(f'Score for fold {fold_no}: F1 score of {F1_score}; {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","\n","        if F1_score > best_f1:\n","            best_f1 = F1_score\n","            \n","            if dataset_name == 'Biological Processes':\n","              tf.keras.models.save_model(\n","                  model,\n","                  f'{model_root_path}/best_BP_model',\n","              )\n","              print(f'Current best model for Biological Processes has an F1 score of {F1_score}')\n","\n","            elif dataset_name == 'Molecular Function':\n","              tf.keras.models.save_model(\n","                  model,\n","                  f'{model_root_path}/best_MF_model',\n","              )\n","              print(f'Current best model for Molecular Function has an F1 score of {F1_score}')\n","            else:\n","              tf.keras.models.save_model(\n","                  model,\n","                  f'{model_root_path}/best_CC_model',\n","              )\n","              print(f'Current best model for Cellular Component has an F1 score of {F1_score}')\n","\n","        fold_no += 1"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def train_on_datasets(get_model, model_name):\n","    for dataset in train_data_dict:\n","        dataset_name = dataset\n","        data = train_data_dict[dataset]\n","        train_model(get_model, dataset_name, model_name, data, 10, BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_model_1():\n","    model = ResNet1D()\n","    \n","    return model\n","\n","train_on_datasets(get_model_1, 'ResNet1D_1')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP6bDrYFgL/WiV5V+sI+Yby","gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}
