{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/home/donatasv/.conda/envs/bio/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import ProteinDataset\n",
    "\n",
    "dataset = ProteinDataset('/gpfs/space/home/donatasv/semester_3/biological_data/project/data/preprocessed_small/biological_process_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/srush/annotated-s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install jaxlib=*=*cuda* jax cuda-nvcc -c conda-forge -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotated_s4.s4 import S4Layer, BatchStackedModel\n",
    "import torch\n",
    "import jax\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"d_model\": 128,\n",
    "        \"n_layers\": 4,\n",
    "        \"dropout\": 0.0,\n",
    "        \"prenorm\": True,\n",
    "        \"embedding\": False,\n",
    "        \"layer\": {\n",
    "            \"N\": 64\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"epochs\": 10,\n",
    "        \"bsz\": 128,\n",
    "        \"lr\": 0.001,\n",
    "        \"lr_schedule\": False,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"checkpoint\": False,\n",
    "        \"suffix\": None,  # Use None for null values in Python\n",
    "        \"sample\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "config = OmegaConf.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.random.manual_seed(seed)  # For dataloader order\n",
    "key = jax.random.PRNGKey(seed)\n",
    "key, rng, train_rng = jax.random.split(key, num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(dataset[0][1])\n",
    "sequence_length = len(dataset[0][0])\n",
    "input_dim = 1\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.9)\n",
    "val_size = total_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Starting `<class 'flax.linen.transforms.VmapS4Layer'>` Training on `<dataset.ProteinDataset object at 0x2ac973fa4a10>` =>> Initializing...\n"
     ]
    }
   ],
   "source": [
    "# Get model class and arguments\n",
    "layer_cls = S4Layer\n",
    "config['model']['layer']['l_max'] = sequence_length\n",
    "# Extract custom hyperparameters from model class\n",
    "lr_layer = getattr(layer_cls, \"lr\", None)\n",
    "print(f\"[*] Starting `{layer_cls}` Training on `{dataset}` =>> Initializing...\")\n",
    "model_cls = partial(\n",
    "    BatchStackedModel,\n",
    "    layer_cls=S4Layer,\n",
    "    d_output=n_classes,\n",
    "    classification=True,\n",
    "    **config['model'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 19:26:55.273894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/blast-plus-2.12.0-zt4jna4xynkry22vk62pu2bzcspytxm7/lib:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cuda-10.1.243-fgipoyn2aa7f5eqpjut35wchklelutf6/lib64:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cudnn-7.6.3.30-10.1-linux-x64-2in3eqmrnltkm2jvegqk3momjizihy5t/lib64:/gpfs/space/software/cluster_software/compilers/gcc-9.2.0/lib64:/gpfs/space/software/cluster_software/manual/any/python/conda/3.8/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/python-3.10.10-pfr7vmasg4bcyjnzs2fqbzu25nihahvn/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/zlib-1.2.9-5f6os64uxcqi6maa562tiez2sfoiev6j/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/util-linux-uuid-2.37.4-64fuxgoqjpljsejkoukv7we25ejujkv2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/sqlite-3.38.5-6om7c4enymngbfes4bs22jwcv47ifolw/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/openssl-3.1.0-ajt6p2d2dme2ukuemvpsop7u223ysc4p/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxcrypt-4.4.33-q66zm4ctluh2vhik2udglo6runo2v2lq/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gettext-0.21.1-4ijwgqvodnymnuqfcawut4kcxvoazqug/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/ncurses-6.2-jfejotbts5qgn7rnn7gvwgq7plcsv56n/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gdbm-1.23-hk4fyx5624v6tel3vemlkd6s36rxjcn2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/readline-8.1-jcxe2o7ibne6bokmmoihy774o7udnzay/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/expat-2.4.8-yon44f47ecp45vz6rz3i636cf3avconb/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/bzip2-1.0.8-gpvicjs26x2h4rox67uniqfkyjvmwgqo/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/cuda-11.7.0-hfqzohhoijx3mhqdh2w3mvycmhbrcner/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxml2-2.9.12-lwp5q5ymzzhhhv2u4zmve6x6uojbymxf/lib:/usr/local/cuda/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libiconv-1.16-lgagwi6e52rlrjftg6bkfywcghlgdw3b/lib\n",
      "2024-02-15 19:26:55.274575: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/blast-plus-2.12.0-zt4jna4xynkry22vk62pu2bzcspytxm7/lib:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cuda-10.1.243-fgipoyn2aa7f5eqpjut35wchklelutf6/lib64:/gpfs/software/soft/spack/linux-centos7-broadwell/gcc-9.2.0/cudnn-7.6.3.30-10.1-linux-x64-2in3eqmrnltkm2jvegqk3momjizihy5t/lib64:/gpfs/space/software/cluster_software/compilers/gcc-9.2.0/lib64:/gpfs/space/software/cluster_software/manual/any/python/conda/3.8/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/python-3.10.10-pfr7vmasg4bcyjnzs2fqbzu25nihahvn/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/zlib-1.2.9-5f6os64uxcqi6maa562tiez2sfoiev6j/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/util-linux-uuid-2.37.4-64fuxgoqjpljsejkoukv7we25ejujkv2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/sqlite-3.38.5-6om7c4enymngbfes4bs22jwcv47ifolw/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/openssl-3.1.0-ajt6p2d2dme2ukuemvpsop7u223ysc4p/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxcrypt-4.4.33-q66zm4ctluh2vhik2udglo6runo2v2lq/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libffi-3.4.2-e5uhsioitlwkogqhphqu62evntt5izii/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gettext-0.21.1-4ijwgqvodnymnuqfcawut4kcxvoazqug/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/ncurses-6.2-jfejotbts5qgn7rnn7gvwgq7plcsv56n/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/gdbm-1.23-hk4fyx5624v6tel3vemlkd6s36rxjcn2/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/readline-8.1-jcxe2o7ibne6bokmmoihy774o7udnzay/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/expat-2.4.8-yon44f47ecp45vz6rz3i636cf3avconb/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/bzip2-1.0.8-gpvicjs26x2h4rox67uniqfkyjvmwgqo/lib:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/cuda-11.7.0-hfqzohhoijx3mhqdh2w3mvycmhbrcner/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libxml2-2.9.12-lwp5q5ymzzhhhv2u4zmve6x6uojbymxf/lib:/usr/local/cuda/lib64:/gpfs/space/software/cluster_software/spack/linux-centos7-x86_64/gcc-9.2.0/libiconv-1.16-lgagwi6e52rlrjftg6bkfywcghlgdw3b/lib\n",
      "2024-02-15 19:26:55.274602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from annotated_s4.s4.train import create_train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hydra optax flax==0.5.0 omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/home/donatasv/.conda/envs/bio/lib/python3.7/site-packages/flax/core/lift.py:112: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  scopes, treedef = jax.tree_flatten(scope_tree)\n",
      "/gpfs/space/home/donatasv/.conda/envs/bio/lib/python3.7/site-packages/flax/core/lift.py:584: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  leaves = jax.tree_leaves(x)\n",
      "/gpfs/space/home/donatasv/.conda/envs/bio/lib/python3.7/site-packages/flax/core/lift.py:592: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  axis_sizes = set(jax.tree_leaves(axis_sizes))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[128])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[ 0.04555337,  0.01130313, -0.01651748, ...,  0.02575472,\n",
      "               0.03717741, -0.0049449 ],\n",
      "             [ 0.08009459, -0.0493723 , -0.01779799, ...,  0.00269891,\n",
      "               0.01006696, -0.02034261],\n",
      "             [ 0.04261799, -0.04334757,  0.01284971, ..., -0.04625276,\n",
      "              -0.02381139, -0.04930048],\n",
      "             ...,\n",
      "             [ 0.05307975,  0.08503498,  0.00541616, ..., -0.06695689,\n",
      "              -0.00237431,  0.01109306],\n",
      "             [ 0.03436558,  0.01655401, -0.01819258, ...,  0.04164709,\n",
      "               0.02646559, -0.05257869],\n",
      "             [ 0.01717659,  0.04736052, -0.00554082, ...,  0.02223217,\n",
      "               0.06620044, -0.06609014]], dtype=float32)\n",
      "  batch_dim = 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7358/1144547037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlr_schedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/semester_3/biological_data/project/annotated_s4/s4/train.py\u001b[0m in \u001b[0;36mcreate_train_state\u001b[0;34m(rng, model_cls, trainloader, lr, lr_layer, lr_schedule, weight_decay, total_steps)\u001b[0m\n\u001b[1;32m     75\u001b[0m     params = model.init(\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_rng\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     )\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Note: Added immediate `unfreeze()` to play well w/ Optax. See below!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 20 frame]\u001b[0m\n",
      "\u001b[0;32m~/semester_3/biological_data/project/annotated_s4/s4/s4.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m~/semester_3/biological_data/project/annotated_s4/s4/s4.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprenorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bio/lib/python3.7/site-packages/flax/core/lift.py\u001b[0m in \u001b[0;36mfind_axis_size\u001b[0;34m(axis, x)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mleaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleaves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mleaves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "state = create_train_state(\n",
    "    rng,\n",
    "    model_cls,\n",
    "    train_loader,\n",
    "    lr=config.train.lr,\n",
    "    lr_layer=lr_layer,\n",
    "    lr_schedule=config.train.lr_schedule,\n",
    "    weight_decay=config.train.weight_decay,\n",
    "    total_steps=len(train_loader) * config.train.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over epochs\n",
    "# best_loss, best_acc, best_epoch = 10000, 0, 0\n",
    "# for epoch in range(train.epochs):\n",
    "#     print(f\"[*] Starting Training Epoch {epoch + 1}...\")\n",
    "#     state, train_loss, train_acc = train_epoch(\n",
    "#         state,\n",
    "#         train_rng,\n",
    "#         model_cls,\n",
    "#         trainloader,\n",
    "#         classification=classification,\n",
    "#     )\n",
    "#     print(f\"[*] Running Epoch {epoch + 1} Validation...\")\n",
    "#     test_loss, test_acc = validate(\n",
    "#         state.params, model_cls, testloader, classification=classification\n",
    "#     )\n",
    "#     print(f\"\\n=>> Epoch {epoch + 1} Metrics ===\")\n",
    "#     print(\n",
    "#         f\"\\tTrain Loss: {train_loss:.5f} -- Train Accuracy:\"\n",
    "#         f\" {train_acc:.4f}\\n\\t Test Loss: {test_loss:.5f} --  Test\"\n",
    "#         f\" Accuracy: {test_acc:.4f}\"\n",
    "#     )\n",
    "#     # Save a checkpoint each epoch & handle best (test loss... not \"copacetic\" but ehh)\n",
    "#     if train.checkpoint:\n",
    "#         suf = f\"-{train.suffix}\" if train.suffix is not None else \"\"\n",
    "#         run_id = f\"checkpoints/{dataset}/{layer}-d_model={model.d_model}-lr={train.lr}-bsz={train.bsz}{suf}\"\n",
    "#         ckpt_path = checkpoints.save_checkpoint(\n",
    "#             run_id,\n",
    "#             state,\n",
    "#             epoch,\n",
    "#             keep=train.epochs,\n",
    "#         )\n",
    "#     if train.sample is not None:\n",
    "#         if dataset == \"mnist\":  # Should work for QuickDraw too but untested\n",
    "#             sample_fn = partial(\n",
    "#                 sample_image_prefix, imshape=(28, 28)\n",
    "#             )  # params=state[\"params\"], length=784, bsz=64, prefix=train.sample)\n",
    "#         else:\n",
    "#             raise NotImplementedError(\n",
    "#                 \"Sampling currently only supported for MNIST\"\n",
    "#             )\n",
    "#         # model_cls = partial(\n",
    "#         #     BatchStackedModel,\n",
    "#         #     layer_cls=layer_cls,\n",
    "#         #     d_output=n_classes,\n",
    "#         #     classification=classification,\n",
    "#         #     **model,\n",
    "#         # )\n",
    "#         samples, examples = sample_fn(\n",
    "#             # run_id,\n",
    "#             params=state.params,\n",
    "#             model=model_cls(decode=True, training=False),\n",
    "#             rng=rng,\n",
    "#             dataloader=testloader,\n",
    "#             prefix=train.sample,\n",
    "#             n_batches=1,\n",
    "#             save=False,\n",
    "#         )\n",
    "#         if wandb is not None:\n",
    "#             samples = [wandb.Image(sample) for sample in samples]\n",
    "#             wandb.log({\"samples\": samples}, commit=False)\n",
    "#             examples = [wandb.Image(example) for example in examples]\n",
    "#             wandb.log({\"examples\": examples}, commit=False)\n",
    "#     if (classification and test_acc > best_acc) or (\n",
    "#         not classification and test_loss < best_loss\n",
    "#     ):\n",
    "#         # Create new \"best-{step}.ckpt and remove old one\n",
    "#         if train.checkpoint:\n",
    "#             shutil.copy(ckpt_path, f\"{run_id}/best_{epoch}\")\n",
    "#             if os.path.exists(f\"{run_id}/best_{best_epoch}\"):\n",
    "#                 os.remove(f\"{run_id}/best_{best_epoch}\")\n",
    "#         best_loss, best_acc, best_epoch = test_loss, test_acc, epoch\n",
    "#     # Print best accuracy & loss so far...\n",
    "#     print(\n",
    "#         f\"\\tBest Test Loss: {best_loss:.5f} -- Best Test Accuracy:\"\n",
    "#         f\" {best_acc:.4f} at Epoch {best_epoch + 1}\\n\"\n",
    "#     )\n",
    "#     if wandb is not None:\n",
    "#         wandb.log(\n",
    "#             {\n",
    "#                 \"train/loss\": train_loss,\n",
    "#                 \"train/accuracy\": train_acc,\n",
    "#                 \"test/loss\": test_loss,\n",
    "#                 \"test/accuracy\": test_acc,\n",
    "#             },\n",
    "#             step=epoch,\n",
    "#         )\n",
    "#         wandb.run.summary[\"Best Test Loss\"] = best_loss\n",
    "#         wandb.run.summary[\"Best Test Accuracy\"] = best_acc\n",
    "#         wandb.run.summary[\"Best Epoch\"] = best_epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
